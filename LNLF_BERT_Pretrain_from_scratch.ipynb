{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU5g2jmqpxz8",
        "outputId": "c3fa3273-3c47-480f-90d1-4b2abadaa401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYrvBX95GHf5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YVc04KsGIrC",
        "outputId": "529fc877-3b33-4eba-c8de-ccb7d5b53793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets==2.14.7\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.7)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (4.66.4)\n",
            "Collecting xxhash (from datasets==2.14.7)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.14.7)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.7)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.7) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.7) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.7) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.7) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.7) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.7) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.7) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.7) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.7) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.7) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.7) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.7) (2024.7.4)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.14.7)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.14.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.14.7) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.14.7) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.7) (1.16.0)\n",
            "Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.7 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==2.14.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjdHF73PGKJD"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hso3gFeiGLU2",
        "outputId": "bdea1497-5245-44a6-9f26-545d3f80d08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.31.0\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2024.7.4)\n",
            "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.31.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "R_KfUR0sGM80",
        "outputId": "cad2d775-424a-49db-a0ef-fcd10dd7b0d4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.31.0'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVEHyYR0AZOh"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers.activations_tf import get_tf_activation\n",
        "from transformers.modeling_tf_outputs import (\n",
        "    TFBaseModelOutput,\n",
        "    TFMaskedLMOutput,\n",
        "    TFMultipleChoiceModelOutput,\n",
        "    TFQuestionAnsweringModelOutput,\n",
        "    TFSequenceClassifierOutput,\n",
        "    TFTokenClassifierOutput,\n",
        ")\n",
        "from transformers.modeling_tf_utils import (\n",
        "    TFMaskedLanguageModelingLoss,\n",
        "    TFModelInputType,\n",
        "    TFMultipleChoiceLoss,\n",
        "    TFPreTrainedModel,\n",
        "    TFQuestionAnsweringLoss,\n",
        "    TFSequenceClassificationLoss,\n",
        "    TFTokenClassificationLoss,\n",
        "    get_initializer,\n",
        "    keras_serializable,\n",
        "    unpack_inputs,\n",
        ")\n",
        "from transformers.tf_utils import check_embeddings_within_bounds, shape_list, stable_softmax\n",
        "from transformers.utils import (\n",
        "    ModelOutput,\n",
        "    add_code_sample_docstrings,\n",
        "    add_start_docstrings,\n",
        "    add_start_docstrings_to_model_forward,\n",
        "    logging,\n",
        "    replace_return_docstrings,\n",
        ")\n",
        "from transformers.models.roberta.configuration_roberta import RobertaConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C61J04vACa4"
      },
      "outputs": [],
      "source": [
        "class LNLFBertConfig(RobertaConfig):\n",
        "\n",
        "    model_type = \"lnlfbert\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        type_sen_size=5,\n",
        "        max_sen_position=64,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.type_sen_size = type_sen_size\n",
        "        self.max_sen_position = max_sen_position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilKQuacRASu3"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordEmbeddings(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Same as BertEmbeddings with a tiny tweak for positional embeddings indexing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.padding_idx = 1\n",
        "        self.config = config\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.max_position_embeddings = config.max_position_embeddings\n",
        "        self.initializer_range = config.initializer_range\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n",
        "\n",
        "    def build(self, input_shape: tf.TensorShape):\n",
        "        with tf.name_scope(\"word_embeddings\"):\n",
        "            self.weight = self.add_weight(\n",
        "                name=\"weight\",\n",
        "                shape=[self.config.vocab_size, self.hidden_size],\n",
        "                initializer=get_initializer(self.initializer_range),\n",
        "            )\n",
        "\n",
        "        with tf.name_scope(\"token_type_embeddings\"):\n",
        "            self.token_type_embeddings = self.add_weight(\n",
        "                name=\"embeddings\",\n",
        "                shape=[self.config.type_vocab_size, self.hidden_size],\n",
        "                initializer=get_initializer(self.initializer_range),\n",
        "            )\n",
        "\n",
        "        with tf.name_scope(\"position_embeddings\"):\n",
        "            self.position_embeddings = self.add_weight(\n",
        "                name=\"embeddings\",\n",
        "                shape=[self.max_position_embeddings, self.hidden_size],\n",
        "                initializer=get_initializer(self.initializer_range),\n",
        "            )\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def create_position_ids_from_input_ids(self, input_ids):\n",
        "        \"\"\"\n",
        "        Replace non-padding symbols with their position numbers. Position numbers begin at padding_idx+1. Padding\n",
        "        symbols are ignored. This is modified from fairseq's `utils.make_positions`.\n",
        "\n",
        "        Args:\n",
        "            input_ids: tf.Tensor\n",
        "        Returns: tf.Tensor\n",
        "        \"\"\"\n",
        "        mask = tf.cast(tf.math.not_equal(input_ids, self.padding_idx), dtype=input_ids.dtype)\n",
        "        incremental_indices = (tf.math.cumsum(mask, axis=-1)) * mask\n",
        "\n",
        "        return incremental_indices + self.padding_idx\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        position_ids=None,\n",
        "        token_type_ids=None,\n",
        "        inputs_embeds=None,\n",
        "        training=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Applies embedding based on inputs tensor.\n",
        "\n",
        "        Returns:\n",
        "            final_embeddings (`tf.Tensor`): output embedding tensor.\n",
        "        \"\"\"\n",
        "        assert not (input_ids is None and inputs_embeds is None)\n",
        "\n",
        "        if input_ids is not None:\n",
        "            check_embeddings_within_bounds(input_ids, self.config.vocab_size)\n",
        "            inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n",
        "\n",
        "        input_shape = shape_list(inputs_embeds)[:-1]\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = tf.fill(dims=input_shape, value=0)\n",
        "\n",
        "        if position_ids is None:\n",
        "            if input_ids is not None:\n",
        "                # Create the position ids from the input token ids. Any padded tokens remain padded.\n",
        "                position_ids = self.create_position_ids_from_input_ids(\n",
        "                    input_ids=input_ids\n",
        "                )\n",
        "            else:\n",
        "                position_ids = tf.expand_dims(\n",
        "                    tf.range(start=self.padding_idx + 1, limit=input_shape[-1] + self.padding_idx + 1), axis=0\n",
        "                )\n",
        "                position_ids = tf.expand_dims(\n",
        "                    position_ids, axis=0\n",
        "                )\n",
        "\n",
        "\n",
        "        position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\n",
        "        token_type_embeds = tf.gather(params=self.token_type_embeddings, indices=token_type_ids)\n",
        "        final_embeddings = inputs_embeds + position_embeds + token_type_embeds\n",
        "        final_embeddings = self.LayerNorm(inputs=final_embeddings)\n",
        "        final_embeddings = self.dropout(inputs=final_embeddings, training=training)\n",
        "\n",
        "        return final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-W4RwYNIB-T"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenEmbeddings(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Same as BertEmbeddings with a tiny tweak for positional embeddings indexing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.padding_idx = 1\n",
        "        self.config = config\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.max_position_embeddings = config.max_sen_position\n",
        "        self.initializer_range = config.initializer_range\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n",
        "        self.concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
        "\n",
        "    def build(self, input_shape: tf.TensorShape):\n",
        "        with tf.name_scope('cls_embeddings'):\n",
        "            self.cls_weights = self.add_weight(\n",
        "                name=\"cls_weight\",\n",
        "                shape=[self.hidden_size,],\n",
        "                initializer=get_initializer(self.initializer_range),\n",
        "            )\n",
        "\n",
        "        with tf.name_scope(\"token_type_embeddings\"):\n",
        "            self.token_type_embeddings = self.add_weight(\n",
        "                name=\"embeddings\",\n",
        "                shape=[self.config.type_sen_size, self.hidden_size],\n",
        "                initializer=get_initializer(self.initializer_range),\n",
        "            )\n",
        "\n",
        "        with tf.name_scope(\"position_embeddings\"):\n",
        "            self.position_embeddings = self.add_weight(\n",
        "                name=\"embeddings\",\n",
        "                shape=[self.max_position_embeddings, self.hidden_size],\n",
        "                initializer=get_initializer(self.initializer_range),\n",
        "            )\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def create_position_ids_from_input_ids(self, input_ids):\n",
        "        \"\"\"\n",
        "        Replace non-padding symbols with their position numbers. Position numbers begin at padding_idx+1. Padding\n",
        "        symbols are ignored. This is modified from fairseq's `utils.make_positions`.\n",
        "\n",
        "        Args:\n",
        "            input_ids: tf.Tensor\n",
        "        Returns: tf.Tensor\n",
        "        \"\"\"\n",
        "        mask = tf.cast(tf.math.not_equal(input_ids, self.padding_idx), dtype=input_ids.dtype)\n",
        "        incremental_indices = (tf.math.cumsum(mask, axis=1)) * mask\n",
        "\n",
        "        return incremental_indices + self.padding_idx\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        position_ids=None,\n",
        "        token_type_ids=None,\n",
        "        inputs_embeds=None,\n",
        "        training=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Applies embedding based on inputs tensor.\n",
        "\n",
        "        Returns:\n",
        "            final_embeddings (`tf.Tensor`): output embedding tensor.\n",
        "        \"\"\"\n",
        "        assert not (inputs_embeds is None)\n",
        "\n",
        "        input_embed_shape = shape_list(inputs_embeds)\n",
        "        input_shape = input_embed_shape[:-1]\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = tf.fill(dims=input_shape, value=0)\n",
        "\n",
        "        if position_ids is None:\n",
        "            position_ids = tf.expand_dims(\n",
        "                tf.range(start=self.padding_idx + 1, limit=input_shape[-1] + self.padding_idx + 1), axis=0\n",
        "            )\n",
        "\n",
        "        input_embed_shape = [input_embed_shape[0], 1, input_embed_shape[2]]\n",
        "        cls_tile = tf.fill(dims=input_embed_shape, value=0)\n",
        "        cls_tile = tf.cast(cls_tile, self.cls_weights.dtype)\n",
        "        cls_embeds = cls_tile + self.cls_weights\n",
        "\n",
        "        position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\n",
        "        token_type_embeds = tf.gather(params=self.token_type_embeddings, indices=token_type_ids)\n",
        "        final_embeddings = inputs_embeds + position_embeds + token_type_embeds\n",
        "        final_embeddings = self.concat_layer([cls_embeds, final_embeddings])\n",
        "        final_embeddings = self.LayerNorm(inputs=final_embeddings)\n",
        "        final_embeddings = self.dropout(inputs=final_embeddings, training=training)\n",
        "\n",
        "        return final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIivBAWgKEN2"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordPooler(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.hidden_size,\n",
        "            kernel_initializer=get_initializer(config.initializer_range),\n",
        "            activation=\"tanh\",\n",
        "            name=\"dense\",\n",
        "        )\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor) -> tf.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = hidden_states[:, :, 0]\n",
        "        pooled_output = self.dense(inputs=first_token_tensor)\n",
        "\n",
        "        return pooled_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYgfjkd0KExN"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenPooler(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.hidden_size,\n",
        "            kernel_initializer=get_initializer(config.initializer_range),\n",
        "            activation=\"tanh\",\n",
        "            name=\"dense\",\n",
        "        )\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor) -> tf.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(inputs=first_token_tensor)\n",
        "\n",
        "        return pooled_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLOokrL2KMm2"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordSelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number \"\n",
        "                f\"of attention heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "        self.sqrt_att_head_size = math.sqrt(self.attention_head_size)\n",
        "\n",
        "        self.query = tf.keras.layers.Dense(\n",
        "            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"query\"\n",
        "        )\n",
        "        self.key = tf.keras.layers.Dense(\n",
        "            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"key\"\n",
        "        )\n",
        "        self.value = tf.keras.layers.Dense(\n",
        "            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"value\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, tensor: tf.Tensor, batch_size: int, q_sen: int) -> tf.Tensor:\n",
        "        # Reshape from [batch_size,  q_sen, sen_length, all_head_size] to [batch_size, q_sen, sen_length, num_attention_heads, attention_head_size]\n",
        "        tensor = tf.reshape(tensor=tensor, shape=(batch_size, q_sen, -1, self.num_attention_heads, self.attention_head_size))\n",
        "\n",
        "        # Transpose the tensor from [batch_size, q_sen, sen_length, num_attention_heads, attention_head_size] to [batch_size, q_sen, num_attention_heads, sen_length, attention_head_size]\n",
        "        return tf.transpose(tensor, perm=[0, 1, 3, 2, 4])\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_states: tf.Tensor,\n",
        "        attention_mask: tf.Tensor,\n",
        "        head_mask: tf.Tensor,\n",
        "        output_attentions: bool,\n",
        "        training: bool = False,\n",
        "    ) -> Tuple[tf.Tensor]:\n",
        "        batch_size, q_sen, q_length, dim = shape_list(hidden_states)\n",
        "        mixed_query_layer = self.query(inputs=hidden_states)\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(inputs=hidden_states), batch_size, q_sen)\n",
        "        value_layer = self.transpose_for_scores(self.value(inputs=hidden_states), batch_size, q_sen)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer, batch_size, q_sen)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        # (batch size, num_heads, sen_len_q, sen_len_k)\n",
        "        attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n",
        "        dk = tf.cast(self.sqrt_att_head_size, dtype=attention_scores.dtype)\n",
        "        attention_scores = tf.divide(attention_scores, dk)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in TFLNLFBertModel call() function)\n",
        "            attention_scores = tf.add(attention_scores, attention_mask)\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = stable_softmax(logits=attention_scores, axis=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(inputs=attention_probs, training=training)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = tf.multiply(attention_probs, head_mask)\n",
        "\n",
        "        attention_output = tf.matmul(attention_probs, value_layer)\n",
        "        attention_output = tf.transpose(attention_output, perm=[0, 1, 3, 2, 4])\n",
        "\n",
        "        # (batch_size, sen_len_q, all_head_size)\n",
        "        attention_output = tf.reshape(tensor=attention_output, shape=(batch_size, q_sen, -1, self.all_head_size))\n",
        "        outputs = (attention_output, attention_probs) if output_attentions else (attention_output,)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJbStHgkKNQb"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenSelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number \"\n",
        "                f\"of attention heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "        self.sqrt_att_head_size = math.sqrt(self.attention_head_size)\n",
        "\n",
        "        self.query = tf.keras.layers.Dense(\n",
        "            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"query\"\n",
        "        )\n",
        "        self.key = tf.keras.layers.Dense(\n",
        "            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"key\"\n",
        "        )\n",
        "        self.value = tf.keras.layers.Dense(\n",
        "            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"value\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, tensor: tf.Tensor, batch_size: int) -> tf.Tensor:\n",
        "        # Reshape from [batch_size, doc_length, all_head_size] to [batch_size, doc_length, num_attention_heads, attention_head_size]\n",
        "        tensor = tf.reshape(tensor=tensor, shape=(batch_size, -1, self.num_attention_heads, self.attention_head_size))\n",
        "\n",
        "        # Transpose the tensor from [batch_size, doc_length, num_attention_heads, attention_head_size] to [batch_size, num_attention_heads, doc_length, attention_head_size]\n",
        "        return tf.transpose(tensor, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_states: tf.Tensor,\n",
        "        attention_mask: tf.Tensor,\n",
        "        head_mask: tf.Tensor,\n",
        "        output_attentions: bool,\n",
        "        training: bool = False,\n",
        "    ) -> Tuple[tf.Tensor]:\n",
        "        batch_size = shape_list(hidden_states)[0]\n",
        "        mixed_query_layer = self.query(inputs=hidden_states)\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(inputs=hidden_states), batch_size)\n",
        "        value_layer = self.transpose_for_scores(self.value(inputs=hidden_states), batch_size)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer, batch_size)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        # (batch size, num_heads, sen_len_q, sen_len_k)\n",
        "        attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n",
        "        dk = tf.cast(self.sqrt_att_head_size, dtype=attention_scores.dtype)\n",
        "        attention_scores = tf.divide(attention_scores, dk)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in TFRobertaModel call() function)\n",
        "            attention_scores = tf.add(attention_scores, attention_mask)\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = stable_softmax(logits=attention_scores, axis=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(inputs=attention_probs, training=training)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = tf.multiply(attention_probs, head_mask)\n",
        "\n",
        "        attention_output = tf.matmul(attention_probs, value_layer)\n",
        "        attention_output = tf.transpose(attention_output, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # (batch_size, sen_len_q, all_head_size)\n",
        "        attention_output = tf.reshape(tensor=attention_output, shape=(batch_size, -1, self.all_head_size))\n",
        "        outputs = (attention_output, attention_probs) if output_attentions else (attention_output,)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRTM9-Em98NX"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordSelfOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor, input_tensor: tf.Tensor, training: bool = False) -> tf.Tensor:\n",
        "        hidden_states = self.dense(inputs=hidden_states)\n",
        "        hidden_states = self.dropout(inputs=hidden_states, training=training)\n",
        "        hidden_states = hidden_states + input_tensor\n",
        "\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj6bny_6OOrU"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenSelfOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor, input_tensor: tf.Tensor, training: bool = False) -> tf.Tensor:\n",
        "        hidden_states = self.dense(inputs=hidden_states)\n",
        "        hidden_states = self.dropout(inputs=hidden_states, training=training)\n",
        "        hidden_states = hidden_states + input_tensor\n",
        "\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMMPIuonO4Et"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.self_attention = TFLNLFBertWordSelfAttention(config, name=\"self\")\n",
        "        self.dense_output = TFLNLFBertWordSelfOutput(config, name=\"output\")\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n",
        "\n",
        "    def prune_heads(self, heads):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        input_tensor: tf.Tensor,\n",
        "        attention_mask: tf.Tensor,\n",
        "        head_mask: tf.Tensor,\n",
        "        output_attentions: bool,\n",
        "        training: bool = False,\n",
        "    ) -> Tuple[tf.Tensor]:\n",
        "        hidden_states = self.LayerNorm(inputs=input_tensor)\n",
        "        self_outputs = self.self_attention(\n",
        "            hidden_states=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            training=training,\n",
        "        )\n",
        "        attention_output = self.dense_output(\n",
        "            hidden_states=self_outputs[0], input_tensor=input_tensor, training=training\n",
        "        )\n",
        "        # add attentions (possibly with past_key_value) if we output them\n",
        "        outputs = (attention_output,) + self_outputs[1:]\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saj3PebrO6fB"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.self_attention = TFLNLFBertSenSelfAttention(config, name=\"self\")\n",
        "        self.dense_output = TFLNLFBertSenSelfOutput(config, name=\"output\")\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n",
        "\n",
        "    def prune_heads(self, heads):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        input_tensor: tf.Tensor,\n",
        "        attention_mask: tf.Tensor,\n",
        "        head_mask: tf.Tensor,\n",
        "        output_attentions: bool,\n",
        "        training: bool = False,\n",
        "    ) -> Tuple[tf.Tensor]:\n",
        "        hidden_states = self.LayerNorm(inputs=input_tensor)\n",
        "        self_outputs = self.self_attention(\n",
        "            hidden_states=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            training=training,\n",
        "        )\n",
        "        attention_output = self.dense_output(\n",
        "            hidden_states=self_outputs[0], input_tensor=input_tensor, training=training\n",
        "        )\n",
        "        # add attentions (possibly with past_key_value) if we output them\n",
        "        outputs = (attention_output,) + self_outputs[1:]\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcgic-jBO_wH"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordIntermediate(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.intermediate_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n",
        "        )\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = get_tf_activation(config.hidden_act)\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor) -> tf.Tensor:\n",
        "        hidden_states = self.LayerNorm(inputs=hidden_states)\n",
        "        hidden_states = self.dense(inputs=hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "\n",
        "        return hidden_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqRk2YrBPB0Z"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenIntermediate(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.intermediate_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n",
        "        )\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = get_tf_activation(config.hidden_act)\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor) -> tf.Tensor:\n",
        "        hidden_states = self.LayerNorm(inputs=hidden_states)\n",
        "        hidden_states = self.dense(inputs=hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "\n",
        "        return hidden_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h76LcytwPGCT"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor, input_tensor: tf.Tensor, training: bool = False) -> tf.Tensor:\n",
        "        hidden_states = self.dense(inputs=hidden_states)\n",
        "        hidden_states = self.dropout(inputs=hidden_states, training=training)\n",
        "        hidden_states = hidden_states + input_tensor\n",
        "\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8E7obLcPIxO"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenOutput(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            units=config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n",
        "\n",
        "    def call(self, hidden_states: tf.Tensor, input_tensor: tf.Tensor, training: bool = False) -> tf.Tensor:\n",
        "        hidden_states = self.dense(inputs=hidden_states)\n",
        "        hidden_states = self.dropout(inputs=hidden_states, training=training)\n",
        "        hidden_states = hidden_states + input_tensor\n",
        "\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qMeKWC4PNJ5"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertWordLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.attention = TFLNLFBertWordAttention(config, name=\"attention\")\n",
        "        self.intermediate = TFLNLFBertWordIntermediate(config, name=\"intermediate\")\n",
        "        self.bert_output = TFLNLFBertWordOutput(config, name=\"output\")\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_states: tf.Tensor,\n",
        "        attention_mask: tf.Tensor,\n",
        "        head_mask: tf.Tensor,\n",
        "        output_attentions: bool,\n",
        "        training: bool = False,\n",
        "    ) -> Tuple[tf.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attention_outputs = self.attention(\n",
        "            input_tensor=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            training=training,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "\n",
        "        # if decoder, the last output is tuple of self-attn cache\n",
        "        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
        "\n",
        "        intermediate_output = self.intermediate(hidden_states=attention_output)\n",
        "        layer_output = self.bert_output(\n",
        "            hidden_states=intermediate_output, input_tensor=attention_output, training=training\n",
        "        )\n",
        "        outputs = (layer_output,) + outputs  # add attentions if we output them\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwxiVBdXPf5g"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertSenLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.attention = TFLNLFBertSenAttention(config, name=\"attention\")\n",
        "        self.intermediate = TFLNLFBertSenIntermediate(config, name=\"intermediate\")\n",
        "        self.bert_output = TFLNLFBertSenOutput(config, name=\"output\")\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_states: tf.Tensor,\n",
        "        attention_mask: tf.Tensor,\n",
        "        head_mask: tf.Tensor,\n",
        "        output_attentions: bool,\n",
        "        training: bool = False,\n",
        "    ) -> Tuple[tf.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attention_outputs = self.attention(\n",
        "            input_tensor=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            training=training,\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "\n",
        "        # if decoder, the last output is tuple of self-attn cache\n",
        "        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
        "\n",
        "        intermediate_output = self.intermediate(hidden_states=attention_output)\n",
        "        layer_output = self.bert_output(\n",
        "            hidden_states=intermediate_output, input_tensor=attention_output, training=training\n",
        "        )\n",
        "        outputs = (layer_output,) + outputs  # add attentions if we output them\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcaHj4iQB4Qa"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TFSenBaseModelOutput(ModelOutput):\n",
        "    \"\"\"\n",
        "    Base class for model's outputs, with potential hidden states and attentions.\n",
        "\n",
        "    Args:\n",
        "        last_hidden_state (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`):\n",
        "            Sequence of hidden-states at the output of the last layer of the model.\n",
        "        hidden_states (`tuple(tf.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
        "            Tuple of `tf.Tensor` (one for the output of the embeddings + one for the output of each layer) of shape\n",
        "            `(batch_size, sequence_length, hidden_size)`.\n",
        "\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n",
        "            Tuple of `tf.Tensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
        "            sequence_length)`.\n",
        "\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
        "            heads.\n",
        "    \"\"\"\n",
        "    last_hidden_state: tf.Tensor = None\n",
        "    last_sen_hidden_states: tf.Tensor = None\n",
        "    last_first_sen_hidden_states: tf.Tensor = None\n",
        "    hidden_states: Tuple[tf.Tensor] | None = None\n",
        "    sen_hidden_states: Tuple[tf.Tensor] | None = None\n",
        "    attentions: Tuple[tf.Tensor] | None = None\n",
        "    sen_attentions: Tuple[tf.Tensor] | None = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrqbNhwVPo8r"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.config = config\n",
        "        self.word_layer = [TFLNLFBertWordLayer(config, name=f\"layer_._{i}\") for i in range(config.num_hidden_layers - 1)]\n",
        "        self.sen_layer = [TFLNLFBertSenLayer(config, name=f\"sen_layer_._{i}\") for i in range(config.num_hidden_layers - 1)]\n",
        "        self.concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
        "        self.sen_concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_states: tf.Tensor,\n",
        "        attention_mask: tf.Tensor,\n",
        "        head_mask: tf.Tensor,\n",
        "        sen_hidden_states: tf.Tensor,\n",
        "        first_sen_hidden_states: tf.Tensor,\n",
        "        sen_attention_mask: tf.Tensor,\n",
        "        sen_head_mask: tf.Tensor,\n",
        "        output_attentions: bool,\n",
        "        output_hidden_states: bool,\n",
        "        return_dict: bool,\n",
        "        training: bool = False,\n",
        "    ) -> Union[TFSenBaseModelOutput, Tuple[tf.Tensor]]:\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_sen_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "        all_sen_attentions = () if output_attentions else None\n",
        "\n",
        "        for i, (word_layer_module, sen_layer_module) in enumerate(zip(self.word_layer, self.sen_layer)):\n",
        "            if output_hidden_states:\n",
        "                all_sen_hidden_states = all_sen_hidden_states + (sen_hidden_states,)\n",
        "\n",
        "            sen_hidden_states = self.sen_concat_layer([tf.expand_dims(first_sen_hidden_states, axis=1), sen_hidden_states])\n",
        "\n",
        "            layer_outputs = sen_layer_module(\n",
        "                hidden_states=sen_hidden_states,\n",
        "                attention_mask=sen_attention_mask,\n",
        "                head_mask=sen_head_mask[i],\n",
        "                output_attentions=output_attentions,\n",
        "                training=training,\n",
        "            )\n",
        "            sen_hidden_states = layer_outputs[0]\n",
        "            first_sen_hidden_states = sen_hidden_states[:, 0]\n",
        "            sen_hidden_states = sen_hidden_states[:, 1:]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_sen_attentions = all_sen_attentions + (layer_outputs[2],)\n",
        "\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            hidden_states = hidden_states[:, :, 1:]\n",
        "            hidden_states = self.concat_layer([tf.expand_dims(sen_hidden_states, axis=2), hidden_states])\n",
        "\n",
        "            layer_outputs = word_layer_module(\n",
        "                hidden_states=hidden_states,\n",
        "                attention_mask=attention_mask,\n",
        "                head_mask=head_mask[i],\n",
        "                output_attentions=output_attentions,\n",
        "                training=training,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "            sen_hidden_states = hidden_states[:, :, 0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "\n",
        "\n",
        "        # Add last layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v for v in [hidden_states, sen_hidden_states, all_hidden_states, all_attentions, None] if v is not None\n",
        "            )\n",
        "\n",
        "        return TFSenBaseModelOutput(\n",
        "            last_hidden_state=hidden_states,\n",
        "            last_sen_hidden_states=sen_hidden_states,\n",
        "            last_first_sen_hidden_states=first_sen_hidden_states,\n",
        "            hidden_states=all_hidden_states,\n",
        "            sen_hidden_states=all_sen_hidden_states,\n",
        "            attentions=all_attentions,\n",
        "            sen_attentions=all_sen_attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0L4ZgDhMJcO"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertEmbeddings(tf.keras.layers.Layer):\n",
        "    def __init__(self, config: LNLFBertConfig, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.config = config\n",
        "        self.word_embeddings = TFLNLFBertWordEmbeddings(config, name=\"word_embeddings\")\n",
        "        self.word_layer = TFLNLFBertWordLayer(config, name=\"word_layer\")\n",
        "        self.sen_embeddings = TFLNLFBertSenEmbeddings(config, name=\"sen_embeddings\")\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        position_ids=None,\n",
        "        token_type_ids=None,\n",
        "        inputs_embeds=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        sen_position_ids=None,\n",
        "        sen_token_type_ids=None,\n",
        "        training=False,\n",
        "    ):\n",
        "        embedding_output = self.word_embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            training=training,\n",
        "        )\n",
        "        layer_outputs = self.word_layer(\n",
        "            hidden_states=embedding_output,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=False,\n",
        "            training=training,\n",
        "        )\n",
        "        hidden_states = layer_outputs[0]\n",
        "        outputs = self.sen_embeddings(\n",
        "            position_ids=sen_position_ids,\n",
        "            token_type_ids=sen_token_type_ids,\n",
        "            inputs_embeds=hidden_states[:,:,0],\n",
        "            training=training,\n",
        "        )\n",
        "        sen_hidden_states=outputs\n",
        "        first_sen_hidden_states=sen_hidden_states[:, 0]\n",
        "        sen_hidden_states=sen_hidden_states[:, 1:]\n",
        "        return (hidden_states, sen_hidden_states, first_sen_hidden_states)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ltFXS7XNPVT"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TFLNLFBertBaseModelOutputWithPooling(ModelOutput):\n",
        "    \"\"\"\n",
        "    Base class for model's outputs that also contains a pooling of the last hidden states.\n",
        "\n",
        "    Args:\n",
        "        last_hidden_state (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`):\n",
        "            Sequence of hidden-states at the output of the last layer of the model.\n",
        "        pooler_output (`tf.Tensor` of shape `(batch_size, hidden_size)`):\n",
        "            Last layer hidden-state of the first token of the sequence (classification token) further processed by a\n",
        "            Linear layer and a Tanh activation function. The Linear layer weights are trained from the next sentence\n",
        "            prediction (classification) objective during pretraining.\n",
        "\n",
        "            This output is usually *not* a good summary of the semantic content of the input, you're often better with\n",
        "            averaging or pooling the sequence of hidden-states for the whole input sequence.\n",
        "        hidden_states (`tuple(tf.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
        "            Tuple of `tf.Tensor` (one for the output of the embeddings + one for the output of each layer) of shape\n",
        "            `(batch_size, sequence_length, hidden_size)`.\n",
        "\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        attentions (`tuple(tf.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n",
        "            Tuple of `tf.Tensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
        "            sequence_length)`.\n",
        "\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
        "            heads.\n",
        "    \"\"\"\n",
        "    last_hidden_state: tf.Tensor = None\n",
        "    pooler_output: tf.Tensor = None\n",
        "    last_sen_hidden_states: tf.Tensor = None\n",
        "    last_first_sen_hidden_states: tf.Tensor = None\n",
        "    hidden_states: Tuple[tf.Tensor] | None = None\n",
        "    sen_hidden_states: Tuple[tf.Tensor] | None = None\n",
        "    attentions: Tuple[tf.Tensor] | None = None\n",
        "    sen_attentions: Tuple[tf.Tensor] | None = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDiXNuG7SIiI"
      },
      "outputs": [],
      "source": [
        "@keras_serializable\n",
        "class TFLNLFBertMainLayer(tf.keras.layers.Layer):\n",
        "    config_class = LNLFBertConfig\n",
        "\n",
        "    def __init__(self, config, add_pooling_layer=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.config = config\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "        self.num_hidden_layers = config.num_hidden_layers\n",
        "        self.initializer_range = config.initializer_range\n",
        "        self.output_attentions = config.output_attentions\n",
        "        self.output_hidden_states = config.output_hidden_states\n",
        "        self.return_dict = config.use_return_dict\n",
        "        self.encoder = TFLNLFBertEncoder(config, name=\"encoder\")\n",
        "        self.pooler = TFLNLFBertSenPooler(config, name=\"pooler\") if add_pooling_layer else None\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n",
        "        # The embeddings must be the last declaration in order to follow the weights order\n",
        "        self.embeddings = TFLNLFBertEmbeddings(config, name=\"mix_embeddings\")\n",
        "\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer.get_input_embeddings\n",
        "    def get_input_embeddings(self) -> tf.keras.layers.Layer:\n",
        "        return self.embeddings\n",
        "\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer.set_input_embeddings\n",
        "    def set_input_embeddings(self, value: tf.Variable):\n",
        "        self.embeddings.weight = value\n",
        "        self.embeddings.vocab_size = shape_list(value)[0]\n",
        "\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer._prune_heads\n",
        "    def _prune_heads(self, heads_to_prune):\n",
        "        \"\"\"\n",
        "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
        "        class PreTrainedModel\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @unpack_inputs\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer.call\n",
        "    def call(\n",
        "        self,\n",
        "        input_ids: TFModelInputType | None = None,\n",
        "        attention_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_attention_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        token_type_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_token_type_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        position_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_position_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        head_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_head_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        inputs_embeds: np.ndarray | tf.Tensor | None = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "        training: bool = False,\n",
        "    ) -> Union[TFLNLFBertBaseModelOutputWithPooling, Tuple[tf.Tensor]]:\n",
        "        if not self.config.is_decoder:\n",
        "            use_cache = False\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = shape_list(input_ids)\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = shape_list(inputs_embeds)[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        batch_size, doc_length, sen_length = input_shape\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = tf.fill(dims=(batch_size, doc_length, sen_length), value=1)\n",
        "\n",
        "        if sen_attention_mask is None:\n",
        "            sen_attention_mask = tf.fill(dims=(batch_size, doc_length), value=1)\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = tf.fill(dims=input_shape, value=0)\n",
        "\n",
        "        if sen_token_type_ids is None:\n",
        "            sen_token_type_ids = tf.fill(dims=input_shape[:-1], value=0)\n",
        "\n",
        "        attention_mask_shape = shape_list(attention_mask)\n",
        "\n",
        "        mask_sen_length = sen_length\n",
        "\n",
        "        extended_attention_mask = tf.reshape(\n",
        "            attention_mask, (attention_mask_shape[0], attention_mask_shape[1], 1, 1, attention_mask_shape[2])\n",
        "        )\n",
        "\n",
        "        sen_attention_mask = tf.cast(sen_attention_mask, dtype=tf.float32)\n",
        "        cls_mask = tf.ones((shape_list(sen_attention_mask)[0], 1))\n",
        "\n",
        "        cls_mask = tf.cast(cls_mask, dtype=tf.float32)\n",
        "\n",
        "        sen_attention_mask = tf.concat([cls_mask, sen_attention_mask], 1)\n",
        "\n",
        "        sen_attention_mask_shape = shape_list(sen_attention_mask)\n",
        "\n",
        "        extended_sen_attention_mask = tf.reshape(\n",
        "            sen_attention_mask, (sen_attention_mask_shape[0], 1, 1, sen_attention_mask_shape[1])\n",
        "        )\n",
        "\n",
        "        extended_attention_mask = tf.cast(extended_attention_mask, dtype=tf.float32)\n",
        "        extended_sen_attention_mask = tf.cast(extended_sen_attention_mask, dtype=tf.float32)\n",
        "        one_cst = tf.constant(1.0, dtype=tf.float32)\n",
        "        ten_thousand_cst = tf.constant(-10000.0, dtype=tf.float32)\n",
        "        extended_attention_mask = tf.multiply(tf.subtract(one_cst, extended_attention_mask), ten_thousand_cst)\n",
        "        extended_sen_attention_mask = tf.multiply(tf.subtract(one_cst, extended_sen_attention_mask), ten_thousand_cst)\n",
        "\n",
        "        encoder_extended_attention_mask = None\n",
        "\n",
        "        if head_mask is not None:\n",
        "            raise NotImplementedError\n",
        "        else:\n",
        "            head_mask = [None] * self.config.num_hidden_layers\n",
        "            sen_head_mask = [None] * (self.config.num_hidden_layers - 1)\n",
        "\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            sen_position_ids=sen_position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            sen_token_type_ids=sen_token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask[0],\n",
        "            training=training,\n",
        "        )\n",
        "\n",
        "        encoder_outputs = self.encoder(\n",
        "            hidden_states=embedding_output[0],\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask[1:],\n",
        "            sen_hidden_states=embedding_output[1],\n",
        "            first_sen_hidden_states=embedding_output[2],\n",
        "            sen_attention_mask=extended_sen_attention_mask,\n",
        "            sen_head_mask=sen_head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "            training=training,\n",
        "        )\n",
        "\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        sequence_output = self.LayerNorm(sequence_output)\n",
        "        pooled_output = self.pooler(hidden_states=sequence_output) if self.pooler is not None else None\n",
        "\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                sequence_output,\n",
        "                pooled_output,\n",
        "            ) + encoder_outputs[1:]\n",
        "\n",
        "\n",
        "\n",
        "        return TFLNLFBertBaseModelOutputWithPooling(\n",
        "            last_hidden_state=sequence_output,\n",
        "            pooler_output=pooled_output,\n",
        "            last_sen_hidden_states=encoder_outputs.last_sen_hidden_states,\n",
        "            last_first_sen_hidden_states=encoder_outputs.last_first_sen_hidden_states,\n",
        "            hidden_states=encoder_outputs.hidden_states,\n",
        "            sen_hidden_states=encoder_outputs.sen_hidden_states,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "            sen_attentions=encoder_outputs.sen_attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYyEEbB1gFPn"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertPreTrainedModel(TFPreTrainedModel):\n",
        "    \"\"\"\n",
        "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
        "    models.\n",
        "    \"\"\"\n",
        "\n",
        "    config_class = LNLFBertConfig\n",
        "    base_model_prefix = \"lnlfbert\"\n",
        "\n",
        "    @property\n",
        "    def input_signature(self) -> Dict[str, tf.TensorSpec]:\n",
        "      model_inputs = list(inspect.signature(self.call).parameters)\n",
        "      sig = {}\n",
        "      for input_name in (\n",
        "              \"input_ids\",\n",
        "              \"attention_mask\",\n",
        "              \"decoder_input_ids\",\n",
        "              \"decoder_attention_mask\",\n",
        "          ):\n",
        "              if input_name in model_inputs:\n",
        "                  sig[input_name] = tf.TensorSpec([None] * 3, tf.int32, name=input_name)\n",
        "\n",
        "      for input_name in (\n",
        "              \"sen_token_type_ids\",\n",
        "              \"sen_attention_mask\",\n",
        "          ):\n",
        "              if input_name in model_inputs:\n",
        "                  sig[input_name] = tf.TensorSpec([None] * 2, tf.int32, name=input_name)\n",
        "\n",
        "      return sig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWOGfKk7l-aZ"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertClassificationHead(tf.keras.layers.Layer):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(self, config, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            config.hidden_size,\n",
        "            kernel_initializer=get_initializer(config.initializer_range),\n",
        "            activation=\"relu\",\n",
        "            name=\"dense\",\n",
        "        )\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = tf.keras.layers.Dropout(classifier_dropout)\n",
        "        self.out_proj = tf.keras.layers.Dense(\n",
        "            config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"out_proj\"\n",
        "        )\n",
        "\n",
        "    def call(self, features, training=False):\n",
        "        x = self.dropout(features, training=training)\n",
        "        x = self.dense(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        x = self.out_proj(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfGcXvdumJ93"
      },
      "outputs": [],
      "source": [
        "class TFLNLFBertLMHead(tf.keras.layers.Layer):\n",
        "    \"\"\"LNLFBert Head for masked language modeling.\"\"\"\n",
        "\n",
        "    def __init__(self, config, input_embeddings, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.config = config\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n",
        "        )\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"layer_norm\")\n",
        "        self.act = get_tf_activation(\"gelu\")\n",
        "\n",
        "        # The output weights are the same as the input embeddings, but there is\n",
        "        # an output-only bias for each token.\n",
        "        self.decoder = input_embeddings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bias = self.add_weight(shape=(self.config.vocab_size,), initializer=\"zeros\", trainable=True, name=\"bias\")\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.decoder\n",
        "\n",
        "    def set_output_embeddings(self, value):\n",
        "        self.decoder.weight = value\n",
        "        self.decoder.vocab_size = shape_list(value)[0]\n",
        "\n",
        "    def get_bias(self):\n",
        "        return {\"bias\": self.bias}\n",
        "\n",
        "    def set_bias(self, value):\n",
        "        self.bias = value[\"bias\"]\n",
        "        self.config.vocab_size = shape_list(value[\"bias\"])[0]\n",
        "\n",
        "    def call(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.act(hidden_states)\n",
        "        hidden_states = self.layer_norm(hidden_states)\n",
        "\n",
        "        # project back to size of vocabulary with bias\n",
        "        input_shape = shape_list(tensor=hidden_states)\n",
        "        doc_length = input_shape[1]\n",
        "        sen_length = input_shape[2]\n",
        "        hidden_states = tf.reshape(tensor=hidden_states, shape=[-1, self.hidden_size])\n",
        "        hidden_states = tf.matmul(a=hidden_states, b=self.decoder.weight, transpose_b=True)\n",
        "        hidden_states = tf.reshape(tensor=hidden_states, shape=[-1, doc_length, sen_length, self.config.vocab_size])\n",
        "        hidden_states = tf.nn.bias_add(value=hidden_states, bias=self.bias)\n",
        "\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4aSyEX2ipvS"
      },
      "outputs": [],
      "source": [
        "LNLFBERT_START_DOCSTRING = r\"\"\"\n",
        "\n",
        "    This model inherits from [`TFPreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
        "    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
        "    etc.)\n",
        "\n",
        "    This model is also a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) subclass. Use it\n",
        "    as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and\n",
        "    behavior.\n",
        "\n",
        "    <Tip>\n",
        "\n",
        "    TensorFlow models and layers in `transformers` accept two formats as input:\n",
        "\n",
        "    - having all inputs as keyword arguments (like PyTorch models), or\n",
        "    - having all inputs as a list, tuple or dict in the first positional argument.\n",
        "\n",
        "    The reason the second format is supported is that Keras methods prefer this format when passing inputs to models\n",
        "    and layers. Because of this support, when using methods like `model.fit()` things should \"just work\" for you - just\n",
        "    pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second\n",
        "    format outside of Keras methods like `fit()` and `predict()`, such as when creating your own layers or models with\n",
        "    the Keras `Functional` API, there are three possibilities you can use to gather all the input Tensors in the first\n",
        "    positional argument:\n",
        "\n",
        "    - a single Tensor with `input_ids` only and nothing else: `model(input_ids)`\n",
        "    - a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:\n",
        "    `model([input_ids, attention_mask])` or `model([input_ids, attention_mask, token_type_ids])`\n",
        "    - a dictionary with one or several input Tensors associated to the input names given in the docstring:\n",
        "    `model({\"input_ids\": input_ids, \"token_type_ids\": token_type_ids})`\n",
        "\n",
        "    Note that when creating models and layers with\n",
        "    [subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) then you don't need to worry\n",
        "    about any of this, as you can just pass inputs like you would to any other Python function!\n",
        "\n",
        "    </Tip>\n",
        "\n",
        "    Parameters:\n",
        "        config ([`LNLFBertConfig`]): Model configuration class with all the parameters of the\n",
        "            model. Initializing with a config file does not load the weights associated with the model, only the\n",
        "            configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
        "\"\"\"\n",
        "\n",
        "LNLFBERT_INPUTS_DOCSTRING = r\"\"\"\n",
        "    Args:\n",
        "        input_ids (`Numpy array` or `tf.Tensor` of shape `({0})`):\n",
        "            Indices of input sequence tokens in the vocabulary.\n",
        "\n",
        "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.__call__`] and\n",
        "            [`PreTrainedTokenizer.encode`] for details.\n",
        "\n",
        "            [What are input IDs?](../glossary#input-ids)\n",
        "        attention_mask (`Numpy array` or `tf.Tensor` of shape `({0})`, *optional*):\n",
        "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
        "\n",
        "            - 1 for tokens that are **not masked**,\n",
        "            - 0 for tokens that are **masked**.\n",
        "\n",
        "            [What are attention masks?](../glossary#attention-mask)\n",
        "        token_type_ids (`Numpy array` or `tf.Tensor` of shape `({0})`, *optional*):\n",
        "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n",
        "            1]`:\n",
        "\n",
        "            - 0 corresponds to a *sentence A* token,\n",
        "            - 1 corresponds to a *sentence B* token.\n",
        "\n",
        "            [What are token type IDs?](../glossary#token-type-ids)\n",
        "        position_ids (`Numpy array` or `tf.Tensor` of shape `({0})`, *optional*):\n",
        "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
        "            config.max_position_embeddings - 1]`.\n",
        "\n",
        "            [What are position IDs?](../glossary#position-ids)\n",
        "        head_mask (`Numpy array` or `tf.Tensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
        "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
        "\n",
        "            - 1 indicates the head is **not masked**,\n",
        "            - 0 indicates the head is **masked**.\n",
        "\n",
        "        inputs_embeds (`tf.Tensor` of shape `({0}, hidden_size)`, *optional*):\n",
        "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
        "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
        "            model's internal embedding lookup matrix.\n",
        "        output_attentions (`bool`, *optional*):\n",
        "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
        "            tensors for more detail. This argument can be used only in eager mode, in graph mode the value in the\n",
        "            config will be used instead.\n",
        "        output_hidden_states (`bool`, *optional*):\n",
        "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
        "            more detail. This argument can be used only in eager mode, in graph mode the value in the config will be\n",
        "            used instead.\n",
        "        return_dict (`bool`, *optional*):\n",
        "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple. This argument can be used in\n",
        "            eager mode, in graph mode the value will always be set to True.\n",
        "        training (`bool`, *optional*, defaults to `False`):\n",
        "            Whether or not to use the model in training mode (some modules like dropout modules have different\n",
        "            behaviors between training and evaluation).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIZW2G2BF2kd"
      },
      "outputs": [],
      "source": [
        "_CHECKPOINT_FOR_DOC = \"lnlfbert-base\"\n",
        "_CONFIG_FOR_DOC = \"LNLFBertConfig\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KPeDKm1m-Cz"
      },
      "outputs": [],
      "source": [
        "@add_start_docstrings(\"\"\"LNLFBert Model with a `language modeling` head on top.\"\"\", LNLFBERT_START_DOCSTRING)\n",
        "class TFLNLFBertForMaskedLM(TFLNLFBertPreTrainedModel, TFMaskedLanguageModelingLoss):\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\", r\"lm_head.decoder.weight\"]\n",
        "\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super().__init__(config, *inputs, **kwargs)\n",
        "\n",
        "        self.lnlfbert = TFLNLFBertMainLayer(config, add_pooling_layer=False, name=\"lnlfbert\")\n",
        "        self.lm_head = TFLNLFBertLMHead(config, self.lnlfbert.embeddings.word_embeddings, name=\"lm_head\")\n",
        "\n",
        "    def get_lm_head(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def get_prefix_bias_name(self):\n",
        "        warnings.warn(\"The method get_prefix_bias_name is deprecated. Please use `get_bias` instead.\", FutureWarning)\n",
        "        return self.name + \"/\" + self.lm_head.name\n",
        "\n",
        "    def hf_compute_loss(self, labels, logits):\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
        "        )\n",
        "        if self.config.tf_legacy_loss:\n",
        "            # make sure only labels that are not equal to -100 affect the loss\n",
        "            active_loss = tf.not_equal(tf.reshape(labels, (-1,)), -100)\n",
        "            reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[-1])), active_loss)\n",
        "            labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n",
        "            return loss_fn(labels, reduced_logits)\n",
        "\n",
        "        # Clip negative labels to zero here to avoid NaNs and errors - those positions will get masked later anyway\n",
        "        inputs_shape = shape_list(logits)\n",
        "        new_labels_shape = (inputs_shape[0], -1)\n",
        "        new_logits_shape = (inputs_shape[0], -1, inputs_shape[-1])\n",
        "        labels = tf.reshape(labels, new_labels_shape)\n",
        "        logits = tf.reshape(logits, new_logits_shape)\n",
        "        unmasked_loss = loss_fn(tf.nn.relu(labels), logits)\n",
        "        # make sure only labels that are not equal to -100 affect the loss\n",
        "        loss_mask = tf.cast(labels != -100, dtype=unmasked_loss.dtype)\n",
        "        masked_loss = unmasked_loss * loss_mask\n",
        "        sum_loss_mask = tf.reduce_sum(loss_mask)\n",
        "        reduced_masked_loss = tf.where(\n",
        "                                tf.reshape(tf.math.greater_equal(sum_loss_mask, 0.001), (1,)),\n",
        "                                tf.reshape(tf.reduce_sum(masked_loss)/sum_loss_mask, (1,)),\n",
        "                                tf.cast(tf.fill([1], 0.), dtype=unmasked_loss.dtype)\n",
        "                              )\n",
        "        return tf.reshape(reduced_masked_loss, (1,))\n",
        "\n",
        "    @unpack_inputs\n",
        "    @add_start_docstrings_to_model_forward(LNLFBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
        "    @add_code_sample_docstrings(\n",
        "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
        "        output_type=TFMaskedLMOutput,\n",
        "        config_class=_CONFIG_FOR_DOC,\n",
        "        mask=\"<mask>\",\n",
        "        expected_output=\"' Paris'\",\n",
        "        expected_loss=0.1,\n",
        "    )\n",
        "    def call(\n",
        "        self,\n",
        "        input_ids: TFModelInputType | None = None,\n",
        "        attention_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_attention_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        token_type_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_token_type_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        position_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_position_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        head_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_head_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        inputs_embeds: np.ndarray | tf.Tensor | None = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "        labels: np.ndarray | tf.Tensor | None = None,\n",
        "        training: Optional[bool] = False,\n",
        "    ) -> Union[TFMaskedLMOutput, Tuple[tf.Tensor]]:\n",
        "        r\"\"\"\n",
        "        labels (`tf.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\n",
        "            config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\n",
        "            loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
        "        \"\"\"\n",
        "        outputs = self.lnlfbert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            sen_attention_mask=sen_attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            sen_token_type_ids=sen_token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            sen_position_ids=sen_position_ids,\n",
        "            head_mask=head_mask,\n",
        "            sen_head_mask=sen_head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "            training=training,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        prediction_scores = self.lm_head(sequence_output)\n",
        "\n",
        "        loss = None if labels is None else self.hf_compute_loss(labels, prediction_scores)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (prediction_scores,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return TFMaskedLMOutput(\n",
        "            loss=loss,\n",
        "            logits=prediction_scores,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpNZ8c-jkBas"
      },
      "outputs": [],
      "source": [
        "@add_start_docstrings(\n",
        "    \"\"\"\n",
        "    LNLFBert Model transformer with a sequence classification/regression head on top (a linear layer on top of the\n",
        "    pooled output) e.g. for GLUE tasks.\n",
        "    \"\"\",\n",
        "    LNLFBERT_START_DOCSTRING,\n",
        ")\n",
        "class TFLNLFBertForSequenceClassification(TFLNLFBertPreTrainedModel, TFSequenceClassificationLoss):\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\", r\"lm_head\"]\n",
        "\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super().__init__(config, *inputs, **kwargs)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.lnlfbert = TFLNLFBertMainLayer(config, add_pooling_layer=False, name=\"lnlfbert\")\n",
        "        self.classifier = TFLNLFBertClassificationHead(config, name=\"classifier\")\n",
        "\n",
        "    @unpack_inputs\n",
        "    @add_start_docstrings_to_model_forward(LNLFBERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
        "    @add_code_sample_docstrings(\n",
        "        checkpoint=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
        "        output_type=TFSequenceClassifierOutput,\n",
        "        config_class=_CONFIG_FOR_DOC,\n",
        "        expected_output=\"'optimism'\",\n",
        "        expected_loss=0.08,\n",
        "    )\n",
        "    def call(\n",
        "        self,\n",
        "        input_ids: TFModelInputType | None = None,\n",
        "        attention_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_attention_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        token_type_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_token_type_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        position_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_position_ids: np.ndarray | tf.Tensor | None = None,\n",
        "        head_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        sen_head_mask: np.ndarray | tf.Tensor | None = None,\n",
        "        inputs_embeds: np.ndarray | tf.Tensor | None = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "        labels: np.ndarray | tf.Tensor | None = None,\n",
        "        training: Optional[bool] = False,\n",
        "    ) -> Union[TFSequenceClassifierOutput, Tuple[tf.Tensor]]:\n",
        "        r\"\"\"\n",
        "        labels (`tf.Tensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        outputs = self.lnlfbert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            sen_attention_mask=sen_attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            sen_token_type_ids=sen_token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            sen_position_ids=sen_position_ids,\n",
        "            head_mask=head_mask,\n",
        "            sen_head_mask=sen_head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "            training=training,\n",
        "        )\n",
        "        #print(\"outputs: \", outputs)\n",
        "        sequence_output = outputs.last_sen_hidden_states\n",
        "        logits = self.classifier(sequence_output, training=training)\n",
        "\n",
        "        loss = None if labels is None else self.hf_compute_loss(labels, logits)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return TFSequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "87527199bbcf4ea28eebc1c9db485b64",
            "592a56a5a4264841aa44745837c74bd9",
            "621414f689204c4495a60b140ad46568",
            "8b4f82ed801b40fba964480d4a663b1d",
            "696e91900e574feda751e558ee897913",
            "1afb9ded326e4dd6ba180f0b9a76af19",
            "c759a4373a674d978f39b8873209b95c",
            "046371c07e7d4adb968e0e3f00ac2ca9",
            "6fab79cdb34145b58eb00ed5eaa92aee",
            "c06ef61ebdf246379110074c3f9ca398",
            "9ed43c25ba3149f5a09a1bbcaf0dfabf"
          ]
        },
        "id": "JNjnsp0mrAdm",
        "outputId": "8d13e946-7c2f-495e-9ba2-20f193af59b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87527199bbcf4ea28eebc1c9db485b64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "config = LNLFBertConfig.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "ccc563353b494157b3badda1d690a316",
            "7e1d5f46de9c453a9842f1484dd65e26",
            "6af6167d5fc1405b89ae85e0e139ffac",
            "8663529208b64f3c8b34ed55daeea1f4",
            "63991ec40d6d4dc2be72ad310d253b90",
            "ec84d17fd3494f48aaa0120cae6c60a0",
            "2ba6b69cb801434b8788485e5fe86bb1",
            "c82cd7b1be234c07a7fa1ac376bc938c",
            "5a749e911f184b979dd200227d132b6a",
            "a2a8f60fc0784956b6dbb495f0c2adb5",
            "c038d0d672b942e1a28b0b8d03b84596",
            "1d41475641034ebb95fed0a0c70fc46d",
            "03cdee58949a4f65bc111a8652a1be34",
            "76dadb29475c4d3bb129efe22c0258c0",
            "ac9ab02472bb44c88d17171785b4f566",
            "9d3e07f9e6b24c6a88a43f3a98ceca56",
            "576f9394c3a546f3afb0d8d16c65007a",
            "f1940ff80b9b48e8b6480719a61c594e",
            "531fea23dda040d18965222868a7e5b6",
            "f7380217ef7b4ca0b175b8d04d2fe62c",
            "294489eab3e5480c8c5b53bb0360cd5d",
            "3640a9d91470474eb6db0aaa37337b5f",
            "6ddb6ddda4694d01868d60ff09293ca0",
            "0f442d39fd6a4734af00bb79c1e0e6cb",
            "ee5c5ae9fc074c30a7630744c61ebd43",
            "c4e4007498034658ad17958526a4d604",
            "f911cb0b7f5845499ad603a5b616cb2f",
            "683fc9e594aa4e2b8767f57d53ed4be9",
            "4462b116525e4562aade75b64328400c",
            "7ff4c6a022534f35857481b65cfce50b",
            "b634b00d88b7419a9885a9dd3a4d28ff",
            "c4caf2143d1c442f83630b6919e5be10",
            "499a9e2f122344db8bbcc98be10b2c8f",
            "6488b857ccef4e14a68a7c9431ed8d47",
            "51e3b6cf6d6c4c31a213852f0c119dae",
            "449b8430de164bc4b37c7b87e38179a1",
            "9a514e6c3a54490e95eb7cbbd656d85f",
            "f74303cb677c4031a70dbb93ae9e8ec8",
            "f33e066edde1445182a839f61e6099a5",
            "e13c4cc96d9a40a8acd3d1d8fa7beb37",
            "e20b5c10fac1437e8fc581ce51ad3e46",
            "ab616d6973834d469c8269cb69baf582",
            "8515c1ec3b9d4ea59ce792d1e5922248",
            "92b2aba711bd4f34a196ca6790945b25"
          ]
        },
        "id": "1JcQIpy_GOYW",
        "outputId": "31b06a88-f5d0-46cc-9c88-57d922ba7750"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccc563353b494157b3badda1d690a316",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d41475641034ebb95fed0a0c70fc46d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ddb6ddda4694d01868d60ff09293ca0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6488b857ccef4e14a68a7c9431ed8d47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, RobertaTokenizerFast\n",
        "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ccEjFVIsUBf",
        "outputId": "e6b34377-de9d-4143-ee0c-f22d064d7100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fs_DAzcsSi_",
        "outputId": "3a764c43-1742-4eec-a9db-20ce47e889d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlaVTh0lsP2q"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Mapping, Sized\n",
        "from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, Optional, Sequence, Tuple, Union\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers.utils import (\n",
        "    ExplicitEnum,\n",
        "    PaddingStrategy,\n",
        "    PushToHubMixin,\n",
        "    TensorType,\n",
        "    add_end_docstrings,\n",
        "    add_model_info_to_auto_map,\n",
        "    cached_file,\n",
        "    copy_func,\n",
        "    download_url,\n",
        "    extract_commit_hash,\n",
        "    is_flax_available,\n",
        "    is_jax_tensor,\n",
        "    is_numpy_array,\n",
        "    is_offline_mode,\n",
        "    is_remote_url,\n",
        "    is_tf_available,\n",
        "    is_tf_tensor,\n",
        "    is_tokenizers_available,\n",
        "    is_torch_available,\n",
        "    is_torch_device,\n",
        "    is_torch_tensor,\n",
        "    logging,\n",
        "    requires_backends,\n",
        "    to_py_obj,\n",
        ")\n",
        "EncodedInput = List[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6AqQGOho1bD"
      },
      "outputs": [],
      "source": [
        "class LNLFBertTokenizer(RobertaTokenizerFast):\n",
        "\n",
        "  model_input_names: List[str] = [\"input_ids\", \"attention_mask\", \"sen_token_type_ids\", \"sen_attention_mask\", \"special_tokens_mask\"]\n",
        "\n",
        "  def __call__(self, texts, padding=False, return_tensors=None, multi_texts=False, order=None, truncation=False, max_length=None, max_sen_num=None, return_special_tokens_mask=None):\n",
        "    if padding:\n",
        "      return self.tokenizer_with_padding(\n",
        "          texts, return_tensors=return_tensors, multi_texts=multi_texts, order=order,\n",
        "          truncation=truncation, max_length=max_length, max_sen_num=max_sen_num, return_special_tokens_mask=return_special_tokens_mask)\n",
        "    else:\n",
        "      return self.tokenizer_without_padding(\n",
        "          texts, return_tensors=return_tensors, multi_texts=multi_texts, order=order,\n",
        "          truncation=truncation, max_length=max_length, max_sen_num=max_sen_num, return_special_tokens_mask=return_special_tokens_mask)\n",
        "\n",
        "  def tokenizer_without_padding(self, texts, return_tensors=None, multi_texts=False, order=None, truncation=False, max_length=None,\n",
        "                                max_sen_num=None, return_special_tokens_mask=None):\n",
        "    results = []\n",
        "    sents_len = []\n",
        "    sen_token_type_ids = []\n",
        "    sen_attention_mask = []\n",
        "\n",
        "    if multi_texts:\n",
        "      list_keys = order\n",
        "      for i in range(len(texts[list_keys[0]])):\n",
        "        tmp_sentences = []\n",
        "        #sen_attention_mask.append(1)\n",
        "        for key_name in list_keys:\n",
        "          text = texts[key_name][i]\n",
        "          if text is None:\n",
        "            text = ''\n",
        "          try:\n",
        "            sentences = nltk.sent_tokenize(text)\n",
        "          except:\n",
        "            print(\"An exception occurred: \",text)\n",
        "          if truncation and max_sen_num:\n",
        "            sen_len = min(len(sentences), max_sen_num[key_name])\n",
        "            sentences = sentences[0:sen_len]\n",
        "          tmp_sentences.extend(sentences)\n",
        "          for sentence in sentences:\n",
        "            results.append(sentence)\n",
        "            sen_token_type_ids.append(key_name)\n",
        "            if sentence:\n",
        "              sen_attention_mask.append(1)\n",
        "            else:\n",
        "              sen_attention_mask.append(0)\n",
        "        sents_len.append(len(tmp_sentences))\n",
        "      output = super().__call__(results, return_tensors=return_tensors, truncation=truncation,\n",
        "                                   max_length=max_length,return_special_tokens_mask=return_special_tokens_mask)\n",
        "      for key, value in output.items():\n",
        "        output[key] = self.set_sentence_len(value, sents_len)\n",
        "      output['sen_attention_mask'] = self.set_sentence_len(sen_attention_mask, sents_len)\n",
        "      output['sen_token_type_ids'] = self.set_sentence_len(sen_token_type_ids, sents_len)\n",
        "      return output\n",
        "    else:\n",
        "      for text in texts:\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "        if truncation and max_sen_num:\n",
        "          sen_len = min(len(sentences), max_sen_num)\n",
        "          sentences = sentences[0:sen_len]\n",
        "        sents_len.append(len(sentences))\n",
        "        for sentence in sentences:\n",
        "          results.append(sentence)\n",
        "          if sentence:\n",
        "            sen_attention_mask.append(1)\n",
        "          else:\n",
        "            sen_attention_mask.append(0)\n",
        "\n",
        "      output = super().__call__(results, return_tensors=return_tensors, truncation=truncation,\n",
        "                                   max_length=max_length, return_special_tokens_mask=return_special_tokens_mask)\n",
        "      for key, value in output.items():\n",
        "        output[key] = self.set_sentence_len(value, sents_len)\n",
        "      output['sen_attention_mask'] = self.set_sentence_len(sen_attention_mask, sents_len)\n",
        "      return output\n",
        "\n",
        "  def set_mask_sentence_len(self, inputs, sents_len):\n",
        "    output = []\n",
        "    start_index = 0\n",
        "    end_index = 0\n",
        "    inputs = inputs.copy()\n",
        "    for sent_len in sents_len:\n",
        "      end_index = start_index + sent_len + 1\n",
        "      output.append(inputs[start_index:end_index])\n",
        "      start_index = end_index\n",
        "    return output\n",
        "\n",
        "  def set_sentence_len(self, inputs, sents_len):\n",
        "    output = []\n",
        "    start_index = 0\n",
        "    end_index = 0\n",
        "    inputs = inputs.copy()\n",
        "    for sent_len in sents_len:\n",
        "      end_index = start_index + sent_len\n",
        "      output.append(inputs[start_index:end_index])\n",
        "      start_index = end_index\n",
        "    return output\n",
        "\n",
        "  def tokenizer_with_padding(self, texts, return_tensors=None, multi_texts=False, order=None,\n",
        "                             truncation=False, max_length=None, max_sen_num=None, return_special_tokens_mask=None):\n",
        "    max_len = 0\n",
        "    results = []\n",
        "    temp_results = []\n",
        "    temp_sen_token_type_ids = []\n",
        "    sen_token_type_ids = []\n",
        "    sen_attention_mask = []\n",
        "\n",
        "    if multi_texts:\n",
        "      list_keys = order\n",
        "      for i in range(len(texts[list_keys[0]])):\n",
        "        tmp_sentences = []\n",
        "        tmp_sen_tokens = []\n",
        "        for key_name in list_keys:\n",
        "          text = texts[key_name][i]\n",
        "          if text is None:\n",
        "            text = ''\n",
        "          try:\n",
        "            sentences = nltk.sent_tokenize(text)\n",
        "          except:\n",
        "            print(\"An exception occurred: \",text)\n",
        "          if truncation and max_sen_num:\n",
        "            sen_len = min(len(sentences), max_sen_num[key_name])\n",
        "            sentences = sentences[0:sen_len]\n",
        "          tmp_sentences.extend(sentences)\n",
        "          tmp_sen_tokens.extend([key_name] * len(sentences))\n",
        "        max_len = max(max_len, len(tmp_sentences))\n",
        "        temp_results.append(tmp_sentences)\n",
        "        temp_sen_token_type_ids.append(tmp_sen_tokens)\n",
        "      for sentences, sen_tokens in zip(temp_results, temp_sen_token_type_ids):\n",
        "        #if sen_token_type_id == list_keys[0]:\n",
        "          #sen_attention_mask.append(1)\n",
        "        while len(sentences) < max_len:\n",
        "          sentences.append(\"\")\n",
        "        for sentence, sen_token_type_id in zip(sentences, sen_tokens):\n",
        "          results.append(sentence)\n",
        "          sen_token_type_ids.append(sen_token_type_id)\n",
        "          if sentence:\n",
        "            sen_attention_mask.append(1)\n",
        "          else:\n",
        "            sen_attention_mask.append(0)\n",
        "\n",
        "      output = super().__call__(results, padding=True, return_tensors=return_tensors, truncation=truncation,\n",
        "                                   max_length=max_length, return_special_tokens_mask=return_special_tokens_mask)\n",
        "      for key, value in output.items():\n",
        "        output[key] = tf.reshape(value, [len(texts[list_keys[0]]), max_len, -1])\n",
        "      output['sen_attention_mask'] = tf.reshape(sen_attention_mask, [len(texts[list_keys[0]]), -1])\n",
        "      output['sen_token_type_ids'] = tf.reshape(sen_token_type_ids, [len(texts[list_keys[0]]), -1])\n",
        "      return output\n",
        "    else:\n",
        "      for text in texts:\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "        if truncation and max_sen_num:\n",
        "            sen_len = max(len(sentences), max_sen_num)\n",
        "        else:\n",
        "            sen_len = len(sentences)\n",
        "        max_len = max(max_len, sen_len)\n",
        "        temp_results.append(sentences[0:sen_len])\n",
        "      for sentences in temp_results:\n",
        "        while len(sentences) < max_len:\n",
        "          sentences.append(\"\")\n",
        "        for sentence in sentences:\n",
        "          results.append(sentence)\n",
        "          if sentence:\n",
        "            sen_attention_mask.append(1)\n",
        "          else:\n",
        "            sen_attention_mask.append(0)\n",
        "\n",
        "      output = super().__call__(results, padding=True, return_tensors=return_tensors, truncation=truncation,\n",
        "                                   max_length=max_length, return_special_tokens_mask=return_special_tokens_mask)\n",
        "      for key, value in output.items():\n",
        "        output[key] = tf.reshape(value, [len(texts), max_len, -1])\n",
        "      output['sen_attention_mask'] = tf.reshape(sen_attention_mask, [len(texts), -1])\n",
        "      return output\n",
        "\n",
        "  def pad(\n",
        "        self,\n",
        "        encoded_inputs: Union[\n",
        "            BatchEncoding,\n",
        "            List[BatchEncoding],\n",
        "            Dict[str, EncodedInput],\n",
        "            Dict[str, List[EncodedInput]],\n",
        "            List[Dict[str, EncodedInput]],\n",
        "        ],\n",
        "        padding: Union[bool, str, PaddingStrategy] = True,\n",
        "        max_length: Optional[int] = None,\n",
        "        pad_to_multiple_of: Optional[int] = None,\n",
        "        return_attention_mask: Optional[bool] = None,\n",
        "        return_tensors: Optional[Union[str, TensorType]] = None,\n",
        "        verbose: bool = True,\n",
        "    ) -> BatchEncoding:\n",
        "        \"\"\"\n",
        "        Pad a single encoded input or a batch of encoded inputs up to predefined length or to the max sequence length\n",
        "        in the batch.\n",
        "\n",
        "        Padding side (left/right) padding token ids are defined at the tokenizer level (with `self.padding_side`,\n",
        "        `self.pad_token_id` and `self.pad_token_type_id`).\n",
        "\n",
        "        Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the\n",
        "        text followed by a call to the `pad` method to get a padded encoding.\n",
        "\n",
        "        <Tip>\n",
        "\n",
        "        If the `encoded_inputs` passed are dictionary of numpy arrays, PyTorch tensors or TensorFlow tensors, the\n",
        "        result will use the same type unless you provide a different tensor type with `return_tensors`. In the case of\n",
        "        PyTorch tensors, you will lose the specific device of your tensors however.\n",
        "\n",
        "        </Tip>\n",
        "\n",
        "        Args:\n",
        "            encoded_inputs ([`BatchEncoding`], list of [`BatchEncoding`], `Dict[str, List[int]]`, `Dict[str, List[List[int]]` or `List[Dict[str, List[int]]]`):\n",
        "                Tokenized inputs. Can represent one input ([`BatchEncoding`] or `Dict[str, List[int]]`) or a batch of\n",
        "                tokenized inputs (list of [`BatchEncoding`], *Dict[str, List[List[int]]]* or *List[Dict[str,\n",
        "                List[int]]]*) so you can use this method during preprocessing as well as in a PyTorch Dataloader\n",
        "                collate function.\n",
        "\n",
        "                Instead of `List[int]` you can have tensors (numpy arrays, PyTorch tensors or TensorFlow tensors), see\n",
        "                the note above for the return type.\n",
        "            padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
        "                 Select a strategy to pad the returned sequences (according to the model's padding side and padding\n",
        "                 index) among:\n",
        "\n",
        "                - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
        "                  sequence if provided).\n",
        "                - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
        "                  acceptable input length for the model if that argument is not provided.\n",
        "                - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n",
        "                  lengths).\n",
        "            max_length (`int`, *optional*):\n",
        "                Maximum length of the returned list and optionally padding length (see above).\n",
        "            pad_to_multiple_of (`int`, *optional*):\n",
        "                If set will pad the sequence to a multiple of the provided value.\n",
        "\n",
        "                This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability\n",
        "                `>= 7.5` (Volta).\n",
        "            return_attention_mask (`bool`, *optional*):\n",
        "                Whether to return the attention mask. If left to the default, will return the attention mask according\n",
        "                to the specific tokenizer's default, defined by the `return_outputs` attribute.\n",
        "\n",
        "                [What are attention masks?](../glossary#attention-mask)\n",
        "            return_tensors (`str` or [`~utils.TensorType`], *optional*):\n",
        "                If set, will return tensors instead of list of python integers. Acceptable values are:\n",
        "\n",
        "                - `'tf'`: Return TensorFlow `tf.constant` objects.\n",
        "                - `'pt'`: Return PyTorch `torch.Tensor` objects.\n",
        "                - `'np'`: Return Numpy `np.ndarray` objects.\n",
        "            verbose (`bool`, *optional*, defaults to `True`):\n",
        "                Whether or not to print more information and warnings.\n",
        "        \"\"\"\n",
        "        if self.__class__.__name__.endswith(\"Fast\"):\n",
        "            if not self.deprecation_warnings.get(\"Asking-to-pad-a-fast-tokenizer\", False):\n",
        "                logger.warning_advice(\n",
        "                    f\"You're using a {self.__class__.__name__} tokenizer. Please note that with a fast tokenizer,\"\n",
        "                    \" using the `__call__` method is faster than using a method to encode the text followed by a call\"\n",
        "                    \" to the `pad` method to get a padded encoding.\"\n",
        "                )\n",
        "                self.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
        "\n",
        "        # If we have a list of dicts, let's convert it in a dict of lists\n",
        "        # We do this to allow using this method as a collate_fn function in PyTorch Dataloader\n",
        "        if isinstance(encoded_inputs, (list, tuple)) and isinstance(encoded_inputs[0], Mapping):\n",
        "            encoded_inputs = {key: [example[key] for example in encoded_inputs] for key in encoded_inputs[0].keys()}\n",
        "\n",
        "        # The model's main input name, usually `input_ids`, has be passed for padding\n",
        "        if self.model_input_names[0] not in encoded_inputs:\n",
        "            raise ValueError(\n",
        "                \"You should supply an encoding or a list of encodings to this method \"\n",
        "                f\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\n",
        "            )\n",
        "\n",
        "        required_input = encoded_inputs[self.model_input_names[0]]\n",
        "\n",
        "        if required_input is None or (isinstance(required_input, Sized) and len(required_input) == 0):\n",
        "            if return_attention_mask:\n",
        "                encoded_inputs[\"attention_mask\"] = []\n",
        "            return encoded_inputs\n",
        "\n",
        "        # If we have PyTorch/TF/NumPy tensors/arrays as inputs, we cast them as python objects\n",
        "        # and rebuild them afterwards if no return_tensors is specified\n",
        "        # Note that we lose the specific device the tensor may be on for PyTorch\n",
        "\n",
        "        first_element = required_input[0]\n",
        "        if isinstance(first_element, (list, tuple)):\n",
        "            # first_element might be an empty list/tuple in some edge cases so we grab the first non empty element.\n",
        "            for item in required_input:\n",
        "                if len(item) != 0:\n",
        "                    first_element = item[0]\n",
        "                    break\n",
        "        # At this state, if `first_element` is still a list/tuple, it's an empty one so there is nothing to do.\n",
        "        if not isinstance(first_element, (int, list, tuple)):\n",
        "            if is_tf_tensor(first_element):\n",
        "                return_tensors = \"tf\" if return_tensors is None else return_tensors\n",
        "            elif is_torch_tensor(first_element):\n",
        "                return_tensors = \"pt\" if return_tensors is None else return_tensors\n",
        "            elif isinstance(first_element, np.ndarray):\n",
        "                return_tensors = \"np\" if return_tensors is None else return_tensors\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\"type of {first_element} unknown: {type(first_element)}. \"\n",
        "                    \"Should be one of a python, numpy, pytorch or tensorflow object.\"\n",
        "                )\n",
        "\n",
        "            for key, value in encoded_inputs.items():\n",
        "                encoded_inputs[key] = to_py_obj(value)\n",
        "\n",
        "        # Convert padding_strategy in PaddingStrategy\n",
        "        padding_strategy, _, max_length, _ = super()._get_padding_truncation_strategies(\n",
        "            padding=padding, max_length=max_length, verbose=verbose\n",
        "        )\n",
        "\n",
        "        required_input = encoded_inputs[self.model_input_names[0]]\n",
        "        if required_input and not isinstance(required_input[0], (list, tuple)):\n",
        "            encoded_inputs = self._pad(\n",
        "                encoded_inputs,\n",
        "                max_length=max_length,\n",
        "                padding_strategy=padding_strategy,\n",
        "                pad_to_multiple_of=pad_to_multiple_of,\n",
        "                return_attention_mask=return_attention_mask,\n",
        "            )\n",
        "            return BatchEncoding(encoded_inputs, tensor_type=return_tensors)\n",
        "\n",
        "        batch_size = len(required_input)\n",
        "        assert all(\n",
        "            len(v) == batch_size for v in encoded_inputs.values()\n",
        "        ), \"Some items in the output dictionary have a different batch size than others.\"\n",
        "\n",
        "        if padding_strategy == PaddingStrategy.LONGEST:\n",
        "            max_sen_length = max(len(inputs) for inputs in required_input)\n",
        "            max_length = 0\n",
        "            for input in required_input:\n",
        "              max_length = max(max_length, max([len(x) for x in input], default=0))\n",
        "            padding_strategy = PaddingStrategy.MAX_LENGTH\n",
        "\n",
        "        batch_outputs = {}\n",
        "        for i in range(batch_size):\n",
        "            inputs = {k: v[i] for k, v in encoded_inputs.items()}\n",
        "            outputs = self._pad(\n",
        "                inputs,\n",
        "                max_length=max_length,\n",
        "                max_sen_length=max_sen_length,\n",
        "                padding_strategy=padding_strategy,\n",
        "                pad_to_multiple_of=pad_to_multiple_of,\n",
        "                return_attention_mask=return_attention_mask,\n",
        "            )\n",
        "\n",
        "            for key, value in outputs.items():\n",
        "                if key not in batch_outputs:\n",
        "                    batch_outputs[key] = []\n",
        "                batch_outputs[key].append(value)\n",
        "\n",
        "        return BatchEncoding(batch_outputs, tensor_type=return_tensors)\n",
        "\n",
        "  def _pad(\n",
        "      self,\n",
        "      encoded_inputs: Union[Dict[str, EncodedInput], BatchEncoding],\n",
        "      max_length: Optional[int] = None,\n",
        "      max_sen_length: Optional[int] = None,\n",
        "      padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "      pad_to_multiple_of: Optional[int] = None,\n",
        "      return_attention_mask: Optional[bool] = None,\n",
        "  ) -> dict:\n",
        "      \"\"\"\n",
        "      Pad encoded inputs (on left/right and up to predefined length or max length in the batch)\n",
        "\n",
        "      Args:\n",
        "          encoded_inputs:\n",
        "              Dictionary of tokenized inputs (`List[int]`) or batch of tokenized inputs (`List[List[int]]`).\n",
        "          max_length: maximum length of the returned list and optionally padding length (see below).\n",
        "              Will truncate by taking into account the special tokens.\n",
        "          padding_strategy: PaddingStrategy to use for padding.\n",
        "\n",
        "              - PaddingStrategy.LONGEST Pad to the longest sequence in the batch\n",
        "              - PaddingStrategy.MAX_LENGTH: Pad to the max length (default)\n",
        "              - PaddingStrategy.DO_NOT_PAD: Do not pad\n",
        "              The tokenizer padding sides are defined in self.padding_side:\n",
        "\n",
        "                  - 'left': pads on the left of the sequences\n",
        "                  - 'right': pads on the right of the sequences\n",
        "          pad_to_multiple_of: (optional) Integer if set will pad the sequence to a multiple of the provided value.\n",
        "              This is especially useful to enable the use of Tensor Core on NVIDIA hardware with compute capability\n",
        "              `>= 7.5` (Volta).\n",
        "          return_attention_mask:\n",
        "              (optional) Set to False to avoid returning attention mask (default: set to model specifics)\n",
        "      \"\"\"\n",
        "      # Load from model defaults\n",
        "      #print(encoded_inputs)\n",
        "      if return_attention_mask is None:\n",
        "          return_attention_mask = \"attention_mask\" in self.model_input_names\n",
        "\n",
        "      required_input = encoded_inputs[self.model_input_names[0]]\n",
        "\n",
        "      if padding_strategy == PaddingStrategy.LONGEST:\n",
        "          max_length = len(required_input)\n",
        "\n",
        "      if max_length is not None and pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
        "          max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
        "\n",
        "      needs_to_be_padded = padding_strategy != PaddingStrategy.DO_NOT_PAD\n",
        "\n",
        "      # Initialize attention mask if not present.\n",
        "      if return_attention_mask and \"attention_mask\" not in encoded_inputs:\n",
        "          encoded_inputs[\"attention_mask\"] = [1] * len(required_input)\n",
        "\n",
        "      if needs_to_be_padded:\n",
        "          sen_difference = max_sen_length - len(required_input)\n",
        "\n",
        "          if self.padding_side == \"right\":\n",
        "              if return_attention_mask:\n",
        "                  encoded_inputs[\"sen_attention_mask\"] = encoded_inputs[\"sen_attention_mask\"] + [0] * sen_difference\n",
        "              if \"sen_token_type_ids\" in encoded_inputs:\n",
        "                  encoded_inputs[\"sen_token_type_ids\"] = (\n",
        "                      encoded_inputs[\"sen_token_type_ids\"] + [self.pad_token_type_id] * sen_difference\n",
        "                  )\n",
        "              for i, input_ids in enumerate(encoded_inputs['input_ids']):\n",
        "                difference = max_length - len(input_ids)\n",
        "                if difference > 0:\n",
        "                  encoded_inputs['input_ids'][i] = np.append(encoded_inputs['input_ids'][i], [0] * difference)\n",
        "                  #encoded_inputs['token_type_ids'][i] = np.append(encoded_inputs['token_type_ids'][i], [self.pad_token_type_id] * difference)\n",
        "                  encoded_inputs['attention_mask'][i] = np.append(encoded_inputs['attention_mask'][i], [0] * difference)\n",
        "                  if \"special_tokens_mask\" in encoded_inputs:\n",
        "                    encoded_inputs[\"special_tokens_mask\"][i] = np.append(encoded_inputs[\"special_tokens_mask\"][i], [1] * difference)\n",
        "              if sen_difference > 0:\n",
        "                encoded_inputs['input_ids'] = encoded_inputs['input_ids'] + [[0] * max_length] * sen_difference\n",
        "                #encoded_inputs['token_type_ids'] = encoded_inputs['token_type_ids'] + [[self.pad_token_type_id] * max_length] * sen_difference\n",
        "                encoded_inputs['attention_mask'] = encoded_inputs['attention_mask'] + [[0] * max_length] * sen_difference\n",
        "                encoded_inputs[\"special_tokens_mask\"] = encoded_inputs[\"special_tokens_mask\"] + [[1] * max_length] * sen_difference\n",
        "          elif self.padding_side == \"left\":\n",
        "              if return_attention_mask:\n",
        "                  encoded_inputs[\"attention_mask\"] = [0] * sen_difference + encoded_inputs[\"attention_mask\"]\n",
        "              if \"token_type_ids\" in encoded_inputs:\n",
        "                  encoded_inputs[\"token_type_ids\"] = [self.pad_token_type_id] * sen_difference + encoded_inputs[\n",
        "                      \"token_type_ids\"\n",
        "                  ]\n",
        "              if \"special_tokens_mask\" in encoded_inputs:\n",
        "                  encoded_inputs[\"special_tokens_mask\"] = [1] * sen_difference + encoded_inputs[\"special_tokens_mask\"]\n",
        "              encoded_inputs[self.model_input_names[0]] = [self.pad_token_id] * sen_difference + required_input\n",
        "          else:\n",
        "              raise ValueError(\"Invalid padding strategy:\" + str(self.padding_side))\n",
        "\n",
        "      return encoded_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0yfpJnG3Ku7",
        "outputId": "9c5d4b8c-7e3a-494f-bf1e-dffe62a8fece"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
            "The class this function is called from is 'LNLFBertTokenizer'.\n"
          ]
        }
      ],
      "source": [
        "my_tokenizer = LNLFBertTokenizer.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvmPGZnYpGs7"
      },
      "outputs": [],
      "source": [
        "#my_tokenizer = SeqTokenizer(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nzY2EcgswFb"
      },
      "outputs": [],
      "source": [
        "a = my_tokenizer({1: [\"This is a first header\", \"This is second [MASK] header\"],0: [\"This is a first documents.\", \"This is a second documents. This is a second sentence.\"]},\n",
        "                 padding=False, return_tensors=None, multi_texts=True, order=[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEHXRljJkmXO"
      },
      "outputs": [],
      "source": [
        "text_column_name = 'text'\n",
        "def tokenize_function(examples):\n",
        "    return my_tokenizer(examples[text_column_name], multi_texts=False, truncation=True, max_length=64, max_sen_num=60, return_special_tokens_mask=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42s915vykIa-"
      },
      "outputs": [],
      "source": [
        "#raw_datasets[\"train\"][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jly0CRbkytD"
      },
      "outputs": [],
      "source": [
        "#tokenize_function(raw_datasets[\"train\"][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2kS8u2Qyfk-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import warnings\n",
        "from collections.abc import Mapping\n",
        "from dataclasses import dataclass\n",
        "from random import randint\n",
        "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "from transformers.data.data_collator import DataCollatorMixin, _tf_collate_batch, _torch_collate_batch, _numpy_collate_batch\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7D2yJLWDwCD"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class SeqDataCollatorForLanguageModeling(DataCollatorMixin):\n",
        "    \"\"\"\n",
        "    Data collator used for language modeling. Inputs are dynamically padded to the maximum length of a batch if they\n",
        "    are not all of the same length.\n",
        "\n",
        "    Args:\n",
        "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
        "            The tokenizer used for encoding the data.\n",
        "        mlm (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not to use masked language modeling. If set to `False`, the labels are the same as the inputs\n",
        "            with the padding tokens ignored (by setting them to -100). Otherwise, the labels are -100 for non-masked\n",
        "            tokens and the value to predict for the masked token.\n",
        "        mlm_probability (`float`, *optional*, defaults to 0.15):\n",
        "            The probability with which to (randomly) mask tokens in the input, when `mlm` is set to `True`.\n",
        "        pad_to_multiple_of (`int`, *optional*):\n",
        "            If set will pad the sequence to a multiple of the provided value.\n",
        "        return_tensors (`str`):\n",
        "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
        "\n",
        "    <Tip>\n",
        "\n",
        "    For best performance, this data collator should be used with a dataset having items that are dictionaries or\n",
        "    BatchEncoding, with the `\"special_tokens_mask\"` key, as returned by a [`PreTrainedTokenizer`] or a\n",
        "    [`PreTrainedTokenizerFast`] with the argument `return_special_tokens_mask=True`.\n",
        "\n",
        "    </Tip>\"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    mlm: bool = True\n",
        "    mlm_probability: float = 0.15\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    tf_experimental_compile: bool = False\n",
        "    return_tensors: str = \"pt\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.mlm and self.tokenizer.mask_token is None:\n",
        "            raise ValueError(\n",
        "                \"This tokenizer does not have a mask token which is necessary for masked language modeling. \"\n",
        "                \"You should pass `mlm=False` to train on causal language modeling instead.\"\n",
        "            )\n",
        "        if self.tf_experimental_compile:\n",
        "            import tensorflow as tf\n",
        "\n",
        "            self.tf_mask_tokens = tf.function(self.tf_mask_tokens, jit_compile=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def tf_bernoulli(shape, probability):\n",
        "        import tensorflow as tf\n",
        "\n",
        "        prob_matrix = tf.fill(shape, probability)\n",
        "        return tf.cast(prob_matrix - tf.random.uniform(shape, 0, 1) >= 0, tf.bool)\n",
        "\n",
        "    def tf_mask_tokens(\n",
        "        self, inputs: Any, vocab_size, mask_token_id, special_tokens_mask: Optional[Any] = None\n",
        "    ) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
        "        \"\"\"\n",
        "        import tensorflow as tf\n",
        "\n",
        "        mask_token_id = tf.cast(mask_token_id, inputs.dtype)\n",
        "\n",
        "        input_shape = tf.shape(inputs)\n",
        "        # 1 for a special token, 0 for a normal token in the special tokens mask\n",
        "        # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
        "        masked_indices = self.tf_bernoulli(input_shape, self.mlm_probability) & ~special_tokens_mask\n",
        "\n",
        "        for idx in range(len(masked_indices)):\n",
        "            if not tf.reduce_any(masked_indices[idx]):\n",
        "                f_token = tf.cast(tf.one_hot(tf.fill((input_shape[0],), 1), depth=input_shape[-1]), dtype=tf.bool)\n",
        "                masked_indices = masked_indices | f_token\n",
        "                break\n",
        "        # Replace unmasked indices with -100 in the labels since we only compute loss on masked tokens\n",
        "        labels = tf.where(masked_indices, inputs, -100)\n",
        "\n",
        "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "        indices_replaced = self.tf_bernoulli(input_shape, 0.8) & masked_indices\n",
        "\n",
        "        inputs = tf.where(indices_replaced, mask_token_id, inputs)\n",
        "\n",
        "        # 10% of the time, we replace masked input tokens with random word\n",
        "        indices_random = self.tf_bernoulli(input_shape, 0.1) & masked_indices & ~indices_replaced\n",
        "        random_words = tf.random.uniform(input_shape, maxval=vocab_size, dtype=inputs.dtype)\n",
        "\n",
        "        inputs = tf.where(indices_random, random_words, inputs)\n",
        "\n",
        "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "        return inputs, labels\n",
        "\n",
        "    def tf_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        #print(\"examples:\", examples)\n",
        "        import tensorflow as tf\n",
        "\n",
        "        # Handle dict or lists with proper padding and conversion to tensor.\n",
        "        if isinstance(examples[0], Mapping):\n",
        "            batch = self.tokenizer.pad(examples, return_tensors=\"tf\", pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "        else:\n",
        "            batch = {\n",
        "                \"input_ids\": _tf_collate_batch(examples, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "            }\n",
        "\n",
        "        # If special token mask has been preprocessed, pop it from the dict.\n",
        "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
        "        if self.mlm:\n",
        "            #print(\"special_tokens_mask:\", special_tokens_mask)\n",
        "            if special_tokens_mask is None:\n",
        "                input_ids = batch[\"input_ids\"].numpy()\n",
        "                input_shape = np.shape(input_ids)\n",
        "                flat_input = np.reshape(input_ids, (-1))\n",
        "                special_tokens_mask = np.array(self.tokenizer.get_special_tokens_mask(flat_input, already_has_special_tokens=True))\n",
        "                special_tokens_mask = np.reshape(special_tokens_mask, input_shape)\n",
        "                \"\"\"special_tokens_mask = [\n",
        "                    self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True)\n",
        "                    for val in batch[\"input_ids\"].numpy().tolist()\n",
        "                ]\n",
        "                \"\"\"\n",
        "                # Cannot directly create as bool\n",
        "                special_tokens_mask = tf.cast(tf.convert_to_tensor(special_tokens_mask, dtype=tf.int64), tf.bool)\n",
        "            else:\n",
        "                special_tokens_mask = tf.cast(special_tokens_mask, tf.bool)\n",
        "            batch[\"input_ids\"], batch[\"labels\"] = self.tf_mask_tokens(\n",
        "                tf.cast(batch[\"input_ids\"], tf.int64),\n",
        "                special_tokens_mask=special_tokens_mask,\n",
        "                mask_token_id=self.tokenizer.mask_token_id,\n",
        "                vocab_size=len(self.tokenizer),\n",
        "            )\n",
        "        else:\n",
        "            labels = batch[\"input_ids\"]\n",
        "            if self.tokenizer.pad_token_id is not None:\n",
        "                # Replace self.tokenizer.pad_token_id with -100\n",
        "                labels = tf.where(labels == self.tokenizer.pad_token_id, -100, labels)\n",
        "            else:\n",
        "                labels = tf.identity(labels)  # Makes a copy, just in case\n",
        "            batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        # Handle dict or lists with proper padding and conversion to tensor.\n",
        "        if isinstance(examples[0], Mapping):\n",
        "            batch = self.tokenizer.pad(examples, return_tensors=\"pt\", pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "        else:\n",
        "            batch = {\n",
        "                \"input_ids\": _torch_collate_batch(examples, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "            }\n",
        "\n",
        "        # If special token mask has been preprocessed, pop it from the dict.\n",
        "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
        "        if self.mlm:\n",
        "            batch[\"input_ids\"], batch[\"labels\"] = self.torch_mask_tokens(\n",
        "                batch[\"input_ids\"], special_tokens_mask=special_tokens_mask\n",
        "            )\n",
        "        else:\n",
        "            labels = batch[\"input_ids\"].clone()\n",
        "            if self.tokenizer.pad_token_id is not None:\n",
        "                labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "            batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "    def torch_mask_tokens(self, inputs: Any, special_tokens_mask: Optional[Any] = None) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
        "        \"\"\"\n",
        "        import torch\n",
        "\n",
        "        labels = inputs.clone()\n",
        "        # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
        "        probability_matrix = torch.full(labels.shape, self.mlm_probability)\n",
        "        if special_tokens_mask is None:\n",
        "            special_tokens_mask = [\n",
        "                self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
        "            ]\n",
        "            special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
        "        else:\n",
        "            special_tokens_mask = special_tokens_mask.bool()\n",
        "\n",
        "        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
        "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
        "\n",
        "        # 10% of the time, we replace masked input tokens with random word\n",
        "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
        "        inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "        return inputs, labels\n",
        "\n",
        "    def numpy_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        # Handle dict or lists with proper padding and conversion to tensor.\n",
        "        if isinstance(examples[0], Mapping):\n",
        "            batch = self.tokenizer.pad(examples, return_tensors=\"np\", pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "        else:\n",
        "            batch = {\n",
        "                \"input_ids\": _numpy_collate_batch(examples, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "            }\n",
        "\n",
        "        # If special token mask has been preprocessed, pop it from the dict.\n",
        "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
        "        if self.mlm:\n",
        "            batch[\"input_ids\"], batch[\"labels\"] = self.numpy_mask_tokens(\n",
        "                batch[\"input_ids\"], special_tokens_mask=special_tokens_mask\n",
        "            )\n",
        "        else:\n",
        "            labels = np.copy(batch[\"input_ids\"])\n",
        "            if self.tokenizer.pad_token_id is not None:\n",
        "                labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "            batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "    def numpy_mask_tokens(self, inputs: Any, special_tokens_mask: Optional[Any] = None) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
        "        \"\"\"\n",
        "        labels = np.copy(inputs)\n",
        "        # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
        "        probability_matrix = np.full(labels.shape, self.mlm_probability)\n",
        "        if special_tokens_mask is None:\n",
        "            special_tokens_mask = [\n",
        "                self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
        "            ]\n",
        "            special_tokens_mask = np.array(special_tokens_mask, dtype=bool)\n",
        "        else:\n",
        "            special_tokens_mask = special_tokens_mask.astype(bool)\n",
        "\n",
        "        probability_matrix[special_tokens_mask] = 0\n",
        "        # Numpy doesn't have bernoulli, so we use a binomial with 1 trial\n",
        "        masked_indices = np.random.binomial(1, probability_matrix, size=probability_matrix.shape).astype(bool)\n",
        "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "        indices_replaced = np.random.binomial(1, 0.8, size=labels.shape).astype(bool) & masked_indices\n",
        "        inputs[indices_replaced] = self.tokenizer.mask_token_id\n",
        "\n",
        "        # 10% of the time, we replace masked input tokens with random word\n",
        "        # indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "        indices_random = (\n",
        "            np.random.binomial(1, 0.5, size=labels.shape).astype(bool) & masked_indices & ~indices_replaced\n",
        "        )\n",
        "        random_words = np.random.randint(\n",
        "            low=0, high=len(self.tokenizer), size=np.count_nonzero(indices_random), dtype=np.int64\n",
        "        )\n",
        "        inputs[indices_random] = random_words\n",
        "\n",
        "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "        return inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpowuaz5n9qG"
      },
      "outputs": [],
      "source": [
        "mlm_probability = 0.15\n",
        "data_collator = SeqDataCollatorForLanguageModeling(\n",
        "    tokenizer=my_tokenizer, mlm_probability=mlm_probability, return_tensors=\"tf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "a9d10d3ea4c946aebe0b299edee9856a",
            "422da429e3ec4d7e8513779ad733817b",
            "0841b248068f4a5e8e7c77b8aa07c92e",
            "55f3d3ed251e4e8186a1a24570552ecc",
            "01dd40591b4c4e13bade61c603d2bda1",
            "2fc739cffe0f4c69bee0efeede1e76d3",
            "8abd57d3da26430d8c0c245698619309",
            "2e6a7164ab5d4b89bc2a610a1fd9b716",
            "155c7ce4b6554baf9c35ba04d7374cd6",
            "fb161318ef8b4752b89a84562a61826d",
            "e69a4ae3e712444a8150cbc865dc2523",
            "ac9f9ebfa7954311b85fefb3c2a74752",
            "86246b31af654f15b159ffcb211ed62d",
            "599c43492145403395150b3254dc6352",
            "ac8ffc9a97864bf2af979e49e8456f1f",
            "11a8e9a04770472592d96f3fec637183",
            "0d1e2e2e38844f1984cc96ce97f3a8ed",
            "e5b15affeec64135b90f70bec0a09f9a",
            "4b180815c0434a6e9191f9de418dfe96",
            "c64e885602bc4ba1a7794af8d26fd978",
            "166f088d722b4686a0037e5e93783c21",
            "88952b71cdb64d41a73ace95815c3df2",
            "84d81329f0dd40918df1b6a2d985b6e3",
            "b0b25ae913464516b9421512466bfce0",
            "f640b9c335064f75bfb747d11be7227f",
            "7ed949021e10487f8f704fa6245b7d49",
            "f52aa0592f81474da00da0e607f87d21",
            "31bd66b9a13b42859cf1e84307a63f0b",
            "1a9cc86c7b9b4b17beef13cb56349efd",
            "d780a3ba79e84dd4bd27ba58b3a2d9cd",
            "1e174ad510f944019acef74a3a81d054",
            "38e7d982f9f44da09b0a7405f355173f",
            "a39b93cba5674a97a0f34b6438e23df0",
            "d188643c49db4ac89f84afe121e52255",
            "bb0c1c9f36f34082a428ccb1a9547552",
            "6a29f5e5de034e04894510e109e63eed",
            "d04a5fc63b4241d5aaade2d94694537c",
            "9ca94d70d90740d0b5c8a6382acec834",
            "1c05b9a4cedf4a97a5641cb078b03d95",
            "0034b49ea2b04db19d7fe13aef61b832",
            "08a558566b694bd389c3cfc684f6cb78",
            "4a7f0407998c4e2fb374ba0a4612c675",
            "487bf6f989ee403b83f7a89162fe81ca",
            "60583940d54c493bac592740c56d5423",
            "13ab4c33ea3042168188562a5485b4ea",
            "9f291f1c947a4a67a9bfc06be066a22f",
            "b49306c80d744f9bb9e78a558bfebcef",
            "8c99d92f586d46bb808a685ecae330f6",
            "11860834fa8944c99c2fbbdf05ddadf8",
            "72d44cd69ff0490991c96191f3e3e64a",
            "6e2a6b22c3e14cdd85abbacf6f9d711d",
            "130ab8231e4947569b0cd5ea1138b98e",
            "03f702468b5946728e8c96dc5a6a8d55",
            "bcf584b9619948698062cf03850c790b",
            "f27c99d3519d4902a546f114d2737a26",
            "50a1917a750644b2b89f0aabfd245321",
            "245518e8d61e4f7f8ca5f081376343f0",
            "54181ed0174e4d2aa356446e7e9f5b11",
            "80071fcef074459c891027492f4ed82f",
            "b179fded35854c3199ae35708ae8f195",
            "5854dee2f4454587aff35a6c46dce22b",
            "c6db215148de4bc9b0c59d11c0ac8b2f",
            "19f1a05289d244ad83d60dbbdb7d5078",
            "2101e5dcba7544a890b019fa95eb6598",
            "786bccee3fb44f2a89916c0d18fb4840",
            "f8606673361d4433aa7da7e5bc58eadd",
            "9988edf69ae546f3a29431933594ff6c",
            "8c61b0b4071944c6a1a62f143005f563",
            "d02a69ce62614a28824ec4dc787692cf",
            "f206c35534e944c189216d333eda06a0",
            "c30e142b47fc47a3998b73d902264029",
            "120c3bb3d3e644e1be4449329836f948",
            "31bec452d0924fd193e2019db0b7f115",
            "eaee35aa20574ee189ee0ea8edb29a59",
            "3cab100d330d45f58f445fb554b8f436",
            "7ebdafb101284890a1afc8653bd04bd6",
            "8dcf28775ead47fc9fa451e8756d9f0c",
            "9bee55da4d6c491e95bfb60f4ed4ae47",
            "ac3b45c0d37d47d7895beaea5ac8fb81",
            "af1aac5ce735443da70dd3633949c89e",
            "6f36c4e757814182aa8ad028ac2e13c4",
            "1634bae7bee24c6fa2cd1c76059735fd",
            "9821e8dcbc9e441c8b48acb2bc143978",
            "75a8c8cedb8f4541bb2e2a15d2d610cc",
            "803a72b895624fc1a3be1bf34c3d480b",
            "e625fd57a304447791e0cde8ccf5f075",
            "0e20b94e23ed44a4bea77af0094fb706",
            "33fbdda2524e4c5c999c5aed77a4c5ec",
            "879d1ff131de45909a1fb76ff8dbdc41",
            "725ffbec655f4992ac50577103d813e1",
            "59bcd83c570d4ab2886b83cf5aa42402",
            "6408770d66374a338ea5134dbb055103",
            "0c1235601eeb4bab9138f53de8d6345c",
            "05fb9e15ad564fcca68a65022d4be78c",
            "27d6b363d41e4a4796cbb8920badeaed",
            "7b1a3bb9b136432eab15754c448bb1cb",
            "2e81a37d18764ca3990473d85f0f6b13",
            "8cabc22c8cc24fb39d60e5379f619312",
            "4dc0d354f20a447d8fc7d3c7aafb29d7",
            "261404ac538e4476878f5798751af00b",
            "44fd6d2f677e48f89812045e93b82e6a",
            "570a57d4cc6b4c9283a7fb6561efb51f",
            "c70995a47e3f437692692a8d1fba3c14",
            "caec4e0c17894182b26fca67d1a59dfe",
            "32f8dab5bb2e46a084fa028bf1026449",
            "a17746e3e85d4e16a3d4d16d432c21cf",
            "b4663e1144a0463889bbee1b40089906",
            "270846a3304741ff8dbbeaf488a85617",
            "d12bafbfdb9f44b79a9383d6a6dc2408",
            "7e0c65324de1408f8a5f6701b96ca0bb"
          ]
        },
        "id": "InHPIX-AHGEj",
        "outputId": "eaa52dcf-2140-4717-a821-06444dfeebe2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9d10d3ea4c946aebe0b299edee9856a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac9f9ebfa7954311b85fefb3c2a74752",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d81329f0dd40918df1b6a2d985b6e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d188643c49db4ac89f84afe121e52255",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/157M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13ab4c33ea3042168188562a5485b4ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/157M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50a1917a750644b2b89f0aabfd245321",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9988edf69ae546f3a29431933594ff6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bee55da4d6c491e95bfb60f4ed4ae47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "879d1ff131de45909a1fb76ff8dbdc41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "261404ac538e4476878f5798751af00b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'wikitext'\n",
        "dataset_config_name = 'wikitext-103-raw-v1'\n",
        "raw_datasets = load_dataset(\n",
        "    dataset_name,\n",
        "    dataset_config_name,\n",
        "    token=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "9b8e8b80f5f14f5f87da3b35d8ac21e6",
            "e1cf34bbef824a35a37da5e279d13a14",
            "f465aeb4730142388d6a41e3965469f2",
            "ee5b15e06f2249dd8171f7f5c246e526",
            "f8af9760b8b448f295aa93d0fa42a22b",
            "e7d9a1693c214a5d8407d385db030e52",
            "be875caf2c3e4d7784921244a7c56999",
            "e5892e11651f4b70b943992bd7f88f57",
            "99a01c6668c540679d3f11539998fca0",
            "9da2aba16ce44a0cb35877deafb6bc7f",
            "80f84a9a28c24e689c49742b95139757",
            "610f6c7c64d64c60ae8c74706385bb98",
            "a703e2022dad4a5985138ce796836a5f",
            "bdfbe4a11f6d459db96dba6ba2e7ec23",
            "cbcb653d86da4525a5693dfe5aea3745",
            "00638b3d312c4ac2893ed09aa3baa4f2",
            "b1000b0af4404b64b0735490c684f8b1",
            "698e601226a349e699e77a7cee0c68a6",
            "429beb32d8294a11bd81a298628ea164",
            "1f0bfee0d3194a9abf813fd2cde4c79d",
            "323fe906c461460d96f0d9452869344e",
            "27d865d507b840c28c44d7e2f416dfdb",
            "e776b1ba6d4543d8b3eddb1acf909a2b",
            "81aec2aaf41f414ab8fb49dc46e35868",
            "f90e15b7adc8421e939e08272fcc5858",
            "2ba10491d3dd458aa619b90cfa037899",
            "dd621a9c822d46edb017315a989e91a5",
            "f74a465c4fed4811bf631ff6ff9f44db",
            "1cef89d6f06043d99ec2b3f0341c41af",
            "459a08784fd64416a9e243ea09adb874",
            "f99f1b880f754e118b3466bd4fbc3a12",
            "651c0f351ec64abea7b85550903406b5",
            "bce88877099e4dffad8a6481de13191a",
            "f90626438ecf49cc9433576e0693cbd3",
            "27929d244481491d9514853cf1c1f544",
            "9ff5346af6394d07a00954447e804949",
            "e7b9536370aa4f7b9d9b515c81687645",
            "c2ef46456b0346338e227a1f1190b7d5",
            "4dc7de46985e40ff977f6f8822ce4a22",
            "8665d47774514cb3b34e7151fbd0e867",
            "b1dcb84c46f64e71b57d44bcc4c63206",
            "22a805900a4b4a3dafd6ce5b02f3c81b",
            "b0b7f061d6bd43dd8be079b87ca2ab56",
            "94986a1cedee400a8d85f4fcab5fac13",
            "7f791311a5e449dc9b47ba4b8058c61c",
            "cf8d949e3e3841069d83965f771c8edf",
            "293f4593ae2649d491e808dbb3d412a0",
            "adb86d20426f4e3f95c50844ac16a996",
            "3bd250fb6ee742bb8cf259e9799e4931",
            "3b168b5f9c6f4ed8a03bb5c31613197c",
            "ba24dc6930814242bf983d5974ea81fb",
            "5b6e3b88573f479ab09ae9bd6512a82e",
            "0484969f7bda4f69a102497bc3c80ca8",
            "e6a547ec7e004756aa776c0d1b1c91cf",
            "50c5c9d7075c49469f86770c96d59157",
            "f105feda0b534fe29f09c77aaabfdd46",
            "fdbbf6893a1f46819973bddc0c30386a",
            "43fb1adc5b9548bda2f2cc192ee69323",
            "74b7296bd360471d9aaa1ac9d9493243",
            "a56488ec12954ad09b26e794d5629148",
            "37c84944ab0e46cf97aec71bf292321c",
            "8b42b4a17f29498883c957a1e543413f",
            "593cbf071d7a487ab29cec034ab2133f",
            "307246944ab640e8928b0df1b945809f",
            "c2b660202e71470e9121a953cd1cff73",
            "3e21ddbdc17a40fca7840360cf11eed0"
          ]
        },
        "id": "AKIO6AR0G432",
        "outputId": "f1b27c82-c50c-47c5-e54f-c71e19b929a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b8e8b80f5f14f5f87da3b35d8ac21e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset line_by_line:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "610f6c7c64d64c60ae8c74706385bb98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset line_by_line:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e776b1ba6d4543d8b3eddb1acf909a2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset line_by_line:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f90626438ecf49cc9433576e0693cbd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f791311a5e449dc9b47ba4b8058c61c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f105feda0b534fe29f09c77aaabfdd46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    num_proc=None,\n",
        "    remove_columns=[text_column_name],\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on dataset line_by_line\",\n",
        ")\n",
        "tokenized_datasets = tokenized_datasets.filter(lambda example: len(example['input_ids']) > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqKDs_x6Gqnd"
      },
      "outputs": [],
      "source": [
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "test_dataset = tokenized_datasets['test']\n",
        "valid_dataset = tokenized_datasets[\"validation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a94caGuy1Ox"
      },
      "outputs": [],
      "source": [
        "options = tf.data.Options()\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClAStc9nsCCe"
      },
      "outputs": [],
      "source": [
        "initial_epoch = 168"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR4JlLoq7O2t",
        "outputId": "46f92a84-2c8e-4c25-cc20-f9cc670f30e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFLNLFBertForMaskedLM.\n",
            "\n",
            "All the layers of TFLNLFBertForMaskedLM were initialized from the model checkpoint at ./drive/MyDrive/Models/TFLNLFBert_Pretrain_from_scratch/epoch167.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLNLFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "#config.num_labels=2\n",
        "model_pre_path = \"./drive/MyDrive/Models/TFLNLFBert_Pretrain_from_scratch/epoch\"\n",
        "if initial_epoch <= 0:\n",
        "  new_model = TFLNLFBertForMaskedLM.from_config(config)\n",
        "  new_model.build()\n",
        "else:\n",
        "  new_model = TFLNLFBertForMaskedLM.from_pretrained(model_pre_path + str(initial_epoch - 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q91O8q_3EbfY"
      },
      "outputs": [],
      "source": [
        "tf_train_dataset = new_model.prepare_tf_dataset(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=1,\n",
        "    collate_fn=data_collator,\n",
        "    drop_remainder=True,\n",
        ").with_options(options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GncmuqyXIwtJ"
      },
      "outputs": [],
      "source": [
        "tf_valid_dataset = new_model.prepare_tf_dataset(\n",
        "    valid_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=1,\n",
        "    collate_fn=data_collator,\n",
        "    drop_remainder=True,\n",
        ").with_options(options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLLRHOy_JKgD"
      },
      "outputs": [],
      "source": [
        "tf_test_dataset = new_model.prepare_tf_dataset(\n",
        "    test_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=1,\n",
        "    collate_fn=data_collator,\n",
        ").with_options(options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hGjLhVqC6ZI"
      },
      "outputs": [],
      "source": [
        "num_train_epochs = 3\n",
        "base_learning_rate=5e-5\n",
        "num_warmup_steps = 0\n",
        "adam_beta1 = 0.9\n",
        "adam_beta2 = 0.999\n",
        "adam_epsilon = 1e-8\n",
        "weight_decay = 0.0\n",
        "max_grad_norm = 1.0\n",
        "xla=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH33L54OUEER"
      },
      "outputs": [],
      "source": [
        "split_time = 60\n",
        "epochs = int(num_train_epochs * split_time)\n",
        "steps_per_epoch = int(len(tf_train_dataset) // split_time)\n",
        "num_epochs = 30\n",
        "next_train_epochs = min(initial_epoch + num_epochs, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JRROiFIUaU6"
      },
      "outputs": [],
      "source": [
        "base_train_steps = len(tf_train_dataset) * int(num_train_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE2glzTYC4TZ"
      },
      "outputs": [],
      "source": [
        "num_train_steps = base_train_steps - initial_epoch * steps_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg-2Ir93UOwJ"
      },
      "outputs": [],
      "source": [
        "learning_rate = base_learning_rate * num_train_steps / base_train_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8d_MYQYUgYB",
        "outputId": "b252f911-1fab-4d4a-809b-0103b9143f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3336938393808224e-06\n"
          ]
        }
      ],
      "source": [
        "print(learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AG_PLXwsEb7M"
      },
      "outputs": [],
      "source": [
        "from transformers import create_optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH_Clv6pD5kb"
      },
      "outputs": [],
      "source": [
        "optimizer, lr_schedule = create_optimizer(\n",
        "    init_lr=learning_rate,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    adam_beta1=adam_beta1,\n",
        "    adam_beta2=adam_beta2,\n",
        "    adam_epsilon=adam_epsilon,\n",
        "    weight_decay_rate=weight_decay,\n",
        "    adam_global_clipnorm=max_grad_norm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Thf_loMGoPf"
      },
      "outputs": [],
      "source": [
        "new_model.compile(optimizer=optimizer, jit_compile=xla)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaXFkUXKuu20",
        "outputId": "7d3920d4-319b-491d-c970-ff8f40b5375b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.333694e-06\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "print(K.eval(new_model.optimizer.lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZdatcqeHAev"
      },
      "outputs": [],
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        print(\"Start save model epoch \", epoch)\n",
        "        self.model.save_pretrained(model_pre_path + str(epoch))\n",
        "        print(\"Optimizer learning rate = \", K.eval(self.model.optimizer.lr))\n",
        "        #print(\"Optimizer learning rate = \", self.model.optimizer._decayed_lr(tf.float32))\n",
        "        print(\"End save model epoch \", epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPrJIsYAHUR_"
      },
      "outputs": [],
      "source": [
        "callbacks = [CustomCallback()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aua5VCZJLsS3",
        "outputId": "aaf57d43-a3b5-4d34-aa50-6f94cea591b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tflnlf_bert_for_masked_lm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lnlfbert (TFLNLFBertMainLa  multiple                  202078464 \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " lm_head (TFLNLFBertLMHead)  multiple                  39642969  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 202720857 (773.32 MB)\n",
            "Trainable params: 202720857 (773.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnVEq0GKFd4N",
        "outputId": "f8817b9b-d06f-4395-a4a1-76744987d76a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 169/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4611Start save model epoch  168\n",
            "Optimizer learning rate =  3.0559327e-06\n",
            "End save model epoch  168\n",
            "19417/19417 [==============================] - 3877s 195ms/step - loss: 2.4611 - val_loss: 2.4056\n",
            "Epoch 170/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4573Start save model epoch  169\n",
            "Optimizer learning rate =  2.7781568e-06\n",
            "End save model epoch  169\n",
            "19417/19417 [==============================] - 3748s 193ms/step - loss: 2.4573 - val_loss: 2.4147\n",
            "Epoch 171/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4252Start save model epoch  170\n",
            "Optimizer learning rate =  2.5003812e-06\n",
            "End save model epoch  170\n",
            "19417/19417 [==============================] - 3730s 192ms/step - loss: 2.4252 - val_loss: 2.4072\n",
            "Epoch 172/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4164Start save model epoch  171\n",
            "Optimizer learning rate =  2.2226056e-06\n",
            "End save model epoch  171\n",
            "19417/19417 [==============================] - 3796s 195ms/step - loss: 2.4164 - val_loss: 2.4334\n",
            "Epoch 173/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4233Start save model epoch  172\n",
            "Optimizer learning rate =  1.94483e-06\n",
            "End save model epoch  172\n",
            "19417/19417 [==============================] - 3764s 194ms/step - loss: 2.4233 - val_loss: 2.4016\n",
            "Epoch 174/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.3982Start save model epoch  173\n",
            "Optimizer learning rate =  1.6670544e-06\n",
            "End save model epoch  173\n",
            "19417/19417 [==============================] - 3744s 193ms/step - loss: 2.3982 - val_loss: 2.4188\n",
            "Epoch 175/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.3970Start save model epoch  174\n",
            "Optimizer learning rate =  1.3892786e-06\n",
            "End save model epoch  174\n",
            "19417/19417 [==============================] - 3765s 194ms/step - loss: 2.3970 - val_loss: 2.4569\n",
            "Epoch 176/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.3990Start save model epoch  175\n",
            "Optimizer learning rate =  1.111503e-06\n",
            "End save model epoch  175\n",
            "19417/19417 [==============================] - 3758s 194ms/step - loss: 2.3990 - val_loss: 2.4486\n",
            "Epoch 177/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4152Start save model epoch  176\n",
            "Optimizer learning rate =  8.337273e-07\n",
            "End save model epoch  176\n",
            "19417/19417 [==============================] - 3773s 194ms/step - loss: 2.4152 - val_loss: 2.4221\n",
            "Epoch 178/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4155Start save model epoch  177\n",
            "Optimizer learning rate =  5.559517e-07\n",
            "End save model epoch  177\n",
            "19417/19417 [==============================] - 3757s 193ms/step - loss: 2.4155 - val_loss: 2.3982\n",
            "Epoch 179/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4143Start save model epoch  178\n",
            "Optimizer learning rate =  2.7817595e-07\n",
            "End save model epoch  178\n",
            "19417/19417 [==============================] - 3733s 192ms/step - loss: 2.4143 - val_loss: 2.3549\n",
            "Epoch 180/180\n",
            "19417/19417 [==============================] - ETA: 0s - loss: 2.4073Start save model epoch  179\n",
            "Optimizer learning rate =  4.0038783e-10\n",
            "End save model epoch  179\n",
            "19417/19417 [==============================] - 3739s 193ms/step - loss: 2.4073 - val_loss: 2.4055\n"
          ]
        }
      ],
      "source": [
        "history = new_model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_valid_dataset,\n",
        "    epochs=next_train_epochs,\n",
        "    initial_epoch=initial_epoch,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "oPyrzXxQlA3q",
        "outputId": "7adcf232-794f-46fe-dc83-a1e7ce385317"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nEpoch 1/30\\n19417/19417 [==============================] - ETA: 0s - loss: 5.7616Start save model epoch  0\\nOptimizer learning rate =  4.972224e-05\\nEnd save model epoch  0\\n19417/19417 [==============================] - 3831s 192ms/step - loss: 5.7616 - val_loss: 5.1976\\nEpoch 2/30\\n19417/19417 [==============================] - ETA: 0s - loss: 4.9109Start save model epoch  1\\nOptimizer learning rate =  4.944446e-05\\nEnd save model epoch  1\\n19417/19417 [==============================] - 3721s 192ms/step - loss: 4.9109 - val_loss: 4.6028\\nEpoch 3/30\\n19417/19417 [==============================] - ETA: 0s - loss: 4.5231Start save model epoch  2\\nOptimizer learning rate =  4.9166687e-05\\nEnd save model epoch  2\\n19417/19417 [==============================] - 3679s 189ms/step - loss: 4.5231 - val_loss: 4.3518\\nEpoch 4/30\\n19417/19417 [==============================] - ETA: 0s - loss: 4.3601Start save model epoch  3\\nOptimizer learning rate =  4.8888913e-05\\nEnd save model epoch  3\\n19417/19417 [==============================] - 3686s 190ms/step - loss: 4.3601 - val_loss: 4.1640\\nEpoch 5/30\\n19417/19417 [==============================] - ETA: 0s - loss: 4.2237Start save model epoch  4\\nOptimizer learning rate =  4.8611135e-05\\nEnd save model epoch  4\\n19417/19417 [==============================] - 3751s 193ms/step - loss: 4.2237 - val_loss: 4.0825\\nEpoch 6/30\\n19417/19417 [==============================] - ETA: 0s - loss: 4.1508Start save model epoch  5\\nOptimizer learning rate =  4.833336e-05\\nEnd save model epoch  5\\n19417/19417 [==============================] - 3772s 194ms/step - loss: 4.1508 - val_loss: 3.9863\\nEpoch 7/30\\n19417/19417 [==============================] - ETA: 0s - loss: 4.0942Start save model epoch  6\\nOptimizer learning rate =  4.8055583e-05\\nEnd save model epoch  6\\n19417/19417 [==============================] - 3768s 194ms/step - loss: 4.0942 - val_loss: 3.9529\\nEpoch 8/30\\n19417/19417 [==============================] - ETA: 0s - loss: 4.0226Start save model epoch  7\\nOptimizer learning rate =  4.7777805e-05\\nEnd save model epoch  7\\n19417/19417 [==============================] - 3741s 193ms/step - loss: 4.0226 - val_loss: 3.9398\\nEpoch 9/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.9662Start save model epoch  8\\nOptimizer learning rate =  4.750003e-05\\nEnd save model epoch  8\\n19417/19417 [==============================] - 3752s 193ms/step - loss: 3.9662 - val_loss: 3.8325\\nEpoch 10/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.9188Start save model epoch  9\\nOptimizer learning rate =  4.7222256e-05\\nEnd save model epoch  9\\n19417/19417 [==============================] - 3736s 192ms/step - loss: 3.9188 - val_loss: 3.8448\\nEpoch 11/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.8827Start save model epoch  10\\nOptimizer learning rate =  4.694448e-05\\nEnd save model epoch  10\\n19417/19417 [==============================] - 3748s 193ms/step - loss: 3.8827 - val_loss: 3.8075\\nEpoch 12/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.8428Start save model epoch  11\\nOptimizer learning rate =  4.6666704e-05\\nEnd save model epoch  11\\n19417/19417 [==============================] - 3771s 194ms/step - loss: 3.8428 - val_loss: 3.7371\\nEpoch 13/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.8088Start save model epoch  12\\nOptimizer learning rate =  4.638893e-05\\nEnd save model epoch  12\\n19417/19417 [==============================] - 3719s 192ms/step - loss: 3.8088 - val_loss: 3.7379\\nEpoch 14/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.7680Start save model epoch  13\\nOptimizer learning rate =  4.6111152e-05\\nEnd save model epoch  13\\n19417/19417 [==============================] - 3681s 190ms/step - loss: 3.7680 - val_loss: 3.7407\\nEpoch 15/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.7287Start save model epoch  14\\nOptimizer learning rate =  4.5833378e-05\\nEnd save model epoch  14\\n19417/19417 [==============================] - 3676s 189ms/step - loss: 3.7287 - val_loss: 3.6863\\nEpoch 16/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.6936Start save model epoch  15\\nOptimizer learning rate =  4.5555604e-05\\nEnd save model epoch  15\\n19417/19417 [==============================] - 3669s 189ms/step - loss: 3.6936 - val_loss: 3.6200\\nEpoch 17/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.7095Start save model epoch  16\\nOptimizer learning rate =  4.5277826e-05\\nEnd save model epoch  16\\n19417/19417 [==============================] - 3671s 189ms/step - loss: 3.7095 - val_loss: 3.6534\\nEpoch 18/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.7167Start save model epoch  17\\nOptimizer learning rate =  4.500005e-05\\nEnd save model epoch  17\\n19417/19417 [==============================] - 3750s 193ms/step - loss: 3.7167 - val_loss: 3.5946\\nEpoch 19/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.6781Start save model epoch  18\\nOptimizer learning rate =  4.4722277e-05\\nEnd save model epoch  18\\n19417/19417 [==============================] - 3744s 193ms/step - loss: 3.6781 - val_loss: 3.6476\\nEpoch 20/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.6828Start save model epoch  19\\nOptimizer learning rate =  4.44445e-05\\nEnd save model epoch  19\\n19417/19417 [==============================] - 3711s 191ms/step - loss: 3.6828 - val_loss: 3.6742\\nEpoch 21/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.6331Start save model epoch  20\\nOptimizer learning rate =  4.4166725e-05\\nEnd save model epoch  20\\n19417/19417 [==============================] - 3703s 191ms/step - loss: 3.6331 - val_loss: 3.5497\\nEpoch 22/30\\n19417/19417 [==============================] - ETA: 0s - loss: 3.6314Start save model epoch  21\\nOptimizer learning rate =  4.388895e-05\\nEnd save model epoch  21\\n19417/19417 [==============================] - 3699s 190ms/step - loss: 3.6314 - val_loss: 3.5026\\nEpoch 23/30\\n18689/19417 [===========================>..] - ETA: 2:13 - loss: 3.6203\\n\\n\\nEpoch 23/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.7263Start save model epoch  22\\nOptimizer learning rate =  4.3611173e-05\\nEnd save model epoch  22\\n19417/19417 [==============================] - 3988s 200ms/step - loss: 3.7263 - val_loss: 3.5994\\nEpoch 24/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.6276Start save model epoch  23\\nOptimizer learning rate =  4.3333403e-05\\nEnd save model epoch  23\\n19417/19417 [==============================] - 3940s 203ms/step - loss: 3.6276 - val_loss: 3.5395\\nEpoch 25/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.5932Start save model epoch  24\\nOptimizer learning rate =  4.3055625e-05\\nEnd save model epoch  24\\n19417/19417 [==============================] - 3868s 199ms/step - loss: 3.5932 - val_loss: 3.4826\\nEpoch 26/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.5285Start save model epoch  25\\nOptimizer learning rate =  4.277785e-05\\nEnd save model epoch  25\\n19417/19417 [==============================] - 3906s 201ms/step - loss: 3.5285 - val_loss: 3.5638\\nEpoch 27/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.5153Start save model epoch  26\\nOptimizer learning rate =  4.2500073e-05\\nEnd save model epoch  26\\n19417/19417 [==============================] - 3892s 200ms/step - loss: 3.5153 - val_loss: 3.5205\\nEpoch 28/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.4889Start save model epoch  27\\nOptimizer learning rate =  4.22223e-05\\nEnd save model epoch  27\\n19417/19417 [==============================] - 3877s 200ms/step - loss: 3.4889 - val_loss: 3.3360\\nEpoch 29/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.5012Start save model epoch  28\\nOptimizer learning rate =  4.1944524e-05\\nEnd save model epoch  28\\n19417/19417 [==============================] - 3831s 197ms/step - loss: 3.5012 - val_loss: 3.3778\\nEpoch 30/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.4791Start save model epoch  29\\nOptimizer learning rate =  4.1666746e-05\\nEnd save model epoch  29\\n19417/19417 [==============================] - 3881s 200ms/step - loss: 3.4791 - val_loss: 3.3992\\nEpoch 31/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.4603Start save model epoch  30\\nOptimizer learning rate =  4.1388972e-05\\nEnd save model epoch  30\\n19417/19417 [==============================] - 3880s 200ms/step - loss: 3.4603 - val_loss: 3.3211\\nEpoch 32/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.4514Start save model epoch  31\\nOptimizer learning rate =  4.1111194e-05\\nEnd save model epoch  31\\n19417/19417 [==============================] - 3789s 195ms/step - loss: 3.4514 - val_loss: 3.3742\\nEpoch 33/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.4323Start save model epoch  32\\nOptimizer learning rate =  4.083342e-05\\nEnd save model epoch  32\\n19417/19417 [==============================] - 3802s 196ms/step - loss: 3.4323 - val_loss: 3.3754\\nEpoch 34/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.4076Start save model epoch  33\\nOptimizer learning rate =  4.0555642e-05\\nEnd save model epoch  33\\n19417/19417 [==============================] - 3805s 196ms/step - loss: 3.4076 - val_loss: 3.3260\\nEpoch 35/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.4138Start save model epoch  34\\nOptimizer learning rate =  4.0277868e-05\\nEnd save model epoch  34\\n19417/19417 [==============================] - 3739s 193ms/step - loss: 3.4138 - val_loss: 3.3436\\nEpoch 36/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.3635Start save model epoch  35\\nOptimizer learning rate =  4.0000094e-05\\nEnd save model epoch  35\\n19417/19417 [==============================] - 3811s 196ms/step - loss: 3.3635 - val_loss: 3.2435\\nEpoch 37/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.3576Start save model epoch  36\\nOptimizer learning rate =  3.9722316e-05\\nEnd save model epoch  36\\n19417/19417 [==============================] - 3761s 194ms/step - loss: 3.3576 - val_loss: 3.2917\\nEpoch 38/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.3536Start save model epoch  37\\nOptimizer learning rate =  3.944454e-05\\nEnd save model epoch  37\\n19417/19417 [==============================] - 3735s 192ms/step - loss: 3.3536 - val_loss: 3.2976\\nEpoch 39/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.3260Start save model epoch  38\\nOptimizer learning rate =  3.9166764e-05\\nEnd save model epoch  38\\n19417/19417 [==============================] - 3786s 195ms/step - loss: 3.3260 - val_loss: 3.3004\\nEpoch 40/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2894Start save model epoch  39\\nOptimizer learning rate =  3.888899e-05\\nEnd save model epoch  39\\n19417/19417 [==============================] - 3821s 197ms/step - loss: 3.2894 - val_loss: 3.2853\\nEpoch 41/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.3094Start save model epoch  40\\nOptimizer learning rate =  3.8611215e-05\\nEnd save model epoch  40\\n19417/19417 [==============================] - 3800s 196ms/step - loss: 3.3094 - val_loss: 3.2053\\nEpoch 42/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2792Start save model epoch  41\\nOptimizer learning rate =  3.8333437e-05\\nEnd save model epoch  41\\n19417/19417 [==============================] - 3881s 200ms/step - loss: 3.2792 - val_loss: 3.1869\\nEpoch 43/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2810Start save model epoch  42\\nOptimizer learning rate =  3.8055663e-05\\nEnd save model epoch  42\\n19417/19417 [==============================] - 3815s 196ms/step - loss: 3.2810 - val_loss: 3.1496\\nEpoch 44/52\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2505Start save model epoch  43\\nOptimizer learning rate =  3.7777885e-05\\nEnd save model epoch  43\\n19417/19417 [==============================] - 3846s 198ms/step - loss: 3.2505 - val_loss: 3.1106\\nEpoch 45/52\\n 3995/19417 [=====>........................] - ETA: 48:46 - loss: 3.3228\\n\\n\\nEpoch 45/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.3721Start save model epoch  44\\nOptimizer learning rate =  3.750011e-05\\nEnd save model epoch  44\\n19417/19417 [==============================] - 3783s 190ms/step - loss: 3.3721 - val_loss: 3.1899\\nEpoch 46/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2501Start save model epoch  45\\nOptimizer learning rate =  3.7222333e-05\\nEnd save model epoch  45\\n19417/19417 [==============================] - 3696s 190ms/step - loss: 3.2501 - val_loss: 3.1693\\nEpoch 47/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2489Start save model epoch  46\\nOptimizer learning rate =  3.6944555e-05\\nEnd save model epoch  46\\n19417/19417 [==============================] - 3665s 189ms/step - loss: 3.2489 - val_loss: 3.2847\\nEpoch 48/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2333Start save model epoch  47\\nOptimizer learning rate =  3.666678e-05\\nEnd save model epoch  47\\n19417/19417 [==============================] - 3724s 192ms/step - loss: 3.2333 - val_loss: 3.1260\\nEpoch 49/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1789Start save model epoch  48\\nOptimizer learning rate =  3.6389007e-05\\nEnd save model epoch  48\\n19417/19417 [==============================] - 3648s 188ms/step - loss: 3.1789 - val_loss: 3.1481\\nEpoch 50/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.2001Start save model epoch  49\\nOptimizer learning rate =  3.6111232e-05\\nEnd save model epoch  49\\n19417/19417 [==============================] - 3665s 189ms/step - loss: 3.2001 - val_loss: 3.1312\\nEpoch 51/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1751Start save model epoch  50\\nOptimizer learning rate =  3.5833455e-05\\nEnd save model epoch  50\\n19417/19417 [==============================] - 3652s 188ms/step - loss: 3.1751 - val_loss: 3.1022\\nEpoch 52/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1779Start save model epoch  51\\nOptimizer learning rate =  3.555568e-05\\nEnd save model epoch  51\\n19417/19417 [==============================] - 3715s 191ms/step - loss: 3.1779 - val_loss: 3.1649\\nEpoch 53/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1792Start save model epoch  52\\nOptimizer learning rate =  3.5277906e-05\\nEnd save model epoch  52\\n19417/19417 [==============================] - 3690s 190ms/step - loss: 3.1792 - val_loss: 3.1396\\nEpoch 54/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1750Start save model epoch  53\\nOptimizer learning rate =  3.500013e-05\\nEnd save model epoch  53\\n19417/19417 [==============================] - 3669s 189ms/step - loss: 3.1750 - val_loss: 3.0579\\nEpoch 55/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1197Start save model epoch  54\\nOptimizer learning rate =  3.4722354e-05\\nEnd save model epoch  54\\n19417/19417 [==============================] - 3654s 188ms/step - loss: 3.1197 - val_loss: 3.0957\\nEpoch 56/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0997Start save model epoch  55\\nOptimizer learning rate =  3.4444576e-05\\nEnd save model epoch  55\\n19417/19417 [==============================] - 3639s 187ms/step - loss: 3.0997 - val_loss: 2.9963\\nEpoch 57/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1009Start save model epoch  56\\nOptimizer learning rate =  3.4166802e-05\\nEnd save model epoch  56\\n19417/19417 [==============================] - 3627s 187ms/step - loss: 3.1009 - val_loss: 3.0458\\nEpoch 58/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1037Start save model epoch  57\\nOptimizer learning rate =  3.3889028e-05\\nEnd save model epoch  57\\n19417/19417 [==============================] - 3759s 194ms/step - loss: 3.1037 - val_loss: 3.0154\\nEpoch 59/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0619Start save model epoch  58\\nOptimizer learning rate =  3.361125e-05\\nEnd save model epoch  58\\n19417/19417 [==============================] - 3666s 189ms/step - loss: 3.0619 - val_loss: 3.0161\\nEpoch 60/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0688Start save model epoch  59\\nOptimizer learning rate =  3.3333476e-05\\nEnd save model epoch  59\\n19417/19417 [==============================] - 3674s 189ms/step - loss: 3.0688 - val_loss: 2.9548\\nEpoch 61/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0665Start save model epoch  60\\nOptimizer learning rate =  3.30557e-05\\nEnd save model epoch  60\\n19417/19417 [==============================] - 3678s 189ms/step - loss: 3.0665 - val_loss: 3.1039\\nEpoch 62/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0440Start save model epoch  61\\nOptimizer learning rate =  3.2777923e-05\\nEnd save model epoch  61\\n19417/19417 [==============================] - 3646s 188ms/step - loss: 3.0440 - val_loss: 3.0805\\nEpoch 63/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0934Start save model epoch  62\\nOptimizer learning rate =  3.2500146e-05\\nEnd save model epoch  62\\n19417/19417 [==============================] - 3775s 194ms/step - loss: 3.0934 - val_loss: 2.9733\\nEpoch 64/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0600Start save model epoch  63\\nOptimizer learning rate =  3.222237e-05\\nEnd save model epoch  63\\n19417/19417 [==============================] - 3687s 190ms/step - loss: 3.0600 - val_loss: 2.9612\\nEpoch 65/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0432Start save model epoch  64\\nOptimizer learning rate =  3.1944597e-05\\nEnd save model epoch  64\\n19417/19417 [==============================] - 3689s 190ms/step - loss: 3.0432 - val_loss: 3.0118\\nEpoch 66/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0233Start save model epoch  65\\nOptimizer learning rate =  3.1666823e-05\\nEnd save model epoch  65\\n19417/19417 [==============================] - 3623s 187ms/step - loss: 3.0233 - val_loss: 2.9341\\nEpoch 67/74\\n19417/19417 [==============================] - ETA: 0s - loss: 3.0780Start save model epoch  66\\nOptimizer learning rate =  3.1389045e-05\\nEnd save model epoch  66\\n19417/19417 [==============================] - 3757s 193ms/step - loss: 3.0780 - val_loss: 2.9593\\nEpoch 68/74\\n 3498/19417 [====>.........................] - ETA: 48:24 - loss: 2.9469\\n\\n\\n\\n\\nEpoch 68/97\\n19417/19417 [==============================] - ETA: 0s - loss: 3.1156Start save model epoch  67\\nOptimizer learning rate =  3.1111274e-05\\nEnd save model epoch  67\\n19417/19417 [==============================] - 3840s 193ms/step - loss: 3.1156 - val_loss: 2.9682\\nEpoch 69/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9867Start save model epoch  68\\nOptimizer learning rate =  3.0833497e-05\\nEnd save model epoch  68\\n19417/19417 [==============================] - 3748s 193ms/step - loss: 2.9867 - val_loss: 2.9669\\nEpoch 70/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9969Start save model epoch  69\\nOptimizer learning rate =  3.0555722e-05\\nEnd save model epoch  69\\n19417/19417 [==============================] - 3727s 192ms/step - loss: 2.9969 - val_loss: 2.8667\\nEpoch 71/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9842Start save model epoch  70\\nOptimizer learning rate =  3.0277946e-05\\nEnd save model epoch  70\\n19417/19417 [==============================] - 3736s 192ms/step - loss: 2.9842 - val_loss: 2.9145\\nEpoch 72/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9537Start save model epoch  71\\nOptimizer learning rate =  3.000017e-05\\nEnd save model epoch  71\\n19417/19417 [==============================] - 3709s 191ms/step - loss: 2.9537 - val_loss: 2.9153\\nEpoch 73/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9650Start save model epoch  72\\nOptimizer learning rate =  2.9722394e-05\\nEnd save model epoch  72\\n19417/19417 [==============================] - 3709s 191ms/step - loss: 2.9650 - val_loss: 2.8977\\nEpoch 74/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9950Start save model epoch  73\\nOptimizer learning rate =  2.944462e-05\\nEnd save model epoch  73\\n19417/19417 [==============================] - 3718s 191ms/step - loss: 2.9950 - val_loss: 2.9954\\nEpoch 75/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9126Start save model epoch  74\\nOptimizer learning rate =  2.9166844e-05\\nEnd save model epoch  74\\n19417/19417 [==============================] - 3768s 194ms/step - loss: 2.9126 - val_loss: 2.8728\\nEpoch 76/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9291Start save model epoch  75\\nOptimizer learning rate =  2.8889068e-05\\nEnd save model epoch  75\\n19417/19417 [==============================] - 3717s 191ms/step - loss: 2.9291 - val_loss: 2.9049\\nEpoch 77/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9458Start save model epoch  76\\nOptimizer learning rate =  2.8611292e-05\\nEnd save model epoch  76\\n19417/19417 [==============================] - 3711s 191ms/step - loss: 2.9458 - val_loss: 2.9015\\nEpoch 78/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9498Start save model epoch  77\\nOptimizer learning rate =  2.8333516e-05\\nEnd save model epoch  77\\n19417/19417 [==============================] - 3729s 192ms/step - loss: 2.9498 - val_loss: 2.8139\\nEpoch 79/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9179Start save model epoch  78\\nOptimizer learning rate =  2.805574e-05\\nEnd save model epoch  78\\n19417/19417 [==============================] - 3642s 188ms/step - loss: 2.9179 - val_loss: 2.8846\\nEpoch 80/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9262Start save model epoch  79\\nOptimizer learning rate =  2.7777965e-05\\nEnd save model epoch  79\\n19417/19417 [==============================] - 3636s 187ms/step - loss: 2.9262 - val_loss: 2.8173\\nEpoch 81/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8855Start save model epoch  80\\nOptimizer learning rate =  2.750019e-05\\nEnd save model epoch  80\\n19417/19417 [==============================] - 3654s 188ms/step - loss: 2.8855 - val_loss: 2.8392\\nEpoch 82/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8939Start save model epoch  81\\nOptimizer learning rate =  2.7222413e-05\\nEnd save model epoch  81\\n19417/19417 [==============================] - 3711s 191ms/step - loss: 2.8939 - val_loss: 2.8766\\nEpoch 83/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8873Start save model epoch  82\\nOptimizer learning rate =  2.694464e-05\\nEnd save model epoch  82\\n19417/19417 [==============================] - 3665s 189ms/step - loss: 2.8873 - val_loss: 2.8077\\nEpoch 84/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8790Start save model epoch  83\\nOptimizer learning rate =  2.6666863e-05\\nEnd save model epoch  83\\n19417/19417 [==============================] - 3669s 189ms/step - loss: 2.8790 - val_loss: 2.8004\\nEpoch 85/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8748Start save model epoch  84\\nOptimizer learning rate =  2.6389087e-05\\nEnd save model epoch  84\\n19417/19417 [==============================] - 3702s 191ms/step - loss: 2.8748 - val_loss: 2.8316\\nEpoch 86/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8816Start save model epoch  85\\nOptimizer learning rate =  2.6111311e-05\\nEnd save model epoch  85\\n19417/19417 [==============================] - 3723s 192ms/step - loss: 2.8816 - val_loss: 2.7907\\nEpoch 87/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8680Start save model epoch  86\\nOptimizer learning rate =  2.5833537e-05\\nEnd save model epoch  86\\n19417/19417 [==============================] - 3730s 192ms/step - loss: 2.8680 - val_loss: 2.8387\\nEpoch 88/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8701Start save model epoch  87\\nOptimizer learning rate =  2.5555759e-05\\nEnd save model epoch  87\\n19417/19417 [==============================] - 3780s 195ms/step - loss: 2.8701 - val_loss: 2.7425\\nEpoch 89/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8219Start save model epoch  88\\nOptimizer learning rate =  2.5277985e-05\\nEnd save model epoch  88\\n19417/19417 [==============================] - 3743s 193ms/step - loss: 2.8219 - val_loss: 2.8169\\nEpoch 90/97\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8651\\n\\n\\nEpoch 90/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.9430Start save model epoch  89\\nOptimizer learning rate =  2.5000207e-05\\nEnd save model epoch  89\\n19417/19417 [==============================] - 3953s 198ms/step - loss: 2.9430 - val_loss: 2.8745\\nEpoch 91/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8203Start save model epoch  90\\nOptimizer learning rate =  2.472243e-05\\nEnd save model epoch  90\\n19417/19417 [==============================] - 3822s 197ms/step - loss: 2.8203 - val_loss: 2.8693\\nEpoch 92/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7926Start save model epoch  91\\nOptimizer learning rate =  2.4444656e-05\\nEnd save model epoch  91\\n19417/19417 [==============================] - 3827s 197ms/step - loss: 2.7926 - val_loss: 2.8483\\nEpoch 93/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8279Start save model epoch  92\\nOptimizer learning rate =  2.416688e-05\\nEnd save model epoch  92\\n19417/19417 [==============================] - 3713s 191ms/step - loss: 2.8279 - val_loss: 2.7135\\nEpoch 94/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8135Start save model epoch  93\\nOptimizer learning rate =  2.3889104e-05\\nEnd save model epoch  93\\n19417/19417 [==============================] - 3644s 188ms/step - loss: 2.8135 - val_loss: 2.7404\\nEpoch 95/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.8087Start save model epoch  94\\nOptimizer learning rate =  2.3611328e-05\\nEnd save model epoch  94\\n19417/19417 [==============================] - 3645s 188ms/step - loss: 2.8087 - val_loss: 2.7645\\nEpoch 96/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7884Start save model epoch  95\\nOptimizer learning rate =  2.3333552e-05\\nEnd save model epoch  95\\n19417/19417 [==============================] - 3612s 186ms/step - loss: 2.7884 - val_loss: 2.7589\\nEpoch 97/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7710Start save model epoch  96\\nOptimizer learning rate =  2.3055778e-05\\nEnd save model epoch  96\\n19417/19417 [==============================] - 3712s 191ms/step - loss: 2.7710 - val_loss: 2.8069\\nEpoch 98/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7796Start save model epoch  97\\nOptimizer learning rate =  2.2778002e-05\\nEnd save model epoch  97\\n19417/19417 [==============================] - 3663s 189ms/step - loss: 2.7796 - val_loss: 2.6974\\nEpoch 99/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7696Start save model epoch  98\\nOptimizer learning rate =  2.2500228e-05\\nEnd save model epoch  98\\n19417/19417 [==============================] - 3686s 190ms/step - loss: 2.7696 - val_loss: 2.7058\\nEpoch 100/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7534Start save model epoch  99\\nOptimizer learning rate =  2.222245e-05\\nEnd save model epoch  99\\n19417/19417 [==============================] - 3682s 190ms/step - loss: 2.7534 - val_loss: 2.7813\\nEpoch 101/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7790Start save model epoch  100\\nOptimizer learning rate =  2.1944676e-05\\nEnd save model epoch  100\\n19417/19417 [==============================] - 3680s 190ms/step - loss: 2.7790 - val_loss: 2.7055\\nEpoch 102/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7529Start save model epoch  101\\nOptimizer learning rate =  2.16669e-05\\nEnd save model epoch  101\\n19417/19417 [==============================] - 3628s 187ms/step - loss: 2.7529 - val_loss: 2.7087\\nEpoch 103/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7688Start save model epoch  102\\nOptimizer learning rate =  2.1389124e-05\\nEnd save model epoch  102\\n19417/19417 [==============================] - 3697s 190ms/step - loss: 2.7688 - val_loss: 2.6796\\nEpoch 104/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7571Start save model epoch  103\\nOptimizer learning rate =  2.111135e-05\\nEnd save model epoch  103\\n19417/19417 [==============================] - 3730s 192ms/step - loss: 2.7571 - val_loss: 2.6883\\nEpoch 105/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7509Start save model epoch  104\\nOptimizer learning rate =  2.0833571e-05\\nEnd save model epoch  104\\n19417/19417 [==============================] - 3706s 191ms/step - loss: 2.7509 - val_loss: 2.7079\\nEpoch 106/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7113Start save model epoch  105\\nOptimizer learning rate =  2.0555797e-05\\nEnd save model epoch  105\\n19417/19417 [==============================] - 3746s 193ms/step - loss: 2.7113 - val_loss: 2.6929\\nEpoch 107/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7183Start save model epoch  106\\nOptimizer learning rate =  2.0278021e-05\\nEnd save model epoch  106\\n19417/19417 [==============================] - 3716s 191ms/step - loss: 2.7183 - val_loss: 2.6718\\nEpoch 108/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7623Start save model epoch  107\\nOptimizer learning rate =  2.0000245e-05\\nEnd save model epoch  107\\n19417/19417 [==============================] - 3754s 193ms/step - loss: 2.7623 - val_loss: 2.5999\\nEpoch 109/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6857Start save model epoch  108\\nOptimizer learning rate =  1.972247e-05\\nEnd save model epoch  108\\n19417/19417 [==============================] - 3744s 193ms/step - loss: 2.6857 - val_loss: 2.6578\\nEpoch 110/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7129Start save model epoch  109\\nOptimizer learning rate =  1.9444695e-05\\nEnd save model epoch  109\\n19417/19417 [==============================] - 3753s 193ms/step - loss: 2.7129 - val_loss: 2.7186\\nEpoch 111/119\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7020Start save model epoch  110\\nOptimizer learning rate =  1.9166919e-05\\nEnd save model epoch  110\\n19417/19417 [==============================] - 3780s 195ms/step - loss: 2.7020 - val_loss: 2.6921\\nEpoch 112/119\\n18573/19417 [===========================>..] - ETA: 2:35 - loss: 2.6791\\n\\n\\nEpoch 112/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.7472Start save model epoch  111\\nOptimizer learning rate =  1.8889143e-05\\nEnd save model epoch  111\\n19417/19417 [==============================] - 3743s 188ms/step - loss: 2.7472 - val_loss: 2.6712\\nEpoch 113/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6876Start save model epoch  112\\nOptimizer learning rate =  1.8611367e-05\\nEnd save model epoch  112\\n19417/19417 [==============================] - 3666s 189ms/step - loss: 2.6876 - val_loss: 2.6248\\nEpoch 114/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6646Start save model epoch  113\\nOptimizer learning rate =  1.8333592e-05\\nEnd save model epoch  113\\n19417/19417 [==============================] - 3657s 188ms/step - loss: 2.6646 - val_loss: 2.6437\\nEpoch 115/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6719Start save model epoch  114\\nOptimizer learning rate =  1.8055816e-05\\nEnd save model epoch  114\\n19417/19417 [==============================] - 3617s 186ms/step - loss: 2.6719 - val_loss: 2.6334\\nEpoch 116/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6825Start save model epoch  115\\nOptimizer learning rate =  1.777804e-05\\nEnd save model epoch  115\\n19417/19417 [==============================] - 3657s 188ms/step - loss: 2.6825 - val_loss: 2.6465\\nEpoch 117/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6771Start save model epoch  116\\nOptimizer learning rate =  1.7500266e-05\\nEnd save model epoch  116\\n19417/19417 [==============================] - 3663s 189ms/step - loss: 2.6771 - val_loss: 2.6368\\nEpoch 118/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6586Start save model epoch  117\\nOptimizer learning rate =  1.7222488e-05\\nEnd save model epoch  117\\n19417/19417 [==============================] - 3610s 186ms/step - loss: 2.6586 - val_loss: 2.5924\\nEpoch 119/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6721Start save model epoch  118\\nOptimizer learning rate =  1.6944714e-05\\nEnd save model epoch  118\\n19417/19417 [==============================] - 3606s 186ms/step - loss: 2.6721 - val_loss: 2.5897\\nEpoch 120/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6362Start save model epoch  119\\nOptimizer learning rate =  1.6666938e-05\\nEnd save model epoch  119\\n19417/19417 [==============================] - 3565s 184ms/step - loss: 2.6362 - val_loss: 2.6119\\nEpoch 121/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6481Start save model epoch  120\\nOptimizer learning rate =  1.6389162e-05\\nEnd save model epoch  120\\n19417/19417 [==============================] - 3569s 184ms/step - loss: 2.6481 - val_loss: 2.6024\\nEpoch 122/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6422Start save model epoch  121\\nOptimizer learning rate =  1.6111388e-05\\nEnd save model epoch  121\\n19417/19417 [==============================] - 3581s 184ms/step - loss: 2.6422 - val_loss: 2.6589\\nEpoch 123/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6004Start save model epoch  122\\nOptimizer learning rate =  1.583361e-05\\nEnd save model epoch  122\\n19417/19417 [==============================] - 3570s 184ms/step - loss: 2.6004 - val_loss: 2.5820\\nEpoch 124/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6425Start save model epoch  123\\nOptimizer learning rate =  1.5555835e-05\\nEnd save model epoch  123\\n19417/19417 [==============================] - 3567s 184ms/step - loss: 2.6425 - val_loss: 2.5258\\nEpoch 125/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6075Start save model epoch  124\\nOptimizer learning rate =  1.527806e-05\\nEnd save model epoch  124\\n19417/19417 [==============================] - 3609s 186ms/step - loss: 2.6075 - val_loss: 2.5576\\nEpoch 126/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6169Start save model epoch  125\\nOptimizer learning rate =  1.5000284e-05\\nEnd save model epoch  125\\n19417/19417 [==============================] - 3563s 184ms/step - loss: 2.6169 - val_loss: 2.6132\\nEpoch 127/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5982Start save model epoch  126\\nOptimizer learning rate =  1.4722508e-05\\nEnd save model epoch  126\\n19417/19417 [==============================] - 3577s 184ms/step - loss: 2.5982 - val_loss: 2.5859\\nEpoch 128/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6180Start save model epoch  127\\nOptimizer learning rate =  1.4444733e-05\\nEnd save model epoch  127\\n19417/19417 [==============================] - 3582s 184ms/step - loss: 2.6180 - val_loss: 2.5634\\nEpoch 129/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6034Start save model epoch  128\\nOptimizer learning rate =  1.4166958e-05\\nEnd save model epoch  128\\n19417/19417 [==============================] - 3621s 187ms/step - loss: 2.6034 - val_loss: 2.5020\\nEpoch 130/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6282Start save model epoch  129\\nOptimizer learning rate =  1.3889181e-05\\nEnd save model epoch  129\\n19417/19417 [==============================] - 3632s 187ms/step - loss: 2.6282 - val_loss: 2.5872\\nEpoch 131/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.6200Start save model epoch  130\\nOptimizer learning rate =  1.3611407e-05\\nEnd save model epoch  130\\n19417/19417 [==============================] - 3582s 184ms/step - loss: 2.6200 - val_loss: 2.5592\\nEpoch 132/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5865Start save model epoch  131\\nOptimizer learning rate =  1.333363e-05\\nEnd save model epoch  131\\n19417/19417 [==============================] - 3641s 188ms/step - loss: 2.5865 - val_loss: 2.5540\\nEpoch 133/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5916Start save model epoch  132\\nOptimizer learning rate =  1.3055855e-05\\nEnd save model epoch  132\\n19417/19417 [==============================] - 3618s 186ms/step - loss: 2.5916 - val_loss: 2.5067\\nEpoch 134/141\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5715Start save model epoch  133\\nOptimizer learning rate =  1.27780795e-05\\nEnd save model epoch  133\\n19417/19417 [==============================] - 3573s 184ms/step - loss: 2.5715 - val_loss: 2.4912\\nEpoch 135/141\\n13057/19417 [===================>..........] - ETA: 18:50 - loss: 2.5874\\n\\n\\nEpoch 135/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5978Start save model epoch  134\\nOptimizer learning rate =  1.25003035e-05\\nEnd save model epoch  134\\n19417/19417 [==============================] - 3782s 190ms/step - loss: 2.5978 - val_loss: 2.4467\\nEpoch 136/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5711Start save model epoch  135\\nOptimizer learning rate =  1.2222528e-05\\nEnd save model epoch  135\\n19417/19417 [==============================] - 3730s 192ms/step - loss: 2.5711 - val_loss: 2.5491\\nEpoch 137/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5562Start save model epoch  136\\nOptimizer learning rate =  1.1944752e-05\\nEnd save model epoch  136\\n19417/19417 [==============================] - 3668s 189ms/step - loss: 2.5562 - val_loss: 2.5270\\nEpoch 138/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5453Start save model epoch  137\\nOptimizer learning rate =  1.1666977e-05\\nEnd save model epoch  137\\n19417/19417 [==============================] - 3730s 192ms/step - loss: 2.5453 - val_loss: 2.5040\\nEpoch 139/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5301Start save model epoch  138\\nOptimizer learning rate =  1.1389202e-05\\nEnd save model epoch  138\\n19417/19417 [==============================] - 3647s 188ms/step - loss: 2.5301 - val_loss: 2.6139\\nEpoch 140/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5560Start save model epoch  139\\nOptimizer learning rate =  1.1111425e-05\\nEnd save model epoch  139\\n19417/19417 [==============================] - 3653s 188ms/step - loss: 2.5560 - val_loss: 2.4628\\nEpoch 141/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4745Start save model epoch  140\\nOptimizer learning rate =  1.0833651e-05\\nEnd save model epoch  140\\n19417/19417 [==============================] - 3687s 190ms/step - loss: 2.4745 - val_loss: 2.4744\\nEpoch 142/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5387Start save model epoch  141\\nOptimizer learning rate =  1.0555874e-05\\nEnd save model epoch  141\\n19417/19417 [==============================] - 3607s 186ms/step - loss: 2.5387 - val_loss: 2.5585\\nEpoch 143/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5262Start save model epoch  142\\nOptimizer learning rate =  1.0278099e-05\\nEnd save model epoch  142\\n19417/19417 [==============================] - 3591s 185ms/step - loss: 2.5262 - val_loss: 2.5120\\nEpoch 144/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5453Start save model epoch  143\\nOptimizer learning rate =  1.0000323e-05\\nEnd save model epoch  143\\n19417/19417 [==============================] - 3682s 190ms/step - loss: 2.5453 - val_loss: 2.4891\\nEpoch 145/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5279Start save model epoch  144\\nOptimizer learning rate =  9.7225475e-06\\nEnd save model epoch  144\\n19417/19417 [==============================] - 3672s 189ms/step - loss: 2.5279 - val_loss: 2.4361\\nEpoch 146/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5149Start save model epoch  145\\nOptimizer learning rate =  9.444771e-06\\nEnd save model epoch  145\\n19417/19417 [==============================] - 3708s 191ms/step - loss: 2.5149 - val_loss: 2.5178\\nEpoch 147/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5181Start save model epoch  146\\nOptimizer learning rate =  9.166996e-06\\nEnd save model epoch  146\\n19417/19417 [==============================] - 3757s 193ms/step - loss: 2.5181 - val_loss: 2.5031\\nEpoch 148/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5391Start save model epoch  147\\nOptimizer learning rate =  8.88922e-06\\nEnd save model epoch  147\\n19417/19417 [==============================] - 3782s 195ms/step - loss: 2.5391 - val_loss: 2.5232\\nEpoch 149/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4903Start save model epoch  148\\nOptimizer learning rate =  8.611445e-06\\nEnd save model epoch  148\\n19417/19417 [==============================] - 3660s 189ms/step - loss: 2.4903 - val_loss: 2.5347\\nEpoch 150/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4832Start save model epoch  149\\nOptimizer learning rate =  8.333669e-06\\nEnd save model epoch  149\\n19417/19417 [==============================] - 3719s 192ms/step - loss: 2.4832 - val_loss: 2.5169\\nEpoch 151/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5030Start save model epoch  150\\nOptimizer learning rate =  8.055894e-06\\nEnd save model epoch  150\\n19417/19417 [==============================] - 3734s 192ms/step - loss: 2.5030 - val_loss: 2.4333\\nEpoch 152/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4848Start save model epoch  151\\nOptimizer learning rate =  7.778118e-06\\nEnd save model epoch  151\\n19417/19417 [==============================] - 3787s 195ms/step - loss: 2.4848 - val_loss: 2.4933\\nEpoch 153/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4904Start save model epoch  152\\nOptimizer learning rate =  7.5003427e-06\\nEnd save model epoch  152\\n19417/19417 [==============================] - 3750s 193ms/step - loss: 2.4904 - val_loss: 2.4876\\nEpoch 154/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4915Start save model epoch  153\\nOptimizer learning rate =  7.222567e-06\\nEnd save model epoch  153\\n19417/19417 [==============================] - 3775s 194ms/step - loss: 2.4915 - val_loss: 2.4470\\nEpoch 155/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4726Start save model epoch  154\\nOptimizer learning rate =  6.9447915e-06\\nEnd save model epoch  154\\n19417/19417 [==============================] - 3729s 192ms/step - loss: 2.4726 - val_loss: 2.3946\\nEpoch 156/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4573Start save model epoch  155\\nOptimizer learning rate =  6.667016e-06\\nEnd save model epoch  155\\n19417/19417 [==============================] - 3772s 194ms/step - loss: 2.4573 - val_loss: 2.4740\\nEpoch 157/164\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4761Start save model epoch  156\\nOptimizer learning rate =  6.38924e-06\\nEnd save model epoch  156\\n19417/19417 [==============================] - 3657s 188ms/step - loss: 2.4761 - val_loss: 2.4608\\nEpoch 158/164\\n  242/19417 [..............................] - ETA: 59:39 - loss: 2.6979\\n\\nEpoch 158/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.5066Start save model epoch  157\\nOptimizer learning rate =  6.1114642e-06\\nEnd save model epoch  157\\n19417/19417 [==============================] - 3918s 197ms/step - loss: 2.5066 - val_loss: 2.4759\\nEpoch 159/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4530Start save model epoch  158\\nOptimizer learning rate =  5.8336886e-06\\nEnd save model epoch  158\\n19417/19417 [==============================] - 3807s 196ms/step - loss: 2.4530 - val_loss: 2.4151\\nEpoch 160/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4528Start save model epoch  159\\nOptimizer learning rate =  5.555913e-06\\nEnd save model epoch  159\\n19417/19417 [==============================] - 3841s 198ms/step - loss: 2.4528 - val_loss: 2.4392\\nEpoch 161/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4363Start save model epoch  160\\nOptimizer learning rate =  5.2781375e-06\\nEnd save model epoch  160\\n19417/19417 [==============================] - 3876s 200ms/step - loss: 2.4363 - val_loss: 2.4095\\nEpoch 162/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4451Start save model epoch  161\\nOptimizer learning rate =  5.000362e-06\\nEnd save model epoch  161\\n19417/19417 [==============================] - 3852s 198ms/step - loss: 2.4451 - val_loss: 2.4412\\nEpoch 163/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4215Start save model epoch  162\\nOptimizer learning rate =  4.7225863e-06\\nEnd save model epoch  162\\n19417/19417 [==============================] - 3752s 193ms/step - loss: 2.4215 - val_loss: 2.4478\\nEpoch 164/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4257Start save model epoch  163\\nOptimizer learning rate =  4.4448107e-06\\nEnd save model epoch  163\\n19417/19417 [==============================] - 3715s 191ms/step - loss: 2.4257 - val_loss: 2.4399\\nEpoch 165/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4184Start save model epoch  164\\nOptimizer learning rate =  4.167035e-06\\nEnd save model epoch  164\\n19417/19417 [==============================] - 3692s 190ms/step - loss: 2.4184 - val_loss: 2.3834\\nEpoch 166/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4272Start save model epoch  165\\nOptimizer learning rate =  3.889259e-06\\nEnd save model epoch  165\\n19417/19417 [==============================] - 3733s 192ms/step - loss: 2.4272 - val_loss: 2.4276\\nEpoch 167/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4169Start save model epoch  166\\nOptimizer learning rate =  3.6114834e-06\\nEnd save model epoch  166\\n19417/19417 [==============================] - 3738s 192ms/step - loss: 2.4169 - val_loss: 2.4929\\nEpoch 168/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.3936Start save model epoch  167\\nOptimizer learning rate =  3.3337078e-06\\nEnd save model epoch  167\\n19417/19417 [==============================] - 3784s 195ms/step - loss: 2.3936 - val_loss: 2.5118\\nEpoch 169/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4129Start save model epoch  168\\nOptimizer learning rate =  3.0559322e-06\\nEnd save model epoch  168\\n19417/19417 [==============================] - 3776s 194ms/step - loss: 2.4129 - val_loss: 2.3711\\nEpoch 170/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4288Start save model epoch  169\\nOptimizer learning rate =  2.7781566e-06\\nEnd save model epoch  169\\n19417/19417 [==============================] - 3761s 194ms/step - loss: 2.4288 - val_loss: 2.4491\\nEpoch 171/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.3722Start save model epoch  170\\nOptimizer learning rate =  2.500381e-06\\nEnd save model epoch  170\\n19417/19417 [==============================] - 3757s 193ms/step - loss: 2.3722 - val_loss: 2.3741\\nEpoch 172/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4204Start save model epoch  171\\nOptimizer learning rate =  2.2226054e-06\\nEnd save model epoch  171\\n19417/19417 [==============================] - 3726s 192ms/step - loss: 2.4204 - val_loss: 2.4465\\nEpoch 173/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4232Start save model epoch  172\\nOptimizer learning rate =  1.9448298e-06\\nEnd save model epoch  172\\n19417/19417 [==============================] - 3799s 196ms/step - loss: 2.4232 - val_loss: 2.3988\\nEpoch 174/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.3918Start save model epoch  173\\nOptimizer learning rate =  1.6670542e-06\\nEnd save model epoch  173\\n19417/19417 [==============================] - 3720s 192ms/step - loss: 2.3918 - val_loss: 2.3730\\nEpoch 175/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.3692Start save model epoch  174\\nOptimizer learning rate =  1.3892786e-06\\nEnd save model epoch  174\\n19417/19417 [==============================] - 3816s 197ms/step - loss: 2.3692 - val_loss: 2.3785\\nEpoch 176/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.3931Start save model epoch  175\\nOptimizer learning rate =  1.111503e-06\\nEnd save model epoch  175\\n19417/19417 [==============================] - 3826s 197ms/step - loss: 2.3931 - val_loss: 2.3465\\nEpoch 177/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4166Start save model epoch  176\\nOptimizer learning rate =  8.337274e-07\\nEnd save model epoch  176\\n19417/19417 [==============================] - 3815s 196ms/step - loss: 2.4166 - val_loss: 2.4141\\nEpoch 178/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.3912Start save model epoch  177\\nOptimizer learning rate =  5.5595183e-07\\nEnd save model epoch  177\\n19417/19417 [==============================] - 3747s 193ms/step - loss: 2.3912 - val_loss: 2.3660\\nEpoch 179/180\\n19417/19417 [==============================] - ETA: 0s - loss: 2.4172Start save model epoch  178\\nOptimizer learning rate =  2.7817586e-07\\nEnd save model epoch  178\\n19417/19417 [==============================] - 3760s 194ms/step - loss: 2.4172 - val_loss: 2.3448\\nEpoch 180/180\\n 7913/19417 [===========>..................] - ETA: 35:26 - loss: 2.4216\\n\\n\\n\\n'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Epoch 1/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 5.6922Start save model epoch  0\n",
        "Optimizer learning rate =  4.972224e-05\n",
        "End save model epoch  0\n",
        "19417/19417 [==============================] - 3936s 198ms/step - loss: 5.6922 - val_loss: 5.2161\n",
        "Epoch 2/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 4.8180Start save model epoch  1\n",
        "Optimizer learning rate =  4.944446e-05\n",
        "End save model epoch  1\n",
        "19417/19417 [==============================] - 3830s 197ms/step - loss: 4.8180 - val_loss: 4.6530\n",
        "Epoch 3/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 4.5446Start save model epoch  2\n",
        "Optimizer learning rate =  4.9166687e-05\n",
        "End save model epoch  2\n",
        "19417/19417 [==============================] - 3808s 196ms/step - loss: 4.5446 - val_loss: 4.3152\n",
        "Epoch 4/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 4.2730Start save model epoch  3\n",
        "Optimizer learning rate =  4.8888913e-05\n",
        "End save model epoch  3\n",
        "19417/19417 [==============================] - 3729s 192ms/step - loss: 4.2730 - val_loss: 4.1824\n",
        "Epoch 5/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 4.2106Start save model epoch  4\n",
        "Optimizer learning rate =  4.8611135e-05\n",
        "End save model epoch  4\n",
        "19417/19417 [==============================] - 3791s 195ms/step - loss: 4.2106 - val_loss: 4.0386\n",
        "Epoch 6/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 4.1498Start save model epoch  5\n",
        "Optimizer learning rate =  4.833336e-05\n",
        "End save model epoch  5\n",
        "19417/19417 [==============================] - 3840s 198ms/step - loss: 4.1498 - val_loss: 4.0779\n",
        "Epoch 7/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 4.0457Start save model epoch  6\n",
        "Optimizer learning rate =  4.8055583e-05\n",
        "End save model epoch  6\n",
        "19417/19417 [==============================] - 3791s 195ms/step - loss: 4.0457 - val_loss: 3.9875\n",
        "Epoch 8/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.9871Start save model epoch  7\n",
        "Optimizer learning rate =  4.7777805e-05\n",
        "End save model epoch  7\n",
        "19417/19417 [==============================] - 3745s 193ms/step - loss: 3.9871 - val_loss: 3.8995\n",
        "Epoch 9/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.9782Start save model epoch  8\n",
        "Optimizer learning rate =  4.750003e-05\n",
        "End save model epoch  8\n",
        "19417/19417 [==============================] - 3833s 197ms/step - loss: 3.9782 - val_loss: 3.8293\n",
        "Epoch 10/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.8852Start save model epoch  9\n",
        "Optimizer learning rate =  4.7222256e-05\n",
        "End save model epoch  9\n",
        "19417/19417 [==============================] - 3738s 192ms/step - loss: 3.8852 - val_loss: 3.8870\n",
        "Epoch 11/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.8409Start save model epoch  10\n",
        "Optimizer learning rate =  4.694448e-05\n",
        "End save model epoch  10\n",
        "19417/19417 [==============================] - 3829s 197ms/step - loss: 3.8409 - val_loss: 3.7197\n",
        "Epoch 12/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.8255Start save model epoch  11\n",
        "Optimizer learning rate =  4.6666704e-05\n",
        "End save model epoch  11\n",
        "19417/19417 [==============================] - 3839s 198ms/step - loss: 3.8255 - val_loss: 3.7656\n",
        "Epoch 13/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.8343Start save model epoch  12\n",
        "Optimizer learning rate =  4.638893e-05\n",
        "End save model epoch  12\n",
        "19417/19417 [==============================] - 3780s 195ms/step - loss: 3.8343 - val_loss: 3.6481\n",
        "Epoch 14/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.7529Start save model epoch  13\n",
        "Optimizer learning rate =  4.6111152e-05\n",
        "End save model epoch  13\n",
        "19417/19417 [==============================] - 3814s 196ms/step - loss: 3.7529 - val_loss: 3.6738\n",
        "Epoch 15/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.7644Start save model epoch  14\n",
        "Optimizer learning rate =  4.5833378e-05\n",
        "End save model epoch  14\n",
        "19417/19417 [==============================] - 3837s 198ms/step - loss: 3.7644 - val_loss: 3.7138\n",
        "Epoch 16/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.7273Start save model epoch  15\n",
        "Optimizer learning rate =  4.5555604e-05\n",
        "End save model epoch  15\n",
        "19417/19417 [==============================] - 3862s 199ms/step - loss: 3.7273 - val_loss: 3.5868\n",
        "Epoch 17/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.7104Start save model epoch  16\n",
        "Optimizer learning rate =  4.5277826e-05\n",
        "End save model epoch  16\n",
        "19417/19417 [==============================] - 3830s 197ms/step - loss: 3.7104 - val_loss: 3.6098\n",
        "Epoch 18/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.7376Start save model epoch  17\n",
        "Optimizer learning rate =  4.500005e-05\n",
        "End save model epoch  17\n",
        "19417/19417 [==============================] - 3848s 198ms/step - loss: 3.7376 - val_loss: 3.6834\n",
        "Epoch 19/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.7163Start save model epoch  18\n",
        "Optimizer learning rate =  4.4722277e-05\n",
        "End save model epoch  18\n",
        "19417/19417 [==============================] - 3754s 193ms/step - loss: 3.7163 - val_loss: 3.6179\n",
        "Epoch 20/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.6676Start save model epoch  19\n",
        "Optimizer learning rate =  4.44445e-05\n",
        "End save model epoch  19\n",
        "19417/19417 [==============================] - 3824s 197ms/step - loss: 3.6676 - val_loss: 3.6925\n",
        "Epoch 21/30\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.6438Start save model epoch  20\n",
        "Optimizer learning rate =  4.4166725e-05\n",
        "End save model epoch  20\n",
        "19417/19417 [==============================] - 3869s 199ms/step - loss: 3.6438 - val_loss: 3.5622\n",
        "Epoch 22/30\n",
        "19110/19417 [============================>.] - ETA: 57s - loss: 3.6374\n",
        "\n",
        "\n",
        "\n",
        "Epoch 22/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.7446Start save model epoch  21\n",
        "Optimizer learning rate =  4.3888947e-05\n",
        "End save model epoch  21\n",
        "19417/19417 [==============================] - 3829s 192ms/step - loss: 3.7446 - val_loss: 3.6213\n",
        "Epoch 23/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.6621Start save model epoch  22\n",
        "Optimizer learning rate =  4.3611173e-05\n",
        "End save model epoch  22\n",
        "19417/19417 [==============================] - 3745s 193ms/step - loss: 3.6621 - val_loss: 3.5728\n",
        "Epoch 24/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.6345Start save model epoch  23\n",
        "Optimizer learning rate =  4.33334e-05\n",
        "End save model epoch  23\n",
        "19417/19417 [==============================] - 3800s 196ms/step - loss: 3.6345 - val_loss: 3.5487\n",
        "Epoch 25/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.6015Start save model epoch  24\n",
        "Optimizer learning rate =  4.3055625e-05\n",
        "End save model epoch  24\n",
        "19417/19417 [==============================] - 3802s 196ms/step - loss: 3.6015 - val_loss: 3.4806\n",
        "Epoch 26/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.6191Start save model epoch  25\n",
        "Optimizer learning rate =  4.2777847e-05\n",
        "End save model epoch  25\n",
        "19417/19417 [==============================] - 3784s 195ms/step - loss: 3.6191 - val_loss: 3.4558\n",
        "Epoch 27/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.5649Start save model epoch  26\n",
        "Optimizer learning rate =  4.250007e-05\n",
        "End save model epoch  26\n",
        "19417/19417 [==============================] - 3702s 191ms/step - loss: 3.5649 - val_loss: 3.3910\n",
        "Epoch 28/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.5401Start save model epoch  27\n",
        "Optimizer learning rate =  4.2222295e-05\n",
        "End save model epoch  27\n",
        "19417/19417 [==============================] - 3710s 191ms/step - loss: 3.5401 - val_loss: 3.4727\n",
        "Epoch 29/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.5013Start save model epoch  28\n",
        "Optimizer learning rate =  4.194452e-05\n",
        "End save model epoch  28\n",
        "19417/19417 [==============================] - 3751s 193ms/step - loss: 3.5013 - val_loss: 3.4204\n",
        "Epoch 30/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.5032Start save model epoch  29\n",
        "Optimizer learning rate =  4.1666743e-05\n",
        "End save model epoch  29\n",
        "19417/19417 [==============================] - 3754s 193ms/step - loss: 3.5032 - val_loss: 3.3860\n",
        "Epoch 31/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.4825Start save model epoch  30\n",
        "Optimizer learning rate =  4.138897e-05\n",
        "End save model epoch  30\n",
        "19417/19417 [==============================] - 3816s 197ms/step - loss: 3.4825 - val_loss: 3.4034\n",
        "Epoch 32/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.4346Start save model epoch  31\n",
        "Optimizer learning rate =  4.1111194e-05\n",
        "End save model epoch  31\n",
        "19417/19417 [==============================] - 3782s 195ms/step - loss: 3.4346 - val_loss: 3.3916\n",
        "Epoch 33/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.4406Start save model epoch  32\n",
        "Optimizer learning rate =  4.083342e-05\n",
        "End save model epoch  32\n",
        "19417/19417 [==============================] - 3798s 196ms/step - loss: 3.4406 - val_loss: 3.3293\n",
        "Epoch 34/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3830Start save model epoch  33\n",
        "Optimizer learning rate =  4.0555642e-05\n",
        "End save model epoch  33\n",
        "19417/19417 [==============================] - 3754s 193ms/step - loss: 3.3830 - val_loss: 3.2969\n",
        "Epoch 35/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.4111Start save model epoch  34\n",
        "Optimizer learning rate =  4.0277864e-05\n",
        "End save model epoch  34\n",
        "19417/19417 [==============================] - 3797s 196ms/step - loss: 3.4111 - val_loss: 3.3084\n",
        "Epoch 36/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3829Start save model epoch  35\n",
        "Optimizer learning rate =  4.000009e-05\n",
        "End save model epoch  35\n",
        "19417/19417 [==============================] - 3846s 198ms/step - loss: 3.3829 - val_loss: 3.2943\n",
        "Epoch 37/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3647Start save model epoch  36\n",
        "Optimizer learning rate =  3.9722316e-05\n",
        "End save model epoch  36\n",
        "19417/19417 [==============================] - 3851s 198ms/step - loss: 3.3647 - val_loss: 3.3300\n",
        "Epoch 38/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3694Start save model epoch  37\n",
        "Optimizer learning rate =  3.944454e-05\n",
        "End save model epoch  37\n",
        "19417/19417 [==============================] - 3795s 195ms/step - loss: 3.3694 - val_loss: 3.2008\n",
        "Epoch 39/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3586Start save model epoch  38\n",
        "Optimizer learning rate =  3.9166764e-05\n",
        "End save model epoch  38\n",
        "19417/19417 [==============================] - 3884s 200ms/step - loss: 3.3586 - val_loss: 3.2105\n",
        "Epoch 40/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3728Start save model epoch  39\n",
        "Optimizer learning rate =  3.8888986e-05\n",
        "End save model epoch  39\n",
        "19417/19417 [==============================] - 3817s 197ms/step - loss: 3.3728 - val_loss: 3.2700\n",
        "Epoch 41/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2994Start save model epoch  40\n",
        "Optimizer learning rate =  3.861121e-05\n",
        "End save model epoch  40\n",
        "19417/19417 [==============================] - 3788s 195ms/step - loss: 3.2994 - val_loss: 3.2454\n",
        "Epoch 42/51\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3345Start save model epoch  41\n",
        "Optimizer learning rate =  3.8333437e-05\n",
        "End save model epoch  41\n",
        "19417/19417 [==============================] - 3778s 195ms/step - loss: 3.3345 - val_loss: 3.1783\n",
        "Epoch 43/51\n",
        "  694/19417 [>.............................] - ETA: 59:29 - loss: 3.4326\n",
        "\n",
        "Epoch 43/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3956Start save model epoch  42\n",
        "Optimizer learning rate =  3.805566e-05\n",
        "End save model epoch  42\n",
        "19417/19417 [==============================] - 4167s 209ms/step - loss: 3.3956 - val_loss: 3.2789\n",
        "Epoch 44/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.3323Start save model epoch  43\n",
        "Optimizer learning rate =  3.7777885e-05\n",
        "End save model epoch  43\n",
        "19417/19417 [==============================] - 4012s 207ms/step - loss: 3.3323 - val_loss: 3.2746\n",
        "Epoch 45/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2965Start save model epoch  44\n",
        "Optimizer learning rate =  3.750011e-05\n",
        "End save model epoch  44\n",
        "19417/19417 [==============================] - 4043s 208ms/step - loss: 3.2965 - val_loss: 3.2737\n",
        "Epoch 46/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2611Start save model epoch  45\n",
        "Optimizer learning rate =  3.7222333e-05\n",
        "End save model epoch  45\n",
        "19417/19417 [==============================] - 4018s 207ms/step - loss: 3.2611 - val_loss: 3.1583\n",
        "Epoch 47/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2878Start save model epoch  46\n",
        "Optimizer learning rate =  3.694456e-05\n",
        "End save model epoch  46\n",
        "19417/19417 [==============================] - 3994s 206ms/step - loss: 3.2878 - val_loss: 3.1686\n",
        "Epoch 48/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2595Start save model epoch  47\n",
        "Optimizer learning rate =  3.666678e-05\n",
        "End save model epoch  47\n",
        "19417/19417 [==============================] - 3994s 206ms/step - loss: 3.2595 - val_loss: 3.1826\n",
        "Epoch 49/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2148Start save model epoch  48\n",
        "Optimizer learning rate =  3.6389007e-05\n",
        "End save model epoch  48\n",
        "19417/19417 [==============================] - 3998s 206ms/step - loss: 3.2148 - val_loss: 3.1843\n",
        "Epoch 50/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2061Start save model epoch  49\n",
        "Optimizer learning rate =  3.6111232e-05\n",
        "End save model epoch  49\n",
        "19417/19417 [==============================] - 3993s 206ms/step - loss: 3.2061 - val_loss: 3.2404\n",
        "Epoch 51/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2656Start save model epoch  50\n",
        "Optimizer learning rate =  3.5833455e-05\n",
        "End save model epoch  50\n",
        "19417/19417 [==============================] - 3994s 206ms/step - loss: 3.2656 - val_loss: 3.0325\n",
        "Epoch 52/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2231Start save model epoch  51\n",
        "Optimizer learning rate =  3.555568e-05\n",
        "End save model epoch  51\n",
        "19417/19417 [==============================] - 3988s 205ms/step - loss: 3.2231 - val_loss: 3.0876\n",
        "Epoch 53/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2183Start save model epoch  52\n",
        "Optimizer learning rate =  3.5277902e-05\n",
        "End save model epoch  52\n",
        "19417/19417 [==============================] - 4003s 206ms/step - loss: 3.2183 - val_loss: 3.1248\n",
        "Epoch 54/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1414Start save model epoch  53\n",
        "Optimizer learning rate =  3.5000132e-05\n",
        "End save model epoch  53\n",
        "19417/19417 [==============================] - 3999s 206ms/step - loss: 3.1414 - val_loss: 3.1112\n",
        "Epoch 55/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1755Start save model epoch  54\n",
        "Optimizer learning rate =  3.4722354e-05\n",
        "End save model epoch  54\n",
        "19417/19417 [==============================] - 3994s 206ms/step - loss: 3.1755 - val_loss: 3.1104\n",
        "Epoch 56/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1547Start save model epoch  55\n",
        "Optimizer learning rate =  3.444458e-05\n",
        "End save model epoch  55\n",
        "19417/19417 [==============================] - 4084s 210ms/step - loss: 3.1547 - val_loss: 3.0524\n",
        "Epoch 57/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1595Start save model epoch  56\n",
        "Optimizer learning rate =  3.4166802e-05\n",
        "End save model epoch  56\n",
        "19417/19417 [==============================] - 4024s 207ms/step - loss: 3.1595 - val_loss: 3.1124\n",
        "Epoch 58/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1837Start save model epoch  57\n",
        "Optimizer learning rate =  3.3889028e-05\n",
        "End save model epoch  57\n",
        "19417/19417 [==============================] - 4048s 208ms/step - loss: 3.1837 - val_loss: 3.0796\n",
        "Epoch 59/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1408Start save model epoch  58\n",
        "Optimizer learning rate =  3.3611253e-05\n",
        "End save model epoch  58\n",
        "19417/19417 [==============================] - 4051s 209ms/step - loss: 3.1408 - val_loss: 3.1243\n",
        "Epoch 60/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1329Start save model epoch  59\n",
        "Optimizer learning rate =  3.3333476e-05\n",
        "End save model epoch  59\n",
        "19417/19417 [==============================] - 4030s 208ms/step - loss: 3.1329 - val_loss: 2.9879\n",
        "Epoch 61/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1329Start save model epoch  60\n",
        "Optimizer learning rate =  3.30557e-05\n",
        "End save model epoch  60\n",
        "19417/19417 [==============================] - 3981s 205ms/step - loss: 3.1329 - val_loss: 3.0376\n",
        "Epoch 62/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1546Start save model epoch  61\n",
        "Optimizer learning rate =  3.2777923e-05\n",
        "End save model epoch  61\n",
        "19417/19417 [==============================] - 4033s 208ms/step - loss: 3.1546 - val_loss: 2.9813\n",
        "Epoch 63/72\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1302Start save model epoch  62\n",
        "Optimizer learning rate =  3.250015e-05\n",
        "End save model epoch  62\n",
        "19417/19417 [==============================] - 4020s 207ms/step - loss: 3.1302 - val_loss: 2.9018\n",
        "Epoch 64/72\n",
        " 3600/19417 [====>.........................] - ETA: 52:50 - loss: 3.1251\n",
        "\n",
        "Epoch 64/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.2231Start save model epoch  63\n",
        "Optimizer learning rate =  3.2222375e-05\n",
        "End save model epoch  63\n",
        "19417/19417 [==============================] - 3934s 198ms/step - loss: 3.2231 - val_loss: 3.0977\n",
        "Epoch 65/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1367Start save model epoch  64\n",
        "Optimizer learning rate =  3.1944597e-05\n",
        "End save model epoch  64\n",
        "19417/19417 [==============================] - 3828s 197ms/step - loss: 3.1367 - val_loss: 3.0479\n",
        "Epoch 66/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.1119Start save model epoch  65\n",
        "Optimizer learning rate =  3.1666823e-05\n",
        "End save model epoch  65\n",
        "19417/19417 [==============================] - 3803s 196ms/step - loss: 3.1119 - val_loss: 3.0071\n",
        "Epoch 67/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0642Start save model epoch  66\n",
        "Optimizer learning rate =  3.1389045e-05\n",
        "End save model epoch  66\n",
        "19417/19417 [==============================] - 3773s 194ms/step - loss: 3.0642 - val_loss: 2.9904\n",
        "Epoch 68/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0735Start save model epoch  67\n",
        "Optimizer learning rate =  3.111127e-05\n",
        "End save model epoch  67\n",
        "19417/19417 [==============================] - 3728s 192ms/step - loss: 3.0735 - val_loss: 2.9921\n",
        "Epoch 69/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0711Start save model epoch  68\n",
        "Optimizer learning rate =  3.0833497e-05\n",
        "End save model epoch  68\n",
        "19417/19417 [==============================] - 3781s 195ms/step - loss: 3.0711 - val_loss: 2.9452\n",
        "Epoch 70/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0389Start save model epoch  69\n",
        "Optimizer learning rate =  3.055572e-05\n",
        "End save model epoch  69\n",
        "19417/19417 [==============================] - 3752s 193ms/step - loss: 3.0389 - val_loss: 3.0024\n",
        "Epoch 71/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0037Start save model epoch  70\n",
        "Optimizer learning rate =  3.0277944e-05\n",
        "End save model epoch  70\n",
        "19417/19417 [==============================] - 3754s 193ms/step - loss: 3.0037 - val_loss: 2.9549\n",
        "Epoch 72/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0457Start save model epoch  71\n",
        "Optimizer learning rate =  3.0000168e-05\n",
        "End save model epoch  71\n",
        "19417/19417 [==============================] - 3748s 193ms/step - loss: 3.0457 - val_loss: 2.9619\n",
        "Epoch 73/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0322Start save model epoch  72\n",
        "Optimizer learning rate =  2.9722392e-05\n",
        "End save model epoch  72\n",
        "19417/19417 [==============================] - 3759s 194ms/step - loss: 3.0322 - val_loss: 3.0170\n",
        "Epoch 74/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0077Start save model epoch  73\n",
        "Optimizer learning rate =  2.9444616e-05\n",
        "End save model epoch  73\n",
        "19417/19417 [==============================] - 3804s 196ms/step - loss: 3.0077 - val_loss: 2.9991\n",
        "Epoch 75/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9987Start save model epoch  74\n",
        "Optimizer learning rate =  2.9166842e-05\n",
        "End save model epoch  74\n",
        "19417/19417 [==============================] - 3847s 198ms/step - loss: 2.9987 - val_loss: 3.0218\n",
        "Epoch 76/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0278Start save model epoch  75\n",
        "Optimizer learning rate =  2.8889064e-05\n",
        "End save model epoch  75\n",
        "19417/19417 [==============================] - 3780s 195ms/step - loss: 3.0278 - val_loss: 2.9013\n",
        "Epoch 77/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0112Start save model epoch  76\n",
        "Optimizer learning rate =  2.861129e-05\n",
        "End save model epoch  76\n",
        "19417/19417 [==============================] - 3775s 194ms/step - loss: 3.0112 - val_loss: 2.9667\n",
        "Epoch 78/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9643Start save model epoch  77\n",
        "Optimizer learning rate =  2.8333516e-05\n",
        "End save model epoch  77\n",
        "19417/19417 [==============================] - 3779s 195ms/step - loss: 2.9643 - val_loss: 2.9515\n",
        "Epoch 79/93\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9768Start save model epoch  78\n",
        "Optimizer learning rate =  2.8055738e-05\n",
        "End save model epoch  78\n",
        "19417/19417 [==============================] - 3726s 192ms/step - loss: 2.9768 - val_loss: 2.8969\n",
        "Epoch 80/93\n",
        " 3672/19417 [====>.........................] - ETA: 48:14 - loss: 3.0621\n",
        "\n",
        "Epoch 80/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 3.0467Start save model epoch  79\n",
        "Optimizer learning rate =  2.7777964e-05\n",
        "End save model epoch  79\n",
        "19417/19417 [==============================] - 3832s 192ms/step - loss: 3.0467 - val_loss: 2.9601\n",
        "Epoch 81/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9642Start save model epoch  80\n",
        "Optimizer learning rate =  2.7500188e-05\n",
        "End save model epoch  80\n",
        "19417/19417 [==============================] - 3732s 192ms/step - loss: 2.9642 - val_loss: 2.8721\n",
        "Epoch 82/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9248Start save model epoch  81\n",
        "Optimizer learning rate =  2.7222412e-05\n",
        "End save model epoch  81\n",
        "19417/19417 [==============================] - 3735s 192ms/step - loss: 2.9248 - val_loss: 2.8670\n",
        "Epoch 83/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9237Start save model epoch  82\n",
        "Optimizer learning rate =  2.6944637e-05\n",
        "End save model epoch  82\n",
        "19417/19417 [==============================] - 3691s 190ms/step - loss: 2.9237 - val_loss: 2.8790\n",
        "Epoch 84/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9417Start save model epoch  83\n",
        "Optimizer learning rate =  2.6666861e-05\n",
        "End save model epoch  83\n",
        "19417/19417 [==============================] - 3783s 195ms/step - loss: 2.9417 - val_loss: 2.9022\n",
        "Epoch 85/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8973Start save model epoch  84\n",
        "Optimizer learning rate =  2.6389085e-05\n",
        "End save model epoch  84\n",
        "19417/19417 [==============================] - 3703s 191ms/step - loss: 2.8973 - val_loss: 2.8604\n",
        "Epoch 86/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9158Start save model epoch  85\n",
        "Optimizer learning rate =  2.611131e-05\n",
        "End save model epoch  85\n",
        "19417/19417 [==============================] - 3757s 193ms/step - loss: 2.9158 - val_loss: 2.9124\n",
        "Epoch 87/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.9148Start save model epoch  86\n",
        "Optimizer learning rate =  2.5833533e-05\n",
        "End save model epoch  86\n",
        "19417/19417 [==============================] - 3768s 194ms/step - loss: 2.9148 - val_loss: 2.8472\n",
        "Epoch 88/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8825Start save model epoch  87\n",
        "Optimizer learning rate =  2.5555759e-05\n",
        "End save model epoch  87\n",
        "19417/19417 [==============================] - 3767s 194ms/step - loss: 2.8825 - val_loss: 2.8804\n",
        "Epoch 89/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8965Start save model epoch  88\n",
        "Optimizer learning rate =  2.5277983e-05\n",
        "End save model epoch  88\n",
        "19417/19417 [==============================] - 3762s 194ms/step - loss: 2.8965 - val_loss: 2.8711\n",
        "Epoch 90/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8561Start save model epoch  89\n",
        "Optimizer learning rate =  2.5000207e-05\n",
        "End save model epoch  89\n",
        "19417/19417 [==============================] - 3816s 197ms/step - loss: 2.8561 - val_loss: 2.7870\n",
        "Epoch 91/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8834Start save model epoch  90\n",
        "Optimizer learning rate =  2.4722432e-05\n",
        "End save model epoch  90\n",
        "19417/19417 [==============================] - 3806s 196ms/step - loss: 2.8834 - val_loss: 2.8637\n",
        "Epoch 92/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8589Start save model epoch  91\n",
        "Optimizer learning rate =  2.4444656e-05\n",
        "End save model epoch  91\n",
        "19417/19417 [==============================] - 3858s 199ms/step - loss: 2.8589 - val_loss: 2.8083\n",
        "Epoch 93/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8601Start save model epoch  92\n",
        "Optimizer learning rate =  2.416688e-05\n",
        "End save model epoch  92\n",
        "19417/19417 [==============================] - 3863s 199ms/step - loss: 2.8601 - val_loss: 2.7794\n",
        "Epoch 94/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8724Start save model epoch  93\n",
        "Optimizer learning rate =  2.3889104e-05\n",
        "End save model epoch  93\n",
        "19417/19417 [==============================] - 3834s 197ms/step - loss: 2.8724 - val_loss: 2.8316\n",
        "Epoch 95/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8460Start save model epoch  94\n",
        "Optimizer learning rate =  2.3611328e-05\n",
        "End save model epoch  94\n",
        "19417/19417 [==============================] - 3882s 200ms/step - loss: 2.8460 - val_loss: 2.7165\n",
        "Epoch 96/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8210Start save model epoch  95\n",
        "Optimizer learning rate =  2.3333554e-05\n",
        "End save model epoch  95\n",
        "19417/19417 [==============================] - 3825s 197ms/step - loss: 2.8210 - val_loss: 2.8142\n",
        "Epoch 97/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8386Start save model epoch  96\n",
        "Optimizer learning rate =  2.3055778e-05\n",
        "End save model epoch  96\n",
        "19417/19417 [==============================] - 3861s 199ms/step - loss: 2.8386 - val_loss: 2.8096\n",
        "Epoch 98/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8302Start save model epoch  97\n",
        "Optimizer learning rate =  2.2778002e-05\n",
        "End save model epoch  97\n",
        "19417/19417 [==============================] - 3855s 199ms/step - loss: 2.8302 - val_loss: 2.7780\n",
        "Epoch 99/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8338Start save model epoch  98\n",
        "Optimizer learning rate =  2.2500228e-05\n",
        "End save model epoch  98\n",
        "19417/19417 [==============================] - 3819s 197ms/step - loss: 2.8338 - val_loss: 2.7968\n",
        "Epoch 100/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8221Start save model epoch  99\n",
        "Optimizer learning rate =  2.2222452e-05\n",
        "End save model epoch  99\n",
        "19417/19417 [==============================] - 3819s 197ms/step - loss: 2.8221 - val_loss: 2.8390\n",
        "Epoch 101/109\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7609Start save model epoch  100\n",
        "Optimizer learning rate =  2.1944676e-05\n",
        "End save model epoch  100\n",
        "19417/19417 [==============================] - 3862s 199ms/step - loss: 2.7609 - val_loss: 2.6845\n",
        "Epoch 102/109\n",
        " 5698/19417 [=======>......................] - ETA: 43:03 - loss: 2.8216\n",
        "\n",
        "Epoch 102/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.8678Start save model epoch  101\n",
        "Optimizer learning rate =  2.16669e-05\n",
        "End save model epoch  101\n",
        "19417/19417 [==============================] - 3937s 198ms/step - loss: 2.8678 - val_loss: 2.7624\n",
        "Epoch 103/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7787Start save model epoch  102\n",
        "Optimizer learning rate =  2.1389124e-05\n",
        "End save model epoch  102\n",
        "19417/19417 [==============================] - 3748s 193ms/step - loss: 2.7787 - val_loss: 2.7331\n",
        "Epoch 104/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7953Start save model epoch  103\n",
        "Optimizer learning rate =  2.111135e-05\n",
        "End save model epoch  103\n",
        "19417/19417 [==============================] - 3804s 196ms/step - loss: 2.7953 - val_loss: 2.7340\n",
        "Epoch 105/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7716Start save model epoch  104\n",
        "Optimizer learning rate =  2.0833573e-05\n",
        "End save model epoch  104\n",
        "19417/19417 [==============================] - 3852s 198ms/step - loss: 2.7716 - val_loss: 2.7192\n",
        "Epoch 106/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7510Start save model epoch  105\n",
        "Optimizer learning rate =  2.0555797e-05\n",
        "End save model epoch  105\n",
        "19417/19417 [==============================] - 3785s 195ms/step - loss: 2.7510 - val_loss: 2.6898\n",
        "Epoch 107/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7641Start save model epoch  106\n",
        "Optimizer learning rate =  2.0278021e-05\n",
        "End save model epoch  106\n",
        "19417/19417 [==============================] - 3829s 197ms/step - loss: 2.7641 - val_loss: 2.7069\n",
        "Epoch 108/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7486Start save model epoch  107\n",
        "Optimizer learning rate =  2.0000245e-05\n",
        "End save model epoch  107\n",
        "19417/19417 [==============================] - 3737s 192ms/step - loss: 2.7486 - val_loss: 2.6922\n",
        "Epoch 109/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7471Start save model epoch  108\n",
        "Optimizer learning rate =  1.972247e-05\n",
        "End save model epoch  108\n",
        "19417/19417 [==============================] - 3730s 192ms/step - loss: 2.7471 - val_loss: 2.6689\n",
        "Epoch 110/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7365Start save model epoch  109\n",
        "Optimizer learning rate =  1.9444695e-05\n",
        "End save model epoch  109\n",
        "19417/19417 [==============================] - 3726s 192ms/step - loss: 2.7365 - val_loss: 2.6608\n",
        "Epoch 111/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7351Start save model epoch  110\n",
        "Optimizer learning rate =  1.9166919e-05\n",
        "End save model epoch  110\n",
        "19417/19417 [==============================] - 3688s 190ms/step - loss: 2.7351 - val_loss: 2.6985\n",
        "Epoch 112/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7344Start save model epoch  111\n",
        "Optimizer learning rate =  1.8889143e-05\n",
        "End save model epoch  111\n",
        "19417/19417 [==============================] - 3728s 192ms/step - loss: 2.7344 - val_loss: 2.6623\n",
        "Epoch 113/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7199Start save model epoch  112\n",
        "Optimizer learning rate =  1.8611368e-05\n",
        "End save model epoch  112\n",
        "19417/19417 [==============================] - 3736s 192ms/step - loss: 2.7199 - val_loss: 2.6550\n",
        "Epoch 114/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7040Start save model epoch  113\n",
        "Optimizer learning rate =  1.8333592e-05\n",
        "End save model epoch  113\n",
        "19417/19417 [==============================] - 3676s 189ms/step - loss: 2.7040 - val_loss: 2.6603\n",
        "Epoch 115/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6928Start save model epoch  114\n",
        "Optimizer learning rate =  1.8055816e-05\n",
        "End save model epoch  114\n",
        "19417/19417 [==============================] - 3766s 194ms/step - loss: 2.6928 - val_loss: 2.6333\n",
        "Epoch 116/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6916Start save model epoch  115\n",
        "Optimizer learning rate =  1.7778042e-05\n",
        "End save model epoch  115\n",
        "19417/19417 [==============================] - 3764s 194ms/step - loss: 2.6916 - val_loss: 2.6557\n",
        "Epoch 117/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7029Start save model epoch  116\n",
        "Optimizer learning rate =  1.7500266e-05\n",
        "End save model epoch  116\n",
        "19417/19417 [==============================] - 3795s 195ms/step - loss: 2.7029 - val_loss: 2.6414\n",
        "Epoch 118/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7168Start save model epoch  117\n",
        "Optimizer learning rate =  1.722249e-05\n",
        "End save model epoch  117\n",
        "19417/19417 [==============================] - 3728s 192ms/step - loss: 2.7168 - val_loss: 2.6266\n",
        "Epoch 119/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6727Start save model epoch  118\n",
        "Optimizer learning rate =  1.6944714e-05\n",
        "End save model epoch  118\n",
        "19417/19417 [==============================] - 3746s 193ms/step - loss: 2.6727 - val_loss: 2.6598\n",
        "Epoch 120/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6452Start save model epoch  119\n",
        "Optimizer learning rate =  1.6666938e-05\n",
        "End save model epoch  119\n",
        "19417/19417 [==============================] - 3778s 195ms/step - loss: 2.6452 - val_loss: 2.6423\n",
        "Epoch 121/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6696Start save model epoch  120\n",
        "Optimizer learning rate =  1.6389162e-05\n",
        "End save model epoch  120\n",
        "19417/19417 [==============================] - 3787s 195ms/step - loss: 2.6696 - val_loss: 2.6314\n",
        "Epoch 122/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6596Start save model epoch  121\n",
        "Optimizer learning rate =  1.6111388e-05\n",
        "End save model epoch  121\n",
        "19417/19417 [==============================] - 3793s 195ms/step - loss: 2.6596 - val_loss: 2.5977\n",
        "Epoch 123/131\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6329Start save model epoch  122\n",
        "Optimizer learning rate =  1.5833612e-05\n",
        "End save model epoch  122\n",
        "19417/19417 [==============================] - 3792s 195ms/step - loss: 2.6329 - val_loss: 2.6110\n",
        "Epoch 124/131\n",
        "12679/19417 [==================>...........] - ETA: 20:45 - loss: 2.6258\n",
        "\n",
        "\n",
        "Epoch 124/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.7291Start save model epoch  123\n",
        "Optimizer learning rate =  1.5555835e-05\n",
        "End save model epoch  123\n",
        "19417/19417 [==============================] - 3722s 187ms/step - loss: 2.7291 - val_loss: 2.6036\n",
        "Epoch 125/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6779Start save model epoch  124\n",
        "Optimizer learning rate =  1.527806e-05\n",
        "End save model epoch  124\n",
        "19417/19417 [==============================] - 3659s 188ms/step - loss: 2.6779 - val_loss: 2.5974\n",
        "Epoch 126/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6327Start save model epoch  125\n",
        "Optimizer learning rate =  1.5000284e-05\n",
        "End save model epoch  125\n",
        "19417/19417 [==============================] - 3687s 190ms/step - loss: 2.6327 - val_loss: 2.5941\n",
        "Epoch 127/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6227Start save model epoch  126\n",
        "Optimizer learning rate =  1.4722508e-05\n",
        "End save model epoch  126\n",
        "19417/19417 [==============================] - 3695s 190ms/step - loss: 2.6227 - val_loss: 2.5875\n",
        "Epoch 128/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6164Start save model epoch  127\n",
        "Optimizer learning rate =  1.4444734e-05\n",
        "End save model epoch  127\n",
        "19417/19417 [==============================] - 3612s 186ms/step - loss: 2.6164 - val_loss: 2.6912\n",
        "Epoch 129/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5877Start save model epoch  128\n",
        "Optimizer learning rate =  1.4166958e-05\n",
        "End save model epoch  128\n",
        "19417/19417 [==============================] - 3687s 190ms/step - loss: 2.5877 - val_loss: 2.5761\n",
        "Epoch 130/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6098Start save model epoch  129\n",
        "Optimizer learning rate =  1.3889182e-05\n",
        "End save model epoch  129\n",
        "19417/19417 [==============================] - 3704s 191ms/step - loss: 2.6098 - val_loss: 2.6102\n",
        "Epoch 131/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6081Start save model epoch  130\n",
        "Optimizer learning rate =  1.3611407e-05\n",
        "End save model epoch  130\n",
        "19417/19417 [==============================] - 3694s 190ms/step - loss: 2.6081 - val_loss: 2.5378\n",
        "Epoch 132/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6138Start save model epoch  131\n",
        "Optimizer learning rate =  1.3333631e-05\n",
        "End save model epoch  131\n",
        "19417/19417 [==============================] - 3746s 193ms/step - loss: 2.6138 - val_loss: 2.5952\n",
        "Epoch 133/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6149Start save model epoch  132\n",
        "Optimizer learning rate =  1.3055856e-05\n",
        "End save model epoch  132\n",
        "19417/19417 [==============================] - 3705s 191ms/step - loss: 2.6149 - val_loss: 2.5825\n",
        "Epoch 134/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5660Start save model epoch  133\n",
        "Optimizer learning rate =  1.27780795e-05\n",
        "End save model epoch  133\n",
        "19417/19417 [==============================] - 3647s 188ms/step - loss: 2.5660 - val_loss: 2.5727\n",
        "Epoch 135/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5875Start save model epoch  134\n",
        "Optimizer learning rate =  1.2500304e-05\n",
        "End save model epoch  134\n",
        "19417/19417 [==============================] - 3684s 190ms/step - loss: 2.5875 - val_loss: 2.5692\n",
        "Epoch 136/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5873Start save model epoch  135\n",
        "Optimizer learning rate =  1.2222528e-05\n",
        "End save model epoch  135\n",
        "19417/19417 [==============================] - 3643s 188ms/step - loss: 2.5873 - val_loss: 2.5685\n",
        "Epoch 137/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.6157Start save model epoch  136\n",
        "Optimizer learning rate =  1.1944752e-05\n",
        "End save model epoch  136\n",
        "19417/19417 [==============================] - 3638s 187ms/step - loss: 2.6157 - val_loss: 2.4873\n",
        "Epoch 138/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5772Start save model epoch  137\n",
        "Optimizer learning rate =  1.1666977e-05\n",
        "End save model epoch  137\n",
        "19417/19417 [==============================] - 3670s 189ms/step - loss: 2.5772 - val_loss: 2.5088\n",
        "Epoch 139/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5666Start save model epoch  138\n",
        "Optimizer learning rate =  1.1389201e-05\n",
        "End save model epoch  138\n",
        "19417/19417 [==============================] - 3736s 192ms/step - loss: 2.5666 - val_loss: 2.5121\n",
        "Epoch 140/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5474Start save model epoch  139\n",
        "Optimizer learning rate =  1.1111426e-05\n",
        "End save model epoch  139\n",
        "19417/19417 [==============================] - 3705s 191ms/step - loss: 2.5474 - val_loss: 2.4772\n",
        "Epoch 141/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5399Start save model epoch  140\n",
        "Optimizer learning rate =  1.083365e-05\n",
        "End save model epoch  140\n",
        "19417/19417 [==============================] - 3723s 192ms/step - loss: 2.5399 - val_loss: 2.4897\n",
        "Epoch 142/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5750Start save model epoch  141\n",
        "Optimizer learning rate =  1.0555874e-05\n",
        "End save model epoch  141\n",
        "19417/19417 [==============================] - 3680s 190ms/step - loss: 2.5750 - val_loss: 2.5112\n",
        "Epoch 143/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5509Start save model epoch  142\n",
        "Optimizer learning rate =  1.0278099e-05\n",
        "End save model epoch  142\n",
        "19417/19417 [==============================] - 3704s 191ms/step - loss: 2.5509 - val_loss: 2.5517\n",
        "Epoch 144/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4983Start save model epoch  143\n",
        "Optimizer learning rate =  1.0000323e-05\n",
        "End save model epoch  143\n",
        "19417/19417 [==============================] - 3695s 190ms/step - loss: 2.4983 - val_loss: 2.5147\n",
        "Epoch 145/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5315Start save model epoch  144\n",
        "Optimizer learning rate =  9.7225475e-06\n",
        "End save model epoch  144\n",
        "19417/19417 [==============================] - 3744s 193ms/step - loss: 2.5315 - val_loss: 2.4812\n",
        "Epoch 146/153\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5185Start save model epoch  145\n",
        "Optimizer learning rate =  9.444771e-06\n",
        "End save model epoch  145\n",
        "19417/19417 [==============================] - 3698s 190ms/step - loss: 2.5185 - val_loss: 2.4442\n",
        "Epoch 147/153\n",
        " 1208/19417 [>.............................] - ETA: 55:56 - loss: 2.4164\n",
        "\n",
        "Epoch 147/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5787Start save model epoch  146\n",
        "Optimizer learning rate =  9.166996e-06\n",
        "End save model epoch  146\n",
        "19417/19417 [==============================] - 3982s 200ms/step - loss: 2.5787 - val_loss: 2.5157\n",
        "Epoch 148/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5139Start save model epoch  147\n",
        "Optimizer learning rate =  8.889221e-06\n",
        "End save model epoch  147\n",
        "19417/19417 [==============================] - 3778s 195ms/step - loss: 2.5139 - val_loss: 2.4974\n",
        "Epoch 149/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4888Start save model epoch  148\n",
        "Optimizer learning rate =  8.611445e-06\n",
        "End save model epoch  148\n",
        "19417/19417 [==============================] - 3731s 192ms/step - loss: 2.4888 - val_loss: 2.4955\n",
        "Epoch 150/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.5033Start save model epoch  149\n",
        "Optimizer learning rate =  8.33367e-06\n",
        "End save model epoch  149\n",
        "19417/19417 [==============================] - 3730s 192ms/step - loss: 2.5033 - val_loss: 2.4443\n",
        "Epoch 151/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4996Start save model epoch  150\n",
        "Optimizer learning rate =  8.055894e-06\n",
        "End save model epoch  150\n",
        "19417/19417 [==============================] - 3767s 194ms/step - loss: 2.4996 - val_loss: 2.4422\n",
        "Epoch 152/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4863Start save model epoch  151\n",
        "Optimizer learning rate =  7.778119e-06\n",
        "End save model epoch  151\n",
        "19417/19417 [==============================] - 3743s 193ms/step - loss: 2.4863 - val_loss: 2.4802\n",
        "Epoch 153/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4768Start save model epoch  152\n",
        "Optimizer learning rate =  7.5003427e-06\n",
        "End save model epoch  152\n",
        "19417/19417 [==============================] - 3731s 192ms/step - loss: 2.4768 - val_loss: 2.5193\n",
        "Epoch 154/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4801Start save model epoch  153\n",
        "Optimizer learning rate =  7.222567e-06\n",
        "End save model epoch  153\n",
        "19417/19417 [==============================] - 3750s 193ms/step - loss: 2.4801 - val_loss: 2.5147\n",
        "Epoch 155/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4708Start save model epoch  154\n",
        "Optimizer learning rate =  6.944792e-06\n",
        "End save model epoch  154\n",
        "19417/19417 [==============================] - 3750s 193ms/step - loss: 2.4708 - val_loss: 2.4965\n",
        "Epoch 156/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4737Start save model epoch  155\n",
        "Optimizer learning rate =  6.667016e-06\n",
        "End save model epoch  155\n",
        "19417/19417 [==============================] - 3696s 190ms/step - loss: 2.4737 - val_loss: 2.5381\n",
        "Epoch 157/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4855Start save model epoch  156\n",
        "Optimizer learning rate =  6.38924e-06\n",
        "End save model epoch  156\n",
        "19417/19417 [==============================] - 3741s 193ms/step - loss: 2.4855 - val_loss: 2.4687\n",
        "Epoch 158/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4668Start save model epoch  157\n",
        "Optimizer learning rate =  6.1114647e-06\n",
        "End save model epoch  157\n",
        "19417/19417 [==============================] - 3752s 193ms/step - loss: 2.4668 - val_loss: 2.4587\n",
        "Epoch 159/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4669Start save model epoch  158\n",
        "Optimizer learning rate =  5.833689e-06\n",
        "End save model epoch  158\n",
        "19417/19417 [==============================] - 3763s 194ms/step - loss: 2.4669 - val_loss: 2.4625\n",
        "Epoch 160/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4818Start save model epoch  159\n",
        "Optimizer learning rate =  5.555913e-06\n",
        "End save model epoch  159\n",
        "19417/19417 [==============================] - 4071s 210ms/step - loss: 2.4818 - val_loss: 2.4438\n",
        "Epoch 161/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4622Start save model epoch  160\n",
        "Optimizer learning rate =  5.278138e-06\n",
        "End save model epoch  160\n",
        "19417/19417 [==============================] - 4080s 210ms/step - loss: 2.4622 - val_loss: 2.4732\n",
        "Epoch 162/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4552Start save model epoch  161\n",
        "Optimizer learning rate =  5.000362e-06\n",
        "End save model epoch  161\n",
        "19417/19417 [==============================] - 3992s 206ms/step - loss: 2.4552 - val_loss: 2.4237\n",
        "Epoch 163/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4540Start save model epoch  162\n",
        "Optimizer learning rate =  4.7225863e-06\n",
        "End save model epoch  162\n",
        "19417/19417 [==============================] - 4040s 208ms/step - loss: 2.4540 - val_loss: 2.4613\n",
        "Epoch 164/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4402Start save model epoch  163\n",
        "Optimizer learning rate =  4.4448107e-06\n",
        "End save model epoch  163\n",
        "19417/19417 [==============================] - 3965s 204ms/step - loss: 2.4402 - val_loss: 2.5003\n",
        "Epoch 165/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4300Start save model epoch  164\n",
        "Optimizer learning rate =  4.167035e-06\n",
        "End save model epoch  164\n",
        "19417/19417 [==============================] - 3982s 205ms/step - loss: 2.4300 - val_loss: 2.4033\n",
        "Epoch 166/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4334Start save model epoch  165\n",
        "Optimizer learning rate =  3.88926e-06\n",
        "End save model epoch  165\n",
        "19417/19417 [==============================] - 4068s 210ms/step - loss: 2.4334 - val_loss: 2.4486\n",
        "Epoch 167/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4172Start save model epoch  166\n",
        "Optimizer learning rate =  3.6114836e-06\n",
        "End save model epoch  166\n",
        "19417/19417 [==============================] - 4071s 210ms/step - loss: 2.4172 - val_loss: 2.4345\n",
        "Epoch 168/176\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4645Start save model epoch  167\n",
        "Optimizer learning rate =  3.3337083e-06\n",
        "End save model epoch  167\n",
        "19417/19417 [==============================] - 4016s 207ms/step - loss: 2.4645 - val_loss: 2.4371\n",
        "Epoch 169/176\n",
        "  568/19417 [..............................] - ETA: 1:02:27 - loss: 2.4320\n",
        "\n",
        "Epoch 169/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4611Start save model epoch  168\n",
        "Optimizer learning rate =  3.0559327e-06\n",
        "End save model epoch  168\n",
        "19417/19417 [==============================] - 3877s 195ms/step - loss: 2.4611 - val_loss: 2.4056\n",
        "Epoch 170/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4573Start save model epoch  169\n",
        "Optimizer learning rate =  2.7781568e-06\n",
        "End save model epoch  169\n",
        "19417/19417 [==============================] - 3748s 193ms/step - loss: 2.4573 - val_loss: 2.4147\n",
        "Epoch 171/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4252Start save model epoch  170\n",
        "Optimizer learning rate =  2.5003812e-06\n",
        "End save model epoch  170\n",
        "19417/19417 [==============================] - 3730s 192ms/step - loss: 2.4252 - val_loss: 2.4072\n",
        "Epoch 172/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4164Start save model epoch  171\n",
        "Optimizer learning rate =  2.2226056e-06\n",
        "End save model epoch  171\n",
        "19417/19417 [==============================] - 3796s 195ms/step - loss: 2.4164 - val_loss: 2.4334\n",
        "Epoch 173/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4233Start save model epoch  172\n",
        "Optimizer learning rate =  1.94483e-06\n",
        "End save model epoch  172\n",
        "19417/19417 [==============================] - 3764s 194ms/step - loss: 2.4233 - val_loss: 2.4016\n",
        "Epoch 174/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.3982Start save model epoch  173\n",
        "Optimizer learning rate =  1.6670544e-06\n",
        "End save model epoch  173\n",
        "19417/19417 [==============================] - 3744s 193ms/step - loss: 2.3982 - val_loss: 2.4188\n",
        "Epoch 175/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.3970Start save model epoch  174\n",
        "Optimizer learning rate =  1.3892786e-06\n",
        "End save model epoch  174\n",
        "19417/19417 [==============================] - 3765s 194ms/step - loss: 2.3970 - val_loss: 2.4569\n",
        "Epoch 176/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.3990Start save model epoch  175\n",
        "Optimizer learning rate =  1.111503e-06\n",
        "End save model epoch  175\n",
        "19417/19417 [==============================] - 3758s 194ms/step - loss: 2.3990 - val_loss: 2.4486\n",
        "Epoch 177/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4152Start save model epoch  176\n",
        "Optimizer learning rate =  8.337273e-07\n",
        "End save model epoch  176\n",
        "19417/19417 [==============================] - 3773s 194ms/step - loss: 2.4152 - val_loss: 2.4221\n",
        "Epoch 178/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4155Start save model epoch  177\n",
        "Optimizer learning rate =  5.559517e-07\n",
        "End save model epoch  177\n",
        "19417/19417 [==============================] - 3757s 193ms/step - loss: 2.4155 - val_loss: 2.3982\n",
        "Epoch 179/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4143Start save model epoch  178\n",
        "Optimizer learning rate =  2.7817595e-07\n",
        "End save model epoch  178\n",
        "19417/19417 [==============================] - 3733s 192ms/step - loss: 2.4143 - val_loss: 2.3549\n",
        "Epoch 180/180\n",
        "19417/19417 [==============================] - ETA: 0s - loss: 2.4073Start save model epoch  179\n",
        "Optimizer learning rate =  4.0038783e-10\n",
        "End save model epoch  179\n",
        "19417/19417 [==============================] - 3739s 193ms/step - loss: 2.4073 - val_loss: 2.4055\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDGyGqTasyWz",
        "outputId": "679b1f86-37da-4965-ace5-91e6f7cfbc40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2461/2461 [==============================] - 176s 71ms/step - loss: 2.3936\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2.393561601638794"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_model.evaluate(tf_valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVVY8zbBCRRU",
        "outputId": "bce1577c-1950-4cb6-d268-d8ae507a8ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2891/2891 [==============================] - 215s 70ms/step - loss: 2.3976\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2.397552967071533"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_model.evaluate(tf_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNmHQ7uqCSvy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0034b49ea2b04db19d7fe13aef61b832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00638b3d312c4ac2893ed09aa3baa4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01dd40591b4c4e13bade61c603d2bda1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03cdee58949a4f65bc111a8652a1be34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_576f9394c3a546f3afb0d8d16c65007a",
            "placeholder": "​",
            "style": "IPY_MODEL_f1940ff80b9b48e8b6480719a61c594e",
            "value": "vocab.json: 100%"
          }
        },
        "03f702468b5946728e8c96dc5a6a8d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "046371c07e7d4adb968e0e3f00ac2ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0484969f7bda4f69a102497bc3c80ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05fb9e15ad564fcca68a65022d4be78c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0841b248068f4a5e8e7c77b8aa07c92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e6a7164ab5d4b89bc2a610a1fd9b716",
            "max": 10464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_155c7ce4b6554baf9c35ba04d7374cd6",
            "value": 10464
          }
        },
        "08a558566b694bd389c3cfc684f6cb78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1235601eeb4bab9138f53de8d6345c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d1e2e2e38844f1984cc96ce97f3a8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e20b94e23ed44a4bea77af0094fb706": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f442d39fd6a4734af00bb79c1e0e6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683fc9e594aa4e2b8767f57d53ed4be9",
            "placeholder": "​",
            "style": "IPY_MODEL_4462b116525e4562aade75b64328400c",
            "value": "merges.txt: 100%"
          }
        },
        "11860834fa8944c99c2fbbdf05ddadf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a8e9a04770472592d96f3fec637183": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120c3bb3d3e644e1be4449329836f948": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130ab8231e4947569b0cd5ea1138b98e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ab4c33ea3042168188562a5485b4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f291f1c947a4a67a9bfc06be066a22f",
              "IPY_MODEL_b49306c80d744f9bb9e78a558bfebcef",
              "IPY_MODEL_8c99d92f586d46bb808a685ecae330f6"
            ],
            "layout": "IPY_MODEL_11860834fa8944c99c2fbbdf05ddadf8"
          }
        },
        "155c7ce4b6554baf9c35ba04d7374cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1634bae7bee24c6fa2cd1c76059735fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "166f088d722b4686a0037e5e93783c21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f1a05289d244ad83d60dbbdb7d5078": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9cc86c7b9b4b17beef13cb56349efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1afb9ded326e4dd6ba180f0b9a76af19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c05b9a4cedf4a97a5641cb078b03d95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cef89d6f06043d99ec2b3f0341c41af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d41475641034ebb95fed0a0c70fc46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03cdee58949a4f65bc111a8652a1be34",
              "IPY_MODEL_76dadb29475c4d3bb129efe22c0258c0",
              "IPY_MODEL_ac9ab02472bb44c88d17171785b4f566"
            ],
            "layout": "IPY_MODEL_9d3e07f9e6b24c6a88a43f3a98ceca56"
          }
        },
        "1e174ad510f944019acef74a3a81d054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f0bfee0d3194a9abf813fd2cde4c79d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2101e5dcba7544a890b019fa95eb6598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22a805900a4b4a3dafd6ce5b02f3c81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "245518e8d61e4f7f8ca5f081376343f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5854dee2f4454587aff35a6c46dce22b",
            "placeholder": "​",
            "style": "IPY_MODEL_c6db215148de4bc9b0c59d11c0ac8b2f",
            "value": "Downloading data: 100%"
          }
        },
        "261404ac538e4476878f5798751af00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44fd6d2f677e48f89812045e93b82e6a",
              "IPY_MODEL_570a57d4cc6b4c9283a7fb6561efb51f",
              "IPY_MODEL_c70995a47e3f437692692a8d1fba3c14"
            ],
            "layout": "IPY_MODEL_caec4e0c17894182b26fca67d1a59dfe"
          }
        },
        "270846a3304741ff8dbbeaf488a85617": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27929d244481491d9514853cf1c1f544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dc7de46985e40ff977f6f8822ce4a22",
            "placeholder": "​",
            "style": "IPY_MODEL_8665d47774514cb3b34e7151fbd0e867",
            "value": "Filter: 100%"
          }
        },
        "27d6b363d41e4a4796cbb8920badeaed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27d865d507b840c28c44d7e2f416dfdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "293f4593ae2649d491e808dbb3d412a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b6e3b88573f479ab09ae9bd6512a82e",
            "max": 1801350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0484969f7bda4f69a102497bc3c80ca8",
            "value": 1801350
          }
        },
        "294489eab3e5480c8c5b53bb0360cd5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba10491d3dd458aa619b90cfa037899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_651c0f351ec64abea7b85550903406b5",
            "placeholder": "​",
            "style": "IPY_MODEL_bce88877099e4dffad8a6481de13191a",
            "value": " 3760/3760 [00:02&lt;00:00, 1792.46 examples/s]"
          }
        },
        "2ba6b69cb801434b8788485e5fe86bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e6a7164ab5d4b89bc2a610a1fd9b716": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e81a37d18764ca3990473d85f0f6b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fc739cffe0f4c69bee0efeede1e76d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "307246944ab640e8928b0df1b945809f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31bd66b9a13b42859cf1e84307a63f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bec452d0924fd193e2019db0b7f115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "323fe906c461460d96f0d9452869344e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f8dab5bb2e46a084fa028bf1026449": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fbdda2524e4c5c999c5aed77a4c5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3640a9d91470474eb6db0aaa37337b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37c84944ab0e46cf97aec71bf292321c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e7d982f9f44da09b0a7405f355173f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b168b5f9c6f4ed8a03bb5c31613197c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd250fb6ee742bb8cf259e9799e4931": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cab100d330d45f58f445fb554b8f436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e21ddbdc17a40fca7840360cf11eed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422da429e3ec4d7e8513779ad733817b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc739cffe0f4c69bee0efeede1e76d3",
            "placeholder": "​",
            "style": "IPY_MODEL_8abd57d3da26430d8c0c245698619309",
            "value": "Downloading readme: 100%"
          }
        },
        "429beb32d8294a11bd81a298628ea164": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43fb1adc5b9548bda2f2cc192ee69323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593cbf071d7a487ab29cec034ab2133f",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_307246944ab640e8928b0df1b945809f",
            "value": 3760
          }
        },
        "4462b116525e4562aade75b64328400c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "449b8430de164bc4b37c7b87e38179a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e20b5c10fac1437e8fc581ce51ad3e46",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab616d6973834d469c8269cb69baf582",
            "value": 1355863
          }
        },
        "44fd6d2f677e48f89812045e93b82e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f8dab5bb2e46a084fa028bf1026449",
            "placeholder": "​",
            "style": "IPY_MODEL_a17746e3e85d4e16a3d4d16d432c21cf",
            "value": "Generating validation split: 100%"
          }
        },
        "459a08784fd64416a9e243ea09adb874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487bf6f989ee403b83f7a89162fe81ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499a9e2f122344db8bbcc98be10b2c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a7f0407998c4e2fb374ba0a4612c675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b180815c0434a6e9191f9de418dfe96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc0d354f20a447d8fc7d3c7aafb29d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dc7de46985e40ff977f6f8822ce4a22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a1917a750644b2b89f0aabfd245321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_245518e8d61e4f7f8ca5f081376343f0",
              "IPY_MODEL_54181ed0174e4d2aa356446e7e9f5b11",
              "IPY_MODEL_80071fcef074459c891027492f4ed82f"
            ],
            "layout": "IPY_MODEL_b179fded35854c3199ae35708ae8f195"
          }
        },
        "50c5c9d7075c49469f86770c96d59157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51e3b6cf6d6c4c31a213852f0c119dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33e066edde1445182a839f61e6099a5",
            "placeholder": "​",
            "style": "IPY_MODEL_e13c4cc96d9a40a8acd3d1d8fa7beb37",
            "value": "tokenizer.json: 100%"
          }
        },
        "531fea23dda040d18965222868a7e5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54181ed0174e4d2aa356446e7e9f5b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19f1a05289d244ad83d60dbbdb7d5078",
            "max": 657209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2101e5dcba7544a890b019fa95eb6598",
            "value": 657209
          }
        },
        "55f3d3ed251e4e8186a1a24570552ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb161318ef8b4752b89a84562a61826d",
            "placeholder": "​",
            "style": "IPY_MODEL_e69a4ae3e712444a8150cbc865dc2523",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 153kB/s]"
          }
        },
        "570a57d4cc6b4c9283a7fb6561efb51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4663e1144a0463889bbee1b40089906",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_270846a3304741ff8dbbeaf488a85617",
            "value": 3760
          }
        },
        "576f9394c3a546f3afb0d8d16c65007a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5854dee2f4454587aff35a6c46dce22b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592a56a5a4264841aa44745837c74bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1afb9ded326e4dd6ba180f0b9a76af19",
            "placeholder": "​",
            "style": "IPY_MODEL_c759a4373a674d978f39b8873209b95c",
            "value": "config.json: 100%"
          }
        },
        "593cbf071d7a487ab29cec034ab2133f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "599c43492145403395150b3254dc6352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b180815c0434a6e9191f9de418dfe96",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c64e885602bc4ba1a7794af8d26fd978",
            "value": 3
          }
        },
        "59bcd83c570d4ab2886b83cf5aa42402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1a3bb9b136432eab15754c448bb1cb",
            "max": 1801350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e81a37d18764ca3990473d85f0f6b13",
            "value": 1801350
          }
        },
        "5a749e911f184b979dd200227d132b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b6e3b88573f479ab09ae9bd6512a82e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60583940d54c493bac592740c56d5423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "610f6c7c64d64c60ae8c74706385bb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a703e2022dad4a5985138ce796836a5f",
              "IPY_MODEL_bdfbe4a11f6d459db96dba6ba2e7ec23",
              "IPY_MODEL_cbcb653d86da4525a5693dfe5aea3745"
            ],
            "layout": "IPY_MODEL_00638b3d312c4ac2893ed09aa3baa4f2"
          }
        },
        "621414f689204c4495a60b140ad46568": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046371c07e7d4adb968e0e3f00ac2ca9",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fab79cdb34145b58eb00ed5eaa92aee",
            "value": 481
          }
        },
        "63991ec40d6d4dc2be72ad310d253b90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6408770d66374a338ea5134dbb055103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cabc22c8cc24fb39d60e5379f619312",
            "placeholder": "​",
            "style": "IPY_MODEL_4dc0d354f20a447d8fc7d3c7aafb29d7",
            "value": " 1801350/1801350 [00:04&lt;00:00, 505496.08 examples/s]"
          }
        },
        "6488b857ccef4e14a68a7c9431ed8d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51e3b6cf6d6c4c31a213852f0c119dae",
              "IPY_MODEL_449b8430de164bc4b37c7b87e38179a1",
              "IPY_MODEL_9a514e6c3a54490e95eb7cbbd656d85f"
            ],
            "layout": "IPY_MODEL_f74303cb677c4031a70dbb93ae9e8ec8"
          }
        },
        "651c0f351ec64abea7b85550903406b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "683fc9e594aa4e2b8767f57d53ed4be9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696e91900e574feda751e558ee897913": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698e601226a349e699e77a7cee0c68a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a29f5e5de034e04894510e109e63eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08a558566b694bd389c3cfc684f6cb78",
            "max": 156987808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a7f0407998c4e2fb374ba0a4612c675",
            "value": 156987808
          }
        },
        "6af6167d5fc1405b89ae85e0e139ffac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82cd7b1be234c07a7fa1ac376bc938c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a749e911f184b979dd200227d132b6a",
            "value": 25
          }
        },
        "6ddb6ddda4694d01868d60ff09293ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f442d39fd6a4734af00bb79c1e0e6cb",
              "IPY_MODEL_ee5c5ae9fc074c30a7630744c61ebd43",
              "IPY_MODEL_c4e4007498034658ad17958526a4d604"
            ],
            "layout": "IPY_MODEL_f911cb0b7f5845499ad603a5b616cb2f"
          }
        },
        "6e2a6b22c3e14cdd85abbacf6f9d711d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f36c4e757814182aa8ad028ac2e13c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e20b94e23ed44a4bea77af0094fb706",
            "placeholder": "​",
            "style": "IPY_MODEL_33fbdda2524e4c5c999c5aed77a4c5ec",
            "value": " 4358/4358 [00:00&lt;00:00, 51781.24 examples/s]"
          }
        },
        "6fab79cdb34145b58eb00ed5eaa92aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "725ffbec655f4992ac50577103d813e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05fb9e15ad564fcca68a65022d4be78c",
            "placeholder": "​",
            "style": "IPY_MODEL_27d6b363d41e4a4796cbb8920badeaed",
            "value": "Generating train split: 100%"
          }
        },
        "72d44cd69ff0490991c96191f3e3e64a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b7296bd360471d9aaa1ac9d9493243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b660202e71470e9121a953cd1cff73",
            "placeholder": "​",
            "style": "IPY_MODEL_3e21ddbdc17a40fca7840360cf11eed0",
            "value": " 3760/3760 [00:00&lt;00:00, 4644.85 examples/s]"
          }
        },
        "75a8c8cedb8f4541bb2e2a15d2d610cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76dadb29475c4d3bb129efe22c0258c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_531fea23dda040d18965222868a7e5b6",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7380217ef7b4ca0b175b8d04d2fe62c",
            "value": 898823
          }
        },
        "786bccee3fb44f2a89916c0d18fb4840": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1a3bb9b136432eab15754c448bb1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0c65324de1408f8a5f6701b96ca0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e1d5f46de9c453a9842f1484dd65e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec84d17fd3494f48aaa0120cae6c60a0",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba6b69cb801434b8788485e5fe86bb1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7ebdafb101284890a1afc8653bd04bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed949021e10487f8f704fa6245b7d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38e7d982f9f44da09b0a7405f355173f",
            "placeholder": "​",
            "style": "IPY_MODEL_a39b93cba5674a97a0f34b6438e23df0",
            "value": " 733k/733k [00:00&lt;00:00, 1.53MB/s]"
          }
        },
        "7f791311a5e449dc9b47ba4b8058c61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf8d949e3e3841069d83965f771c8edf",
              "IPY_MODEL_293f4593ae2649d491e808dbb3d412a0",
              "IPY_MODEL_adb86d20426f4e3f95c50844ac16a996"
            ],
            "layout": "IPY_MODEL_3bd250fb6ee742bb8cf259e9799e4931"
          }
        },
        "7ff4c6a022534f35857481b65cfce50b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80071fcef074459c891027492f4ed82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786bccee3fb44f2a89916c0d18fb4840",
            "placeholder": "​",
            "style": "IPY_MODEL_f8606673361d4433aa7da7e5bc58eadd",
            "value": " 657k/657k [00:00&lt;00:00, 2.99MB/s]"
          }
        },
        "803a72b895624fc1a3be1bf34c3d480b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f84a9a28c24e689c49742b95139757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81aec2aaf41f414ab8fb49dc46e35868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74a465c4fed4811bf631ff6ff9f44db",
            "placeholder": "​",
            "style": "IPY_MODEL_1cef89d6f06043d99ec2b3f0341c41af",
            "value": "Running tokenizer on dataset line_by_line: 100%"
          }
        },
        "84d81329f0dd40918df1b6a2d985b6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0b25ae913464516b9421512466bfce0",
              "IPY_MODEL_f640b9c335064f75bfb747d11be7227f",
              "IPY_MODEL_7ed949021e10487f8f704fa6245b7d49"
            ],
            "layout": "IPY_MODEL_f52aa0592f81474da00da0e607f87d21"
          }
        },
        "8515c1ec3b9d4ea59ce792d1e5922248": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86246b31af654f15b159ffcb211ed62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1e2e2e38844f1984cc96ce97f3a8ed",
            "placeholder": "​",
            "style": "IPY_MODEL_e5b15affeec64135b90f70bec0a09f9a",
            "value": "Downloading data files: 100%"
          }
        },
        "8663529208b64f3c8b34ed55daeea1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2a8f60fc0784956b6dbb495f0c2adb5",
            "placeholder": "​",
            "style": "IPY_MODEL_c038d0d672b942e1a28b0b8d03b84596",
            "value": " 25.0/25.0 [00:00&lt;00:00, 661B/s]"
          }
        },
        "8665d47774514cb3b34e7151fbd0e867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87527199bbcf4ea28eebc1c9db485b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_592a56a5a4264841aa44745837c74bd9",
              "IPY_MODEL_621414f689204c4495a60b140ad46568",
              "IPY_MODEL_8b4f82ed801b40fba964480d4a663b1d"
            ],
            "layout": "IPY_MODEL_696e91900e574feda751e558ee897913"
          }
        },
        "879d1ff131de45909a1fb76ff8dbdc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_725ffbec655f4992ac50577103d813e1",
              "IPY_MODEL_59bcd83c570d4ab2886b83cf5aa42402",
              "IPY_MODEL_6408770d66374a338ea5134dbb055103"
            ],
            "layout": "IPY_MODEL_0c1235601eeb4bab9138f53de8d6345c"
          }
        },
        "88952b71cdb64d41a73ace95815c3df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8abd57d3da26430d8c0c245698619309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b42b4a17f29498883c957a1e543413f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4f82ed801b40fba964480d4a663b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06ef61ebdf246379110074c3f9ca398",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed43c25ba3149f5a09a1bbcaf0dfabf",
            "value": " 481/481 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "8c61b0b4071944c6a1a62f143005f563": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120c3bb3d3e644e1be4449329836f948",
            "placeholder": "​",
            "style": "IPY_MODEL_31bec452d0924fd193e2019db0b7f115",
            "value": "Extracting data files: 100%"
          }
        },
        "8c99d92f586d46bb808a685ecae330f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf584b9619948698062cf03850c790b",
            "placeholder": "​",
            "style": "IPY_MODEL_f27c99d3519d4902a546f114d2737a26",
            "value": " 157M/157M [00:01&lt;00:00, 111MB/s]"
          }
        },
        "8cabc22c8cc24fb39d60e5379f619312": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dcf28775ead47fc9fa451e8756d9f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b2aba711bd4f34a196ca6790945b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94986a1cedee400a8d85f4fcab5fac13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9821e8dcbc9e441c8b48acb2bc143978": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9988edf69ae546f3a29431933594ff6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c61b0b4071944c6a1a62f143005f563",
              "IPY_MODEL_d02a69ce62614a28824ec4dc787692cf",
              "IPY_MODEL_f206c35534e944c189216d333eda06a0"
            ],
            "layout": "IPY_MODEL_c30e142b47fc47a3998b73d902264029"
          }
        },
        "99a01c6668c540679d3f11539998fca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a514e6c3a54490e95eb7cbbd656d85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8515c1ec3b9d4ea59ce792d1e5922248",
            "placeholder": "​",
            "style": "IPY_MODEL_92b2aba711bd4f34a196ca6790945b25",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.14MB/s]"
          }
        },
        "9b8e8b80f5f14f5f87da3b35d8ac21e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1cf34bbef824a35a37da5e279d13a14",
              "IPY_MODEL_f465aeb4730142388d6a41e3965469f2",
              "IPY_MODEL_ee5b15e06f2249dd8171f7f5c246e526"
            ],
            "layout": "IPY_MODEL_f8af9760b8b448f295aa93d0fa42a22b"
          }
        },
        "9bee55da4d6c491e95bfb60f4ed4ae47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac3b45c0d37d47d7895beaea5ac8fb81",
              "IPY_MODEL_af1aac5ce735443da70dd3633949c89e",
              "IPY_MODEL_6f36c4e757814182aa8ad028ac2e13c4"
            ],
            "layout": "IPY_MODEL_1634bae7bee24c6fa2cd1c76059735fd"
          }
        },
        "9ca94d70d90740d0b5c8a6382acec834": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3e07f9e6b24c6a88a43f3a98ceca56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da2aba16ce44a0cb35877deafb6bc7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed43c25ba3149f5a09a1bbcaf0dfabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f291f1c947a4a67a9bfc06be066a22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d44cd69ff0490991c96191f3e3e64a",
            "placeholder": "​",
            "style": "IPY_MODEL_6e2a6b22c3e14cdd85abbacf6f9d711d",
            "value": "Downloading data: 100%"
          }
        },
        "9ff5346af6394d07a00954447e804949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1dcb84c46f64e71b57d44bcc4c63206",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22a805900a4b4a3dafd6ce5b02f3c81b",
            "value": 4358
          }
        },
        "a17746e3e85d4e16a3d4d16d432c21cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2a8f60fc0784956b6dbb495f0c2adb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39b93cba5674a97a0f34b6438e23df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a56488ec12954ad09b26e794d5629148": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a703e2022dad4a5985138ce796836a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1000b0af4404b64b0735490c684f8b1",
            "placeholder": "​",
            "style": "IPY_MODEL_698e601226a349e699e77a7cee0c68a6",
            "value": "Running tokenizer on dataset line_by_line: 100%"
          }
        },
        "a9d10d3ea4c946aebe0b299edee9856a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_422da429e3ec4d7e8513779ad733817b",
              "IPY_MODEL_0841b248068f4a5e8e7c77b8aa07c92e",
              "IPY_MODEL_55f3d3ed251e4e8186a1a24570552ecc"
            ],
            "layout": "IPY_MODEL_01dd40591b4c4e13bade61c603d2bda1"
          }
        },
        "ab616d6973834d469c8269cb69baf582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac3b45c0d37d47d7895beaea5ac8fb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9821e8dcbc9e441c8b48acb2bc143978",
            "placeholder": "​",
            "style": "IPY_MODEL_75a8c8cedb8f4541bb2e2a15d2d610cc",
            "value": "Generating test split: 100%"
          }
        },
        "ac8ffc9a97864bf2af979e49e8456f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_166f088d722b4686a0037e5e93783c21",
            "placeholder": "​",
            "style": "IPY_MODEL_88952b71cdb64d41a73ace95815c3df2",
            "value": " 3/3 [00:04&lt;00:00,  1.29s/it]"
          }
        },
        "ac9ab02472bb44c88d17171785b4f566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294489eab3e5480c8c5b53bb0360cd5d",
            "placeholder": "​",
            "style": "IPY_MODEL_3640a9d91470474eb6db0aaa37337b5f",
            "value": " 899k/899k [00:00&lt;00:00, 2.75MB/s]"
          }
        },
        "ac9f9ebfa7954311b85fefb3c2a74752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86246b31af654f15b159ffcb211ed62d",
              "IPY_MODEL_599c43492145403395150b3254dc6352",
              "IPY_MODEL_ac8ffc9a97864bf2af979e49e8456f1f"
            ],
            "layout": "IPY_MODEL_11a8e9a04770472592d96f3fec637183"
          }
        },
        "adb86d20426f4e3f95c50844ac16a996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a547ec7e004756aa776c0d1b1c91cf",
            "placeholder": "​",
            "style": "IPY_MODEL_50c5c9d7075c49469f86770c96d59157",
            "value": " 1801350/1801350 [04:08&lt;00:00, 5411.05 examples/s]"
          }
        },
        "af1aac5ce735443da70dd3633949c89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803a72b895624fc1a3be1bf34c3d480b",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e625fd57a304447791e0cde8ccf5f075",
            "value": 4358
          }
        },
        "b0b25ae913464516b9421512466bfce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31bd66b9a13b42859cf1e84307a63f0b",
            "placeholder": "​",
            "style": "IPY_MODEL_1a9cc86c7b9b4b17beef13cb56349efd",
            "value": "Downloading data: 100%"
          }
        },
        "b0b7f061d6bd43dd8be079b87ca2ab56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1000b0af4404b64b0735490c684f8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b179fded35854c3199ae35708ae8f195": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1dcb84c46f64e71b57d44bcc4c63206": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4663e1144a0463889bbee1b40089906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b49306c80d744f9bb9e78a558bfebcef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_130ab8231e4947569b0cd5ea1138b98e",
            "max": 157088770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03f702468b5946728e8c96dc5a6a8d55",
            "value": 157088770
          }
        },
        "b634b00d88b7419a9885a9dd3a4d28ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba24dc6930814242bf983d5974ea81fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb0c1c9f36f34082a428ccb1a9547552": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c05b9a4cedf4a97a5641cb078b03d95",
            "placeholder": "​",
            "style": "IPY_MODEL_0034b49ea2b04db19d7fe13aef61b832",
            "value": "Downloading data: 100%"
          }
        },
        "bce88877099e4dffad8a6481de13191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf584b9619948698062cf03850c790b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdfbe4a11f6d459db96dba6ba2e7ec23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_429beb32d8294a11bd81a298628ea164",
            "max": 1801350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f0bfee0d3194a9abf813fd2cde4c79d",
            "value": 1801350
          }
        },
        "be875caf2c3e4d7784921244a7c56999": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c038d0d672b942e1a28b0b8d03b84596": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06ef61ebdf246379110074c3f9ca398": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b660202e71470e9121a953cd1cff73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ef46456b0346338e227a1f1190b7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30e142b47fc47a3998b73d902264029": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4caf2143d1c442f83630b6919e5be10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e4007498034658ad17958526a4d604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4caf2143d1c442f83630b6919e5be10",
            "placeholder": "​",
            "style": "IPY_MODEL_499a9e2f122344db8bbcc98be10b2c8f",
            "value": " 456k/456k [00:00&lt;00:00, 2.06MB/s]"
          }
        },
        "c64e885602bc4ba1a7794af8d26fd978": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6db215148de4bc9b0c59d11c0ac8b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c70995a47e3f437692692a8d1fba3c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12bafbfdb9f44b79a9383d6a6dc2408",
            "placeholder": "​",
            "style": "IPY_MODEL_7e0c65324de1408f8a5f6701b96ca0bb",
            "value": " 3760/3760 [00:00&lt;00:00, 54570.81 examples/s]"
          }
        },
        "c759a4373a674d978f39b8873209b95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c82cd7b1be234c07a7fa1ac376bc938c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caec4e0c17894182b26fca67d1a59dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcb653d86da4525a5693dfe5aea3745": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_323fe906c461460d96f0d9452869344e",
            "placeholder": "​",
            "style": "IPY_MODEL_27d865d507b840c28c44d7e2f416dfdb",
            "value": " 1801350/1801350 [11:15&lt;00:00, 2687.25 examples/s]"
          }
        },
        "ccc563353b494157b3badda1d690a316": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e1d5f46de9c453a9842f1484dd65e26",
              "IPY_MODEL_6af6167d5fc1405b89ae85e0e139ffac",
              "IPY_MODEL_8663529208b64f3c8b34ed55daeea1f4"
            ],
            "layout": "IPY_MODEL_63991ec40d6d4dc2be72ad310d253b90"
          }
        },
        "cf8d949e3e3841069d83965f771c8edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b168b5f9c6f4ed8a03bb5c31613197c",
            "placeholder": "​",
            "style": "IPY_MODEL_ba24dc6930814242bf983d5974ea81fb",
            "value": "Filter: 100%"
          }
        },
        "d02a69ce62614a28824ec4dc787692cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaee35aa20574ee189ee0ea8edb29a59",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cab100d330d45f58f445fb554b8f436",
            "value": 3
          }
        },
        "d04a5fc63b4241d5aaade2d94694537c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_487bf6f989ee403b83f7a89162fe81ca",
            "placeholder": "​",
            "style": "IPY_MODEL_60583940d54c493bac592740c56d5423",
            "value": " 157M/157M [00:01&lt;00:00, 128MB/s]"
          }
        },
        "d12bafbfdb9f44b79a9383d6a6dc2408": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d188643c49db4ac89f84afe121e52255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb0c1c9f36f34082a428ccb1a9547552",
              "IPY_MODEL_6a29f5e5de034e04894510e109e63eed",
              "IPY_MODEL_d04a5fc63b4241d5aaade2d94694537c"
            ],
            "layout": "IPY_MODEL_9ca94d70d90740d0b5c8a6382acec834"
          }
        },
        "d780a3ba79e84dd4bd27ba58b3a2d9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd621a9c822d46edb017315a989e91a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13c4cc96d9a40a8acd3d1d8fa7beb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1cf34bbef824a35a37da5e279d13a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d9a1693c214a5d8407d385db030e52",
            "placeholder": "​",
            "style": "IPY_MODEL_be875caf2c3e4d7784921244a7c56999",
            "value": "Running tokenizer on dataset line_by_line: 100%"
          }
        },
        "e20b5c10fac1437e8fc581ce51ad3e46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5892e11651f4b70b943992bd7f88f57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b15affeec64135b90f70bec0a09f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e625fd57a304447791e0cde8ccf5f075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e69a4ae3e712444a8150cbc865dc2523": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a547ec7e004756aa776c0d1b1c91cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e776b1ba6d4543d8b3eddb1acf909a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81aec2aaf41f414ab8fb49dc46e35868",
              "IPY_MODEL_f90e15b7adc8421e939e08272fcc5858",
              "IPY_MODEL_2ba10491d3dd458aa619b90cfa037899"
            ],
            "layout": "IPY_MODEL_dd621a9c822d46edb017315a989e91a5"
          }
        },
        "e7b9536370aa4f7b9d9b515c81687645": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b7f061d6bd43dd8be079b87ca2ab56",
            "placeholder": "​",
            "style": "IPY_MODEL_94986a1cedee400a8d85f4fcab5fac13",
            "value": " 4358/4358 [00:00&lt;00:00, 7097.56 examples/s]"
          }
        },
        "e7d9a1693c214a5d8407d385db030e52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaee35aa20574ee189ee0ea8edb29a59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec84d17fd3494f48aaa0120cae6c60a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee5b15e06f2249dd8171f7f5c246e526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da2aba16ce44a0cb35877deafb6bc7f",
            "placeholder": "​",
            "style": "IPY_MODEL_80f84a9a28c24e689c49742b95139757",
            "value": " 4358/4358 [00:03&lt;00:00, 1261.38 examples/s]"
          }
        },
        "ee5c5ae9fc074c30a7630744c61ebd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff4c6a022534f35857481b65cfce50b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b634b00d88b7419a9885a9dd3a4d28ff",
            "value": 456318
          }
        },
        "f105feda0b534fe29f09c77aaabfdd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdbbf6893a1f46819973bddc0c30386a",
              "IPY_MODEL_43fb1adc5b9548bda2f2cc192ee69323",
              "IPY_MODEL_74b7296bd360471d9aaa1ac9d9493243"
            ],
            "layout": "IPY_MODEL_a56488ec12954ad09b26e794d5629148"
          }
        },
        "f1940ff80b9b48e8b6480719a61c594e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f206c35534e944c189216d333eda06a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebdafb101284890a1afc8653bd04bd6",
            "placeholder": "​",
            "style": "IPY_MODEL_8dcf28775ead47fc9fa451e8756d9f0c",
            "value": " 3/3 [00:00&lt;00:00, 71.20it/s]"
          }
        },
        "f27c99d3519d4902a546f114d2737a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f33e066edde1445182a839f61e6099a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f465aeb4730142388d6a41e3965469f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5892e11651f4b70b943992bd7f88f57",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99a01c6668c540679d3f11539998fca0",
            "value": 4358
          }
        },
        "f52aa0592f81474da00da0e607f87d21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f640b9c335064f75bfb747d11be7227f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d780a3ba79e84dd4bd27ba58b3a2d9cd",
            "max": 732610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e174ad510f944019acef74a3a81d054",
            "value": 732610
          }
        },
        "f7380217ef7b4ca0b175b8d04d2fe62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f74303cb677c4031a70dbb93ae9e8ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74a465c4fed4811bf631ff6ff9f44db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8606673361d4433aa7da7e5bc58eadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8af9760b8b448f295aa93d0fa42a22b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90626438ecf49cc9433576e0693cbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27929d244481491d9514853cf1c1f544",
              "IPY_MODEL_9ff5346af6394d07a00954447e804949",
              "IPY_MODEL_e7b9536370aa4f7b9d9b515c81687645"
            ],
            "layout": "IPY_MODEL_c2ef46456b0346338e227a1f1190b7d5"
          }
        },
        "f90e15b7adc8421e939e08272fcc5858": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_459a08784fd64416a9e243ea09adb874",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f99f1b880f754e118b3466bd4fbc3a12",
            "value": 3760
          }
        },
        "f911cb0b7f5845499ad603a5b616cb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99f1b880f754e118b3466bd4fbc3a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb161318ef8b4752b89a84562a61826d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbbf6893a1f46819973bddc0c30386a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37c84944ab0e46cf97aec71bf292321c",
            "placeholder": "​",
            "style": "IPY_MODEL_8b42b4a17f29498883c957a1e543413f",
            "value": "Filter: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}